{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FINAL_CODE",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbXpeHIWN5YO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d3c36a2b-4994-402e-9854-81f0289dc30a"
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default() \n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 145605 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.14-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.14-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.14-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM0VGHyGLs-H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "cf7b1248-93e9-4ae5-8752-ef40d8a21600"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG66p6fcoaBo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "eb551684-1ce1-428e-d23f-35d02381828b"
      },
      "source": [
        "# Install TF 2.0 preview CPU version\n",
        "# Install tf 2.0 preview GPU version\n",
        "!pip install tf-nightly-gpu-2.0-preview"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf-nightly-gpu-2.0-preview in /usr/local/lib/python3.6/dist-packages (2.0.0.dev20191002)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.0.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (3.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.11.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (0.8.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.17.4)\n",
            "Requirement already satisfied: tensorflow-estimator-2.0-preview in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (2.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (0.1.8)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (0.2.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (0.33.6)\n",
            "Requirement already satisfied: tb-nightly<2.2.0a0,>=2.1.0a0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (2.1.0a20191206)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (3.10.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tf-nightly-gpu-2.0-preview) (2.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (1.7.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (2.21.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (3.1.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (0.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (42.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (0.16.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (0.2.7)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (2019.11.28)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3xNlsYaTKne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppC23F7P0_sm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "115e2012-a5d1-4882-b3ae-48710d4bd3af"
      },
      "source": [
        "import os\n",
        "!pip show tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 1.15.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: absl-py, keras-applications, google-pasta, keras-preprocessing, protobuf, termcolor, astor, gast, wrapt, opt-einsum, tensorflow-estimator, six, wheel, numpy, grpcio, tensorboard\n",
            "Required-by: stable-baselines, magenta, fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAUUMCChlDjx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "1d991b7a-2eb3-4b27-c473-d4a7dc4cc2c2"
      },
      "source": [
        "pip install --upgrade tensorflow-gpu==1.4\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow-gpu==1.4 in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-tensorboard<0.5.0,>=0.4.0rc1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.4) (0.4.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.4) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.4) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: enum34>=1.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.4) (1.1.6)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.4) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.4) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow-gpu==1.4) (0.9999999)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow-gpu==1.4) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow-gpu==1.4) (1.5.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow-gpu==1.4) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.3.0->tensorflow-gpu==1.4) (42.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXBoRh30pXJw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a1384298-675f-4a69-88b1-6c6377323195"
      },
      "source": [
        "!pip show keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: Keras\n",
            "Version: 2.2.5\n",
            "Summary: Deep Learning for humans\n",
            "Home-page: https://github.com/keras-team/keras\n",
            "Author: Francois Chollet\n",
            "Author-email: francois.chollet@gmail.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: keras-preprocessing, keras-applications, six, pyyaml, numpy, scipy, h5py\n",
            "Required-by: textgenrnn, keras-vis, kapre, fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr0cy0uC1GOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/BRATS-2/Image_Data/HG')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC0yym6b1Kwq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "85e543c6-b6a4-4bf7-8d0e-119127af4238"
      },
      "source": [
        "!pip3 install SimpleITK\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting SimpleITK\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/d8/53338c34f71020725ffb3557846c80af96c29c03bc883551a2565aa68a7c/SimpleITK-1.2.4-cp36-cp36m-manylinux1_x86_64.whl (42.5MB)\n",
            "\u001b[K     |████████████████████████████████| 42.5MB 192kB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-1.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K82XkNZ91OOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import SimpleITK as sitk\n",
        "import numpy as np\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NrSUPU41R4Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7ea0699-55e8-4b27-964e-ed167cabae0b"
      },
      "source": [
        "import os\n",
        "path = '/content/drive/My Drive/BRATS-2/Image_Data/HG/0007'\n",
        "p = os.listdir(path)\n",
        "p.sort(key=str.lower)\n",
        "arr=[]\n",
        "\n",
        "for i in range(len(p)):\n",
        "  if 'more' in p[i] or 'OT' in p[i]:\n",
        "    if p[i] != '.DS_Store':\n",
        "      p1 = os.listdir(path+'/'+p[i])\n",
        "      img = sitk.ReadImage(path+'/'+p[i]+'/'+p1[0])\n",
        "      Y_labels = sitk.GetArrayFromImage(img) \n",
        "      print(Y_labels.shape)\n",
        "  else:\n",
        "    if p[i] != '.DS_Store':\n",
        "      p1 = os.listdir(path+'/'+p[i])\n",
        "      p1.sort()\n",
        "      img = sitk.ReadImage(path + '/' + p[i]+'/'+p1[-1])\n",
        "      arr.append(sitk.GetArrayFromImage(img))\n",
        "      \n",
        "data = np.zeros((Y_labels.shape[1],Y_labels.shape[0],Y_labels.shape[2],4))\n",
        "for i in range(Y_labels.shape[1]):\n",
        "  data[i,:,:,0] = arr[0][:,i,:]\n",
        "  data[i,:,:,1] = arr[1][:,i,:]\n",
        "  data[i,:,:,2] = arr[2][:,i,:]\n",
        "  data[i,:,:,3] = arr[3][:,i,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(176, 216, 176)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBmPK1pTOrQW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "outputId": "54418985-6914-451f-c953-a9d591ee3c79"
      },
      "source": [
        "%pylab inline\n",
        "import matplotlib.pyplot as plt\n",
        "img = data[126,:,:,0]\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()\n",
        "plt.imsave('slice_126_4',img,cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOy9adBt6XXX91vPs/fZZ3znO9/bt7ul\nbrUGhGVLsiSDbSwMxlaMirgcCKEocJUqVQkhqSTE8DX5QPIhCZUiEApCDKEwsnHAuAATG8vEYFuD\n1Zqnnrtv3+mdz7inZ+XDevbebxuZoW8Pst+zqlTqe95z9t7n7P2sZ63/+q//ElVlbWtb2/k192Zf\nwNrWtrY319ZOYG1rO+e2dgJrW9s5t7UTWNvazrmtncDa1nbObe0E1ra2c26vmxMQkR8Qka+JyFMi\n8uOv13nWtra1PZjJ68ETEBEPfB34fuAl4FPAH1PVL7/mJ1vb2tb2QPZ6RQLvB55S1WdUtQB+EvjD\nr9O51ra2tT2AJa/Tca8BL57590vAd/5Wb+5Jpn1Gr9OlrG1tawOYcrSvqhd+8+uvlxP4t5qIfAz4\nGECfId8pH36zLmVtazsX9gv6089/s9dfr3TgFnDjzL+vx9daU9W/pqrvVdX3pmSv02WsbW1r+7fZ\n6+UEPgU8JiKPiEgP+KPAz75O51rb2tb2APa6pAOqWonIfw78POCB/1NVv/R6nGtta1vbg9nrhgmo\n6j8G/vHrdfy1rW1tr42tGYNrW9s5t7UTWNvazrmtncDa1nbObe0E1ra2c25rJ7C2tZ1zWzuBta3t\nnNvaCaxtbefc1k5gbWs757Z2Amtb2zm3tRNY29rOua2dwNrWds5t7QTWtrZzbmsnsLa1nXNbO4G1\nre2c29oJrG1t59zWTmBtazvn9qqdgIjcEJFfEpEvi8iXROTPxtd3ROT/FZFvxP/ffu0ud21rW9tr\nbQ8SCVTAf62q7wA+APxnIvIO4MeBX1TVx4BfjP9e29rW9i1qr9oJqOptVf2N+N9T4CvYvIE/DPxE\nfNtPAB990Itc29rW9vrZa4IJiMjDwHuAXwcuqert+Kc7wKXX4hxrW9vaXh97YCcgImPg7wP/paqe\nnv2b2qDDbzrsUEQ+JiKfFpFPl+QPehlrW9vaXqU9kBMQkRRzAH9HVX8mvnxXRK7Ev18B7n2zz66H\nj6xtbd8a9iDVAQH+BvAVVf2fz/zpZ4E/Gf/7TwL/8NVf3trWtrbX2x5k7sB3AX8C+IKIPBlf+wvA\nXwQ+LiI/BjwP/OiDXeLa1ra219NetRNQ1V8B5Lf483q66L+j+bc/Ruj3AAj9hNlDA04edfjC/l71\nYXm94kc/8ElurzYA+JVPvx1NlN7Oil6vAqCuHeNBzvsvvsCyTsm8vf7zX3071z+eMn7yZXQyBGD2\n+BZ+Gbj1PSnVNcNjNPf0b6U88r9/Ay4YtePZH92jHCmaKK60Wx16Crs5Pq0pj/vd95g56nEgPfKU\nWzUAF37dM9ivkVoJve5RcaWCQDqza/TzEvf0LdjbZuv/OgLgbeO7fOLeYzw8OeQgHzEv7Te6Pxvx\nnVde4PHRHX7q+W8HYPBXtzm9kTA4CNRZPI/C8F5JelpSbqQAZAcr9n/3hPwjJ/CvtgB46O8+jw4y\npKqpnv2m8zp/x9ubNpV4bWayKpBnbYp7ur3F1sGIrS94VlcnALz83T3o1/yhjc/zE/l3AaDDmvHO\ngvnJgL3NGQDXxiec5AMeHdwHYNMvAPiN3ev0jifobM78264CUPcck8/d5eZqh5OHbSEXm0J2pKCB\nMLBFk+/V9G97qnFc/EB24FgOE8LKHp3egbfP71X4qSckQBoA2PncHAmBxY0J6dQcQzIrOH3riGIi\n+NyOkawytg820Lv7fOpfvhOALz5+me++9gw3B/vcSTf5tfsPA3BhPCcPnqEr2BvOAbh3cY+r/+gF\nqivbLK8M7Ddygs8D00cGZCd27mLHvmv12S2ufM68rObFb7mTnRdbO4E3yYofeB8A/plD3CUbGa/9\nDOoa7h4xWNlD+pavltz+Dx7iv73wI3zfta8D8MEnnuax8T2+dHqlPd5/dPFT/IfjU/7W6R7P5hfZ\nScw53L21ze5L99Be2r53ds2xuHgNv1Q2nrfzzOjhamX5HY+wuBTfO8kJBx5XCOW2LaSqFKRw6Kgi\nPejZogfSg4R0KhRbSn/ToovTxyds/8oLFO/cJFna52cPj1hccFRDSMxPUQ3g8INX2PqH+1z+NXMg\n926mLOuUL0yvMU4KUmevPzw+ZOBLfvnwce7PxwDku8LqsUtoIq2zqfuO1V6K1OBy++zyQgoO6r5S\n9yIctjm23+b+0au/mb/Nbe0E3iRTD8OvHyDLHF2tABDnIATUeQj24OpyyaX/+4scH7+Tf/DRdwPw\nJ97+Sd47fJZUan7p3uMAfM/gNvdqeDp/J9vJnP/+Uz8EwKVPeOqXbhPe/w7uv9tud7mhbD4F5Ya0\nC94XSpIriLDxrF3P/kFGSJV0Joyes89WA0grR5F4VGgLwK6CZAV5omjzWq3o1oTVjqN/aIuu6gvF\nFkiAfMfeVw1hcM8xefdb2fgNo5gUo2v88h96K49fuccXpxOGvRKAvWxGUOHm8JAXp1vtNWki5FsJ\nw5dX7W+cb3rqnlCNLFrJTmumN1PKrYpyHJ2ACHI6h6xHcuM61YsvPeit/W1n6waita3tnNs6Eniz\nLACnMxgOoG+An4qAS9HJCF54GQAZDdGiZOv/eZLs+HcB8Dc++ntxH1R+z+jrPDveA+BnZo/xlt5d\nfm3/EZ799Rtc/qxFEptP3oO33uTeuwfke/ba8LZjeSHuxpu2D0xerljseXbu5uTbBsKJAs4ih5DY\n9l6PAi53uKVDAohF30gQ8m3FL4WyiBHH0MGd++x+aUS+ZRGH1BZtqEA1jMfcrAiHKfe/Y8TeF+x6\ntr42o+6PeebGTcJjCxYru6aPP/8+Llw/5gOXnmN3YPnEbAnZ3TmuGJAe2mthkDJwkN2ZU0+Mh5Ic\nL3joOcf0bVtIbb8FaWLpQAio9/Dia3J3f1vZ2gm8STb66j3o9dCjY7h2GQBNbAHIrXtwcReAMMxw\n/Yxwb5/hJ58G4LGTG/z1wXex974pz0ztfb/0yXfSu7wg/fSEh/+/OX5qebnUgdkTexw/oUh87usM\nqpGSngiri/ZaOUnwOSTHS1Z7tuAaLCA99O11pyceqUEdhFTpn8Qwf6gkC2F5MSB3bNH1ZgEu7pIe\nLlle6LXHkBLKSXc9buEJGaxSOHnEwLvR7ZLsRCmHjpUbUkU+2fBQ2F/t8o/ubjLYiGlUAuX2gDpz\nTJ+wykbvpKJ/ewZFSdLmJ45yZ0j/oEAKO3kYZbhFgeQlOu6+53mytRN4k0yPT6Gu0bpGh7ZAVhf7\njL54B60qaIA859BeigyHkNvCTu6dcvVnL/KXP/tRypG9beME+MaEzWcrNHEUF+0PdTZhes2jWY0/\nsYc8JLaDhwyLSLBFPb5VEwYp0+txJ98rkdyhCW2JUCpzIMlcCMMuEugdC/Mbgd6Jo+7bouvfz5HF\nitWNS/ROrBwYUsfkReHoHVBO7MMShGIzMLjrmF+189S9lGQF2bHSP4LTR5sSJaSnQime6p5VUHwC\nt767z81/MiU70HidcZFvjVp8RaqAVAFXVLhZLI32O8A0fP6rr/p+/na2tRN4k0xGQ3S1Qnwfd8eQ\n6XR4gerKNn6xQlNbsCqCmy0g60HftsP52/Y4eJdn+yuBrS/aZ0/fvsVy1+HKQL6bcvi27taqBz/1\n7c7rc/AnQrkBdQzJ03vC6KUVq4sDSgPdcYMKLXq43I4BUPdhcNcREkiWgo843PKy4nOhGirpo1MA\nnvkjYx7/iQmuCPiVOYHVXp9kpUyeEQ4/EC9o6UGg2NIOaCyFcgzJUqkzQcrut0tKIVl6XORSzN5S\ncfFXPW6et+XNcquPy2tcXPgA9TijzjzVKMGPzfH6RWXO8Etfe7W38re9rYHBta3tnNs6EnizLOap\nemWvbbNMjpao94Sbl3CnSwBcUVpKMOwjc3stJEJ/H47f6tj8ioXJ/f2ScpCxuJjSm4e2ft+E5poo\nbmE+P/SgGiihZ7s5wM7XShCoBo5yYp8JpynJNOb8I3vN5wYApnNBAywvRnCvB64GV8LynjETZafg\n7gc22Xy2pBxbrn/6UELIoH+gyCJGO70AOMphTXIUS5FDwxzC1K4vNV4Q5cjO4QpY7dm5x88m9GY1\nxaUxfm4hg9RKNUlJZiVhZAQil8f0QyHdNwBRU0+5OzjXC+E8f/c310TQ65eoNrP2wUU89TDBLSvw\ntvjq3QnuZAGJRyO92OdK/yDQOxWqbXvApw9l5FuCeljtevqHtkCWF4RiJ+AXYmg/toCKPcUVwsYz\nMR04KUHh6HFPPWiQc6XarvCnRgQCwxMQLA0QWF2N+XYhVJmSzBwut2vXMRy/Xdl6BqpBl9P7pTK7\nJgxeNieweCimAbW0IX41UEJ0YL1jadOR9vo3O8d04clAlQlhL4W9WIVQUIFy5PERBCwvpFQDhzo4\nvWkkhb1PHuFX9au/j78DbO0E3iTT0QBNHOoExBZIsZ0hleLr0GICblVRXdigHiRIsIc+3/SExD5z\n+ITtsPOrgnqldyJIgGpofy8nSrbvrDwYk7/gob/vSJbQO0Pnvff+TcvLQwQBlw5NFZyiPr6GgYMh\ntcVIs34E/MJRbQR6kRhU0iO9Nqd/q2DwZWMwFn/gIXyuVCOhdxojjiRhdb0kPUhwdbzuzRoJQu9U\ncHUXcUgNvjDswVX23tWO4Eoox0Kd2muubiIUQYL9lpNbFeqVZBVaQLOeZCTHS86zG1g7gTfJ6q89\nhbznnUhQik3b4cuRx1WKuj69Y0Ov862MYiuh7km78Fc7wuh2YH7ZsbzUbO9KeipUI1ukjWWHRuVN\n5h1DPlnajlv1ob9vW2/oJxSbgqs6DRhXunYH1qYvx0N2IiRLKCeQxfJhNVBCpvi57bT2ZsjnPe58\n95grP2tg4ehuxfGjKT6HchRTmUOoRgmu7LgDfuWoJjV15ljtateqppBvK67GVC6x46g3p1QP4u+b\nCeks/hbxK50+ZI/78K4xJAGKnR7ac+caHDvP331ta1sb60jgTbXQT5BKqTea3dTC2qqfUE7s1uSb\njnzTQvxml1ZnHHxNLCyHLm92OVRjpXdsW2c1MoDNldLuiNVAyVbChc+VLXOuHKdWSlx1+XdIleTU\nIomQ2fuShUUHIY0cgXhMdUYuQoyMBJaXyyJhdgPm33YtHlNwpZJvi5XmsN06WQjVqGMmqge3chSb\nAYQWH0hOLNII3voVwADCZCFUfagHEeOYCsUGhETp79tv4QslpGIdjEVMG0qhzhzVH/sAG3/31x74\nnv52tLUTeBOtmqRWp455bJUJOrTF6lo6LiyvKKMXhWIzYgebSrKwRViPY3df7fFLIQzigj8TPrtC\nKPa6rNfPHFUuFBNP/74t7tVeiittcWkaQ/KFEDJrIKpCZDPW0DuxRa+OtgrhC6sQhCx0wKADKQV1\nsP8u81a9U3MA6mkdSN03kNLlkToNJLEagBiYqJHk0DgfX0A5tgO4yn4nv5KuKjKAchyQSqiG8fce\nWhqDdtftKphfdAwOwqu7ib8D7IGdgIh44NPALVX9iIg8AvwksAt8BvgTqlo86Hl+J1r6zz7N6iPv\nNz49kE0DdU9YXHKk0y4390tbND7qsdaZ8e/TqSIRSFMHiC34ZGFlNLAOO1fC8PmEcrPJty1fXl5w\n+MJWSDGWtvzW4Ad1n7jrm7AIgNZCPYB0qlRDacVPygkGICaKxBZhTSD0Aq7wbcSy2hFCr/kOdNce\nPUJ2GF8UwyFEYblRt4mrL+yzqmKRBzHiCHbcdNbs8LboJR4LrAcCjODUXPf8sjEiL/zVX//3vn+/\nU+y1iAT+LDZzYCP++38E/hdV/UkR+avAjwF/5TU4z+9I6//cJ9v/Xn70/dSpkCy0XTSuhP59C2Xr\nqM6THTlCaguvFfXYMUJ/NalxucOv4o46E3RgC615zS8hnSnVQDi9GVORoTmZum+LHsyhWD9+lyIk\nC4tUQmrRRr4dnVWsPybTrpYnAUTtGE05rx4oybRzHgBojDhiZQOgf6j0jwLl0KHOs7oSI56B4gtr\nQMLFYyYGCiYLaaMDXwjqzEkWW11lQRSqkbUzg0UWw5e/qSB2a+7b3mH/v3/C6vHLZHdnUNn1lBfG\npHdOYDpHZxa+hPn8tzzWt6I9qNrwdeCHgL8e/y3A9wE/Hd+yHj6ytrV9i9uDRgL/K/DngEn89y5w\nrKpNkeolbCrRv2Yi8jHgYwB9hg94GW+8+d0dUwEShxaxzPYqdoDwPe+hHNltkMp08ap+j2Ir7tq5\nmnZeTyg27TOuhGIDiu0AV4y8ryc9qk3b6kIWCFH+rxoJOqopL4IsY738Kc/gMHDwTt+VE9UAvXIS\n2ogh9NRC+kHX8XdWi0vFIg2AfC/gV87ShjP8f9Sut4ls/FLYeAZOHof6RuwCvJshpZDvKHVsKprf\nBKkECCQLh59FTCJEILEw4A9ARyVykuJXkO/EtOJYyHdfucNLLfT3lXIslPF9Lrc04vBPf5CN5wvS\nE8u5/OGM6pnnkPe+C1labqUbI5JFiZzM0MhCTO+ewskMnOAm1nThLl1Ap3MINfXB4b/DU/Dm2qt2\nAiLyEeCeqn5GRL733/fzqvrXgL8GsCE7/+Z47E02NxyC91CWhCIm20EhyyDPEW+Ly1+4gESmn1YV\nEh+KbyZg6d/2Vjv28YrkqEHEPZp5JreEcNcW1+xqwmC/JD1ekeTma08eceRvixTieWTIVYJmAT/1\n1KPQdQemiiw9Oqrw0w6w23+3p860W/CJIhFEbNl5YgvOaZdKuMLC6moQQ/zoFJKF65SGtMMp6mEA\ncW3+HnqG0G88A4exYzBsVUga4CSFrGHxCKhH00DlQGPo37+XUGdKLV0FZDlypDMhpKZ3AFCOXEeO\n6nf6iCFVkqWy88WYIqiSHddkdxe4+aqjc8f7iCqU5illOidZFWi/h6wiQOM9TEagSr0XvdKTX8Pv\n7aCrCn/JerXFOXSVUx9968mYPajk+A+LyA8CfQwT+EvAlogkMRq4Dtx68Mt8Y831+3Zz4wMRVjmu\nlyKjIT6q+4bFAhYgvR6UDQpXIdsx2ayDtQsDyZXLaFEgaQpJ/MkL47S7wym4uJKcAxGS51fojm37\ng5c9mjjqQcrhO+zBLN66JExTpHAwtutxK4ebO4I3Cm8D5BnFD1j6tuKQ7yih7QpsWm9tYeM6xmDo\nqfUWhK705nOjH6uL4qPx0v3SSpaoUI/sRK5wuFXneMCig+kjsbx4EsODUQ1HPSuDHthrIY0wQ+3A\n055nda3EzTx+1dGgRYXhHbVSahHZihuB3oE5pt3P24c3n5rj5wXuZA5xEWtVIRsTux87E2RZxN+j\nJrlxnfD1F+CqTdKrr+7iD6aQ9lrHUO9OcPMcVHHP3bELunkNgiKqrXScigMnSJah+bfWxK0HkRz/\n88CfB4iRwH+jqn9cRH4K+BGsQvDbbviIm0ygrhHv0To+zIO+/XuVt45BkgQZj9DZHBl16Uw4nUJZ\nmnPwDd1OkfEIvEfTGPrPFoi3xiDieWSZW8twkiAHx/bZyQgGPbwqo1uR5baRIR56J0LveWMb1n0o\nNhS/gnTmW3Vg9RayF1tddBBSe13OcGU1tXKZK6Vl7bnCynvJsuMYNP9vPQDS0nyrgRoi31P8slv4\n6oEASXzuq5Ha66l2If7MuAfqO2lzV9nnQgZ1VuNP7Xertyr80jgFjVz61q9m7P3zF9DRgMG+KS1J\ngM2vneBO5uipsRUlTVFVGPQJcythuAu7pjegiiwLNLPfUwcgeYVLE/sM4BaFaRLOl+jSIjEPdg/v\nHZgzAcJ4gJwuzAGkUaWpl6JFiYjgb1y39+1uEJ788r/+EL7B9nrwBP474CdF5H8APotNKfqWN78R\nQznvjcufJlDFMDBJ0MYxFB2sLSLgPeFhU/0NvYTkqy+ggGxM0NmsPaYenSDbmzA13EA3x+A9sli1\njUG6MYKqprq8S75rTJp807HcdVz8jSWTF+16eqeeqi+UYyE3IR3bqcX0AUJlDgIi6aaE3ok7MxVS\n26i96dMvt2JvQd0JiIBSjQLpSUIav4omRjd2RUxBop9zpf3N6voNqUlxhfUflM3Pu7JqQfBdJUBC\njDCCvMIxATATwtS1r1d10ob5vb5d/Olbelw6PKJ65CJbXz6xPz71Am5vx37jvgEkOhqYE18VuM14\nQXVtSH8UcXGzWN90Dh1khH6KrGJn4nRh92o47qAREUsN93Y6Z3FwivZ7aFlBJGPpfG7XcuMqenc/\n/mYl7uYNquffXE2z18QJqOongE/E/34GeP9rcdy1rW1tr7+tGYOApD2T9ALEieXoZfXK9wyHMbyL\neWxdo4sleI/7hnlyibJgbjS0oRZjAwY1j4MuVjmSNJxchVAZyNTUnC9ucPu7hqz2tEXtXQX5lZJ8\nt8/GM/ZaulBCAqsLkXRDZOcpuJXYDt2AYont+KFn+gFgZKDgrAmnBQGDWHhf0oJ4qHUbQsdgLIbW\n29+wBauoQoR2TUZSNjRdh6tsEEgTHVSjgNRCMu3KDCE17oKrOxYgGPGnzgy09LFjcHAnNlFdAP+k\nhd+XPl8hWYZflmgvpluP3STf7pMc54BJrbnpwlq4N0ZIs+PXwbAYgNMZumnHlMUKnKC9IfWOfT5x\ngqwKdP+o7fzU2Yzw1hsggo8KUTqdImqRXhMdNOkA+0dtmqhVhWApqNvbedMmIJ17J+AmsboZ8/Kw\nXOGGQ7Quupulagu8rpHMwnQtS7vBRdHiBIiAOMLp1G56BPxMRsxBnqPx89I4hr1N7nzIwMTlJTEK\nbaTvQuyqq4ViNzCtfHsevwJCt2DrgRK8Ik7ITs900w0UV9ii7R117cU+t9bjxnonhgVUA3DNU6GW\nGri6A/Z8Dn5lrcDGUIy/I0KZqomQNqDjIKClOReJi9hXdt66/0pqdDVS0umZFKEyByCVHbs9Zgbb\n36jZfFYZPxVD/6qmfOdNZg/1WVyMOgx9c0o3/lneCrRoP7Pf/e6+AXUAe1tIHPQiSYKeGH5AP0Nm\nC/yqwMcNgjQ1gHfQ77CD6Qz5yrNImlC+42EAkqMBun8MaYK45kZW5oCKwvQi43NBVSEPXaX6ylOE\n3/Nt9lv+SjPa842xc+0E/NamofXeE47tgZIkMfQ2hDY6cJMxVJUBhREQkvEIXVpJqXUMy6Udr8EN\nzmAKJElbPgTs+Dub3H//FsVG3BVDZOc5JQw7dH/0bMLies3qph2393JK2LCF2dTpq6HVwX0ORZT+\nhq7Jx1W0zDlX2e7qym6Hdrngl5bXd1FI5NpDpwxcQegZRz+kdE1JI8Xl5sRCz97sCoeU9lpbNkyV\nZCaxHyAeswZXG9inzUSjpX33kEKxZQKmzXXMLzp6U+XodxsgogJHTwjFhRo0ipzU5my+8Z9MuPAZ\nc/TbTx4jRQlJ0qL2SIz6mh07PSPwujlBBz3kpbv2WmmfrW/dwV+MAOT2Fno6RXa2cUUdv6MnHBxa\nRFjM22dA+plFA001KArNCpBcu4J+ySKBN1rb4Fw7AcRBUYIPuEEEj+pgjiAudsDKR3mOG4+sQoCF\n+OI9WlUdWJim6GKB9DNzBsv4oGUZhBq8Qxu9+60J80c3Y6nNXnKlVefqPnAhnueox/zRknQzpzw1\nZ9Oq/WbahuOujNFAauBbU/qzeNOotSFrauPWRSehizgkNc5APezSBsQalZIlbfOSNSQpDMzhNI04\nBu4ZxpZGVeNyp0IqExFtgD23iiF+P+DnUe4sg6Cdg4LI8xeoxoH+bd8KooZEKLaE+TUodqMgytTb\nda1c68BCLGmGrZJ732kXOb2xw4XPTRh9+W7L7WC6sNkDswVc2G4l3PR0imxuWCWgeQ7qGpwnvPft\nLC5m3eMxcfSP6nbAajpd4bc3qY9OLL0EZGsTYnWAyDWRLLNn58XbsLPVOrA32tZ6Amtb2zm3cxkJ\nNCwulivIMnQ67Wr6zqF53gI6gEUBWQZl1e4gYbkyHcA0bXXtqWsL/aH19oCxCoeDGGU0yW1gueMp\nx9J2/OXbRrmtNmuSWxaZhJ6iQ6WuPP7UPlsPA8VITUa82fnSrqe/2gxtDT6kxgSUqiu/uYgHqJO2\nCQdn5Bs7TmwGOnaoU8pRFzH4XEmW9p5is2vdlcq+R7bvWF6LvIfKRRkyaaMQl1trYDJ3VJOYNkTM\nQBOFqmMbamQKNsKnYBFH3YdyO9DbtUir6PdgZdqGeilGULPIpJwnaNRCWDwcOFqmLC5cY++T+/GA\nse5/dY962GsHlYQLm7jpyvL6hgU6GhBGGfWwWzbLXZvJOLucUI7tnMvLfQb3LnL9J5+hum0EonBw\niPR6ljrGZ0T6GXpsN1DTpCOSOW+R4xtk59IJ1PcPAOP/62Lxir+JiI2jqusuRVjlBuhEchBgD4a3\nwaFtaBmxAfLc8IRm6EWcF4AGNOaN4epuK3JRxg67/oFQbCrpkW+nALtFrO/vZy1rbnhpTll6yqbX\nFyPapDMxsY2z6YBXKIUwCK0UmDqN6L7pD4KBhdVAqcZ12wlY963lNqS0uXrlhew0IGp4QR17FGQZ\nVYzH2pKSoOvcC64jLyHGVExOX0kqktBVNZKlkMxNdqzudV2VIYV8t0Y2C+qXDGDzV1aERYb2FE5j\nLjOoobRuw6ZnQgc16mDrGwtCVD92x3N0sUJWOX46awk/LkyQ2cJy+NgngAjLSwOm1z0Lm/Ie5yMo\n1UaNm8Qeg1o43fM8+7/tkf7LRwG4/vHnWhyIe9ZPoNOppZ5VhZst0EuGMyRJQnXnLm+UnTsn4N79\nBO5eLOWUZTvZpwEBcQKrAr+91bLK8N7eF+qu5BNvnvR6LSYgRJJQnqNlhZwZBx5OpxACbtdUbt1z\ntxlu9Zk+lHHlV+3c9749pditLbeNZbYwqundTQ1wi7vp4rTP1s6cY9dvd/JGdDNkUaCjyWQLh1+B\npkKI1YCQAs4WaLO4k2Vsz/V6huJrQiH9o66N2edWAUgWViVYDBresEUL1UCRRqi07CKNZN5lnrbo\nu/PYD2d05TaySZRyYqCfL3GcbAUAACAASURBVLrjFJuKyx31KoHtqjk1Ugr+8hJ93hxD5RSckhz7\nVmOg7guuAr8okXnEa46n6Hxu9+Xh69Qjc9jueI4O+5SPXGzpydXAc/tDnmojdJWVRK3vIQhh3i0n\nN6xYzXvUURb9hT/+MDd+5jbha08jA3Mq0kuNyJTn6GhgjFGw0vMbaOfPCRzN2rp9E35pVXXlwLKy\n6UCqHZ13Mkb6GWF70k6zkdv30JktdLlg8wDJC8LhEfLIDRy0NzXcuWcosIgxxwAZjchuT7nyrwLF\nZgxdA0i/xh37tsTnTxOKqwVUDonNNQKsitSQ99gw46eecmyAoQQI2gluuEooBwGNm6QoreJPox1Q\nZ7Y408OkDdP9XW+CoqMzrYMShT3j7p0sumO6AqqxtH0G9ahGKrEaf4crokkjitqF+SaGIm3o71fm\nAMrtmNo0DsOZFLksHdpvuqSE9NTh741YPtGMREogUTRVLn/SduiTR1Ky4wBPv9hSwuXaZQ5+8K0s\nL1m6lMzt/LtfSpA6UI0SkihJHlJrVCq3FbKmlqnoyp4diYpKbJaE3CO579SPCuHZ//gKj/z9HuGp\n5+z9Wc+eB3HGJI30c9mYwOkpb5StgcG1re2c27mKBA7/1AfZempF6FlXWHZnhr7wsoFDTVSwXCLj\nEYsnLlGNzMMvd6wunW91jTSu3CabBtQJ88uRoJLB+FZgds2Z9HcE/PqHV9h7ckH64j7VLRs57ooS\nKUp60wW9iB3Mr9wkf1eNqM37A8h3gnUAFg6NkYAuEla1wKDGH1kUUU9qklPflgebvTskQN/IQW3z\nT2rhf90/E5Kr1evrTFtiTzmBwX2LEHze7drWVKQsL7iWLARQTYzc1HIKckcY1mjecf+tPTnm6k2P\ngrPegTrT9njFth2kd+ioBmf6EdKAXzjqYWg7BocXV8y2e1z7BNy60nUmilfqnZIklu4u/8MXoZ9R\nv+0mz3/EegdWDxUQSiTRV3RQnr6lz8bTsNrtIpbxC/Y7JVPf4Jc2sLVfW+tzI8GmIImilbat0WGa\n4nPh8D3b7OzHdHSxtJQx9h9oTD9l0MdvbFC/QdHAuXIC6UI5fEefnS/H9s7nXjLQznVkIX9xDx32\nGTz5AhKBweL3XmP/PUZ1Hezbjc63hcVlz+JGhTRa/QJ132rWxVZo23mXj9acfJfD+z3KY9NYefgf\nBIaff4lwfIKLYeDFn/4qUj/BwXcE6huNUEkCvYAsHL2n7HpWVypYenpH3hp/ADcuqSuhmii9fU8d\n14J6RVZiKUEMTbPDGLJrhyVkh3HAhzNgEcwhVEML87OTpoNRSOca5cq0resbPmkhfZNOUAvUQu/4\nDFDZDC1RaZuSXGxjbgRHAdJT11KRwyC0jgkV6igg2lQx5s9uooPArQ8LLpKkdKeGexmP/FxJ+qyB\nbLo54e73XuDoQzkQ04bc28JPanTp8RHcCxdzyvt9yk2bwgRwdFHxx0nUSGh2AzVn5MxBAfjDlNA3\nMlYztKXYqRm+mFiqdvWCPS5fedrSxCxDNrpOVF2ukM2NNywlOFdOYHrDMX/3ikv/PNJNvUeLkjA7\nIrkeJbE3x5QXhux//wVmN+MCK2l3qdWO3dTJC4H99wCpMngxjvLetHKWRDqvNuO8F46676mDtLnk\n8z+YsPH4o1z+VyesNm1xZ599ht2/9Sku/uIVlm+zaOW5H3bIsKLeLQkDO4+fO+qxzRtsFoKuvB3b\nKcUe9G/be0MaUf5TOhnyseIXsTTZ4FsLJVkJq62OI6ypUmceV2rLauydKr1pjTpB1FFGYFAqI/1U\n49Dl//2a3n5CdgJ5Q5pZWBUhpIrkTRuyAZrJ3LWAWzXWeEw1rcAzoIIUYorI8bfUSiANKI63/j3b\nTf39E7SXsnjrDvvf/0i8/8LyrTnME1yMIrRvC1qOU0iV+tiAE7dR4pcGnvqROYZ6kRD2Slj6NgqR\nUtCekh67duqTK7rSaTPLsY6zH1VAszhdqtez/oSqQu/ex0UtCkkS62J9g+xcOYHifTPecek+WsSh\nl9Mpbjik/PC389L7YuvuXtN0r224Wg1sx6tGHfI9fcjhc6UGVpeis1gZuu1XVvNOFrHZZbfT/ZfI\nWdcsMH0U1G+247hW3/F2Np4PbH3qNukvfBaAtz91g7sfvsL0Idpdv96p8IeJ7YijuBUf9ZCdnFB4\nXO5MPwAYveRIFsr8mrafzw48y2sV/XtJG37X2RlkfhhBs5Un31F8Dr2ofuxqpe47a2UeSIsq1ZmQ\n79amZNTs2g1vYdhJiEsNRdrQgWPlYGHnrgfaObUkziJUwHWvgzknKVwLxPVvTMmfnfDIP1jhju1E\nd7//GtOHIqswifTvhYdm8TfHU0iPE1uc0ZE11oin1E3ZsRfQhbeya5Rgd5VAKZSTYNELloKlp3Eu\nRExjQj9QD2yKVIhOwDuxdmMX+SbJmeV4hqfyetsaGFzb2s65PVAkICJbmNLwuzCf/aeBrwF/D3gY\neA74UVX9lhBWKw76fGlxlbdnptojvR7HP/y7uPMHylYirHc/AoSOVyjshCxEYkjM+7zp3idHMUcE\nQt8GdlTDOBEnlvl6p3EH6ClN/B1wuNykr6dviWFtoswfEu586ApuZWyUG/+85OIn7tL79oucvMV2\nkNU7CsLAo/0ad9BrPxtmqdX5U215+YtrgcFdZ3X9PJKAMiWZepv2E0uJTe+BFIKPJa9qXFNOHNWx\nY7AfwctLnvHt2nbOpOsirDZBhzXkrsVC/KmnGpoWYLPDzm8EYzZWXbdhKRgopx1vQQc1lM7C7kTR\nOGSFhkOxWeIz2+G3/t6ErV99iXu//wYnH7Efve6paRdOEzSyl9SpAXln5ii4ZQQtvX2GSZSPO02R\nSlGv+A37kvUyAa/IyrcNWjgr7SYL1xKaENA0zkeIkYDUBnyWY0cSxUz14Wu4/ROql++QXL3cNhbp\nbG6YwBtkD5oO/CXgn6rqj4hIDxgCfwH4RVX9iyLy48CPY2pDb7r9+d/3c/xPP/eHqb/+NAD7H/sg\nqz94CscDksMmrw+4OIqroZuqOnQQbCZAZNOFNDbNrMCVtuCqkZqu/kwoN0KbDqg3EEuFLl9OA7UT\n6mH3mtRiC2mWUG3ZQ//sjwj+9CK7nxMe/onnAJi+7zovfbSC3BE2YgxfS2QHOqPhtqo9puIrddfE\no0kUDhVtc/ByQ1pFocapiQphWLO6ICQL+45+pa2q0dkGosX1ALWpA2k/IuK5Y7Bvjq4BBl3UKEQg\nNIBEBNnqYUDibylLjw5q3NQjuVAlzRcCv5dTH2Y8+pdtcc5uKl/7L26YI9yKJZnC2TGy0Ooc2r0w\nLEGmZ4g9hVANzCFqPL9fOpaXhXqrNM4Blh5JHn/bM9QJdVCPAyrNd3TtRKQq/r7aU7J9j18pL3/v\nVrwWGNzfZPfnS8LJaauARFmhWUc0e71N9FXmHiKyCTwJPKpnDiIiXwO+V1Vvi8gV4BOq+rZ/07E2\nZEe/Uz78qq7j38fu/pkPce2nnmb1DtN4u/WfFpRFQigdsrAb7ZZCPalNtbdZDCEOsii7hylZCump\nsLxct5p6PodiN6BJIDnu8m2csels8EXX6mptvl07L5E7r4O67RPQBEIW7BriQ3b1E46tX7/FV/+r\na/hLxi4rTzJkWKGFQ3LfIvxSCvUk4BauHfihDlCLUJpoJ1kI+bZS9zsFYk3UyEhe2fhy2n7Wr7C5\niGolNIDFWwrbuUsxCh9AJfiVGAU4koqqoTmEVzhEb2zIBmSzcwfSg6T97cIgtO/d+kLChc/OefEP\nmNhHsRkI47ot74F1FLpCDIBsihWD7n42/sfPHT43DUbthY6BGanGod9VApLj6Ay0/TghU8KwRkrX\nVQdmPs5SlFYzwe65OZzmPgQPy+s1V35Z2PjZJzvC2lkG62tov6A//RlVfe9vfv1BIoFHgPvA3xSR\n342NHPuzwCVVvR3fcwe49ADneE3t2k89jW6MefaPxJB/1vR1yxmgyNnDJLYTAvZwBFucbhBvzq2+\n7W6ONrSskggO1gn1IBAy+3wyE5KVmF5A2TT2GGhUD+sWbKSKzTVHiYl7Yg+4n8UHMi6Ql39f4OXf\nd4Un/o9Tjt9hYeOd318hTmHp8UtHtRXbWg8T0iNHuRGQBvX39hRLLWRRaKSZJCQBqt24mzpwJwlh\nEKjiJpWssGrBppAdahvmu6xG83juODtA4m/oV6YcBBY5lKOYDpxFpGppAUmwBVeNQ4tapUf2H9d+\nuWB50fH8Dw0pYylS00BylNgItEaotD7DR4iH9erM6WbGNWjeZwKnpnt4Vh2pntRILbhld6GiUZnp\nFSvHE/rBgEdis1aFAZv5GceEpQhNvwUKo6tTjt+yxdb2VtumLmlCHUvWb4Q9CDCYAN8O/BVVfQ8w\nx0L/1mKE8E1DDRH5mIh8WkQ+XfKtJcG8trWdJ3uQSOAl4CVVbSY5/jTmBO6KyJUz6cC9b/bhN2P4\nSDidcvT7H4FJjMdWHlRITvwZWSsD0DShzZGrWAt3FYRVww5UqqEBTKFummjs327l8EvXHtMAI5uL\n14CFEjCyTu66sDhR0iNnPPzoF8cvGGOuHGs7TruM04m+8ed6jH7druexv1HxzEcHyLUl9X5Guh8x\njq06ph7S9gn4lcQ82PQC7eQ2MhwVpIra/5nV/NNj3/YDSLDPutIIU/lOZDHOUpsAHGchNtYAaA0I\nOLivqES2YiOmUgghDUjlrGuS2GTUUwhw5V84tj5vnZ93f++ucTVE2/A7mXrrezjpzusqupQn7rya\nxohv6agb4ZRgZT7jJUjbAdn0PVj01oGnUttrTeQYeoarpMfdDMZqFCBKqDdkIfUGxjY9FmCSbrOX\nJ3Clpnz4Ev5z37Bj/qbO1tfbHmTuwB0ReVFE3qaqXwM+DHw5/u9PAn+Rb7G5A5JlrHZci4hLFdt0\nlQ7EE1uMSvcAA1TDQEi6RpgwCEhuINxZFSBpKgm5b0PGRlMvO+ryQRv06SwcbYDmqgtdm5BxtWtN\nQYN7wip2pA1e8pQbSlVnnP4uO+Di6oBHf2bB/rcNOXpfSdV8x7ho63F3Ip97QmYSZE1ILrVRd/Od\n0CkQlWINSTF1sBdp5xYALR7iTg2/KMfByDvY4m6mC6exMaccGbCWzqRtkmociVsJ9balIsmwIn1+\nwKMfPyX0E/bfb01ap28B9YHecddUpNdX1IuEeiRdB2MhaKZk932LRwQFlTi9OEoJ1gPDQdR3FYPm\nu+Ot+9HHkD7Eygu9M0NbgrV7V0NtgWS84ua+HYgKsXrTi9qOLRYCvQNH+ciK00cHbH+xcyRvpD1o\ndeDPAH8nVgaeAf4Udms+LiI/BjwP/OgDnuO1MycmQNmQWYYVrGxBrCJgl8xdOxK7WfCuAAZCOhWb\nxgtUeyWaBBuR3Tw7myUcp9Cv0YXrHgBsgYVE28UTvB23zgxoA8uXJZacWgfiYHmlJpm5lqJbbBl4\nl4hrF3u1UfPUHx3w2N+ds/OVhNsfiiXCGxX1hjmsdjSZA4JRm5O4iJNVjDbyrkpQDS368CsbbAJE\nXUIY3QrMrnfX1E4iOkq6RZMYM9AVQh3xkcbpFFvaiYrkQj0M1JMKF6sAG788YO9zczR1HL5ryMF3\nRJzhzLX178RoZ+Zgs+4cFRAmNQRYXQ1t5ceV4Gr7Pu3U50oIYtGbVUvi1wnQf9m19wiAntGtpey+\nhzrQrRKZJ0jRRAw2TMUvXEucyvYTY5NWtI6q2LTyab5MuPchZfeXDd8J0ylvpD2QE1DVJ4F/DW3E\nooJvOQuzORvPBar32c6dL9N26k0VkeNyu4JUkWnSynm7XOgdW/27HX0VQSBNlVDFstbC9L1lltiD\n34746pR8ul3AQsWQdlN3QmqNMyq0ZTbbRgNloq8Is5vhow1oWI8DMi557odG3PjFnJsfN2x29egu\nL35fSri+Mh4BoKUBmo3EONgCCYlFBuVGt8v5FaTTM3oCK6MYV1FjsC6710Nq+gPNAmvQ8N4xZKdN\nk5SjGqv15McfU50gwwq33+Phf9SIqd4jv76FK2qO33YmW1TbVatJoIyMw/GzCeHA0qqGhVhlwe5F\n0bU2qxfILexvUqOG1ehKu09n+xmKiY1sa+9PYtRxCfbdIdLJTxJzTtLcx1hhObORlBOLNGonuDr2\ncOzbcTa+nDL8g3fJHzMM3b/0xk7uWzMG17a2c27nqnfAbWxw+rBjNY3xXWEhe7VXGtkGaxbRWggT\n6L3UTfxtdg4XQ12Psxq6U3zTLuoVXXShZ7MzAEgcoNmWstW6+lxpYSFEnf5UTa2mmeeXBSsdOqwW\nDsZa8wGtHHoxbkmFJxSe4krJsz/cY+NpG4125edv89hLKS/9wB6zb7O8oxZPepiYstCZbcDntpM3\n+Aixnq5eSGLKMnkpsNoWyong8g7A9Cv7rKuEXmx+k9pC6WoM1dBO1OAakguuyd+vrnDPDnjL37xD\nedkGsT71py6amtKGABUSWYxslpB7NNCG37MnCmTmDRhsKBdH1luhiUIa74/zuNJZSF93X7Ea2uBV\ndbTAbUhtR9cEqrSJJJTswPL/JrVKpzZXIfQsUgDDRqQmNnjF4/U0jmrTttyZLGBwEPCFcudowvJd\nBgRd+iXeUDtXTkCvXbAHpmlSCcYBkFkHyIRFHxLLY1spcBRXC3XSSXz1D4WictSZI0RiCYlp7ycL\nsbn38eEJiXFQqoG2JB4idVYC7TG1DVE7uimpRifQPXjJqKI+zCALhGV3C5NxSV05wqjm+D2WrC8v\nXeaRnz7i6r845cXMcs7F47mlIXqmacjbA5vOIXvJzr28aE7AF9pWEVZbltIM7gdW264Ni9XB8I5S\nbAnptMmZ7HghEZKlvba6EFOPDNwVIw8kXxzx8F9/itkHH+bFH7CP+o2lsfcqh8wSoxEDlA7SAKVD\nGz7CzNKwcqNrba5HAZJgjj5vgBgjZjWAZXMfkHhvClrqbt2zlCmcaQRL5s7mK1QC5Ss/30i7gwF+\nxcUKWZ7BhbJg2IIoq6hzizomtwLjrx5y+IWLFG8cU/gVdq6cwNE7N9jeO+LoZdttSBV/6q2E1oBm\nQLJ0NmG30a7v2S6fHXVoejUwxDydg5wZ/tk7NlacelqAzJVK3TOBjEY+S1OT2ApJh7STRnJMoBPr\nXDmjAxOrGUB9kNkO55Wkb099tUyojzKIBLfGieR7NS/+4A43/skR13/JEt7nxiPc4zP8ZyYtxpHO\n4u4oZ64Hax1O59qWSevMUP1kZbvd8lrnFKuBtKQgsHkFvlBcpZw8Ene/Oayul/hRRfp5Y/w9/Lef\nZ/b+6ACaqOq+7YqSWClQGuqv2I4sKtAMOdkpCJGElY4MU/BBKPPEij9N268HWZnKcadP0JRrDTuo\nkua3JpZLpQUG/TJWj3rdaPfQj1OXLuaEVYwC594IaP3wiooDhcPPvJGIgOXbV8yOMya/sWLj+cDo\n5TMKLW+gnSsncPKYYyjdjoraok5Pu53BFRYWl2Nagcp8R6OyrpXrwKKIkBAZg/ZZqcxhuArKyEWH\nMyFh1lFYZWWRRt3rQlMqW/Cy8F25SW3xSykdFTgCTtXAUUcOfBKVedrPRRMVFldr7n1giwuftjj9\nxi/kvLyaUPdg7wu2pfXvLqlHKbOrGeW4q4svLsdhIU1dHaV/X5jeFPK9ul1MdU9Y7SjD24ImTXlS\nSReB3kmFK6Mc946jGib0n0q5/k9Ndbd8aI8XPmI7b8PpF23AUzU6dIP8V84WmKrxPIA6CJIEdOlZ\nNeQDFZJ+RVU5i6YALTu25G+mJ/uVObcm9Hd11FFMOqGTfM+chzFF4+cz63dwdzPYiA6s0T5MQ5tm\n4hWyGl12KYvOE07fqlzaHtM/qDi9ad5mmzfWzpUTWF2sSKrE5KihRfHVa1uSKzZiBUBpx2nXg4Co\np+7pK8UxS7GRWo0cdhbVZJztpg2hREL895lNoZ6ENqdtehTcwrUPZ0NV1dRSCAkdyp2eChonDZ1V\nBg69eA6vnX6/t8V1+L6Swb6NKxo/N2P3iymHT3iSeazRz3Oqca/tKwDL55vooLFqqyLXMylIdIpV\nxDeqIe3osmIsJCuHijB6waKQwZ2Evc8HqlHaYiYvfv8IQkXvnm8daj0wAEUKUJI2QnCDytS4KmnT\nujBLbbc/4/96o4JiFh1C3ThPu1c6qrumralhIyHVdqirvZdYCpRu+tEgyog52uiMJKC1oJcKpI43\n49TSE79RUDVaBJXdU58L2oipXCqoFVZXxmT7S04ffuOahs7aujqwtrWdcztXkQBZIF+lFlJioGCV\nKhx76nHX008akCRAM8WmdNbMUndAmjqrEYdU252zd+yM8BMjiZbw0+zmcTgoALFxhc2yDWulFmQp\nhGFoh3pSx50oUfxJVERqpMWlYxuaRoBQhQhGNTX4SF9loLz8ffbemz87YHBnxV6ZsdqLFOFkA5y1\nCOdbr0xjUNrfB6+UG7aTyqCmimKGycyqH9VY22nMibeKgQm2Rgm126fIdIFe3eH2d1vgm+/WpMf+\nFUo86iyC0TRY7h/BvZDHdsxUcZEazaS2yCcL7W9ZgEH/Z1h7Ugi6U+ATpZ7adVtXn4X49TC07w2J\ntgSvNrxPFH+atNoHAHqpgjxF5hlJ3OHrvj0XbRQA9O7bTMazkSQrT3LqSac59SBtSWNvtJ0rJ/D4\nj32ap/72e5Be5LvnHno11QVDm1vLHVqeUciF2CtPmwO7YCFkiwwDqwuhJYkki65FODilHiv+0J2h\n6VoFgb3AeMt4rSfFJsncUTvtcsk0lgiDUI/iBaVqQziOu27D9NTIMoN70oKWQDv2O5RpW624+94e\nlz8FflXbtCXsvxdX+xQbXXpjw1LjAx9PnRxGwpFA7fUVrbJ+aZJabS+EWEog4UwefG0DV09Y7aRM\nH+3aqhFbeI3jdGX8zk5bB2AXEJBeQJwiV6JHPu0h4wqfBKoyLryVbzsFm3tWbVf0+hXlMm1FV1zF\nK4hDIZK0/Km3CpGnA2aX3u6B0LUc72eWTvS1nQFBGkgOUkKlZEddr0m5EQyzaR41p/ROEzR1+EVF\nunglnvNG2blyAgBJr6Yqm179CN7lrhWtlKUhu4ZMdUCcX0bKaHOfhLYHvr2p3phwbuko/ZldLVH8\nwsVhHdGJVMYiC7lnmdjCyi4vKJ8bm5BoVLiVhSfZW+F8IJ/bAy6nqbU3X8gp427jluZ0sgMfWW12\nSTZuDAjS6gQUW8r8csruZw4J/ShImiVIra+oDGjcDdXB4HajNhSnF2eKHCWd9kCzKOLUIjBdwuG9\ngC+CNScBpzd7+AJm1wXtdVTgkNiO3VCwbWqS5f46rsnGVoscDXIO72/Q31i199GNStLMsIKqaSo6\nSKk2K2sxfiiOky8dde1MJ7DFPTS2/ppeQ3LQoLxQTqyPotk0WDqrSjQRChblqSeWhO1tbpbi8yhW\n0uAJPQVvOgVtZFELvRNY7faYvHyCLwa8GXbunECoHdqQVBqEF3CN0oxCGFl4mcwaWJ827G9EQVAD\nFF0u7a7tCmkVcg1Qs+Mnp57Qs12u1whK9GyhyiKhiqF/KB1cKJDjFBeBMD8qWs6Rb1KEvZw69ziv\n7UMfgsOtjMjiSlpEO/SsslENuh1v/Lxj9zMHvPzh3XYxbLxQ4XOlf1/b6oD6poLRVQeyg6YBRyg2\nzjgbH4VDHG3KVPW7MlwytSrE4NAEN5ZPlGTPRkn3DetWrCZ161CTm0uK/QFkgaRfESLopipcuHTC\n/bubjLZscftBIKggopQDcwzDx+ecHowMgL0bu7F6SlCLPJoyHUBdG49BVDohmVroHVlJ180MtQ+p\nNQG5lRDaJgNIp/a7p1FZOJkZ/Xh2M7yicuQWrovmsPSknMCycEz0zAbzBtsaGFzb2s65nb9IINiO\nAaDzFCqJ6jL2d8HCRpS2gUg0lofCGaaZD8jSGduvqSuphYfJie38TSQReoYdSOgowmDnTKaO0sU4\nstGj26igsAvqZRV1LfSzijJKpfukJngxclBThoyjvRXjLbT9/5XJe/lCGT1tF7/3hQWUFf3D0DYG\n9e/nTG8OyKba7l75trEDeyfGmwArAaYz4lQiXqGS00QBIb7mCxBV0tMS7dlvMfn6MeFrT/PYC2/n\n/nc0O2ykUBeOMLYwIp9mRp9OAknapXAAm/0V9QWhn9p7p6uM+WkfBJKevTZfZEgacMdJu+trGkj3\nk3biM1gq4lf2PdzCtbcyRDHSdC4tNTqkNo1Ialr+d+/YyrWDu3KGD2KEQnV09OQUtF9FqfQucixH\nxkMoL2+Szl57SbF/Fzt/TiAqxgJGzKlsbHdL74wklbPilC4XQk8QlZb3HVLr5EuOvXX0EQEoUard\nkvRe+gr1WQmRL+DOvFaZ6IePzqLerJHCteq4AOXzI+qNGg3OkHEgjQ+6ir4C/Kq2KlDBLVwLGIIR\noNLT7iE9eNeA7KTP+KWCYtMegWKzh6vBVd1shdEtpRrYYm90ELITpU6F6cMGlI4ixbjcMPEOUdo+\nA6kg3/AEnzG6ZaF7fmmM33gnflkyOIjMuUsOCVGrL6L7GgepcNyj8Np+59m8z8XxjFWRUtb23unB\niGRQUe9ncLFbSDpLqLerloDk/n/23j3mvuy86/s8a+29z/W9/i7zm5tnxvbYEKd2EhITu2mDmqoF\n1DatVNFQpAqKRCtASDRSIUCVUpIWaFXU/gEFBCLQlhAQSBE3QREoUexJHCfEMbFjG3s89/ld3st5\nz3XvvdbqH8+67NeOiT0znt9vZt5Heuf3znn3OWefs/da61nP873sLG6qSszp2tiNKDDIBfwA1m2i\nrXm9KlRi0yuATBmX8TN6MFsuyY2J04lAQoGESyuYi8t6AXYXu0xjcNOK8fMqKeZ4c+MdNwnU85Zu\nE++A2mdwTZDLx/m9HkluOGuLPWxxi4YmQoS31wI0nv4oFMx47ZHaE7a2YNRRwEm/r2ydNBDtVvel\n0hchDHtW4Q56ZGswD7/dcgAAIABJREFU13TU1Udb3MlYuQLxfHYnE/3dDvjvHdkOy0887UEUvTyN\nCDwneYWfvxBo94T5c47RSSpeCttjy26v8AFAC33jc0dYFGj03pc2BDvl7kd6uj190fmzMLkI9FPJ\nRUC7VdhwNzO46J40enXJ+sl97nxolinLvvLKUbiwBbm5rHQPPgr4dcUu2n5Prm340p1riAS2m1go\nrT3y3AT2PCZmRt2yAgFzVuUJ3rZa3xAPdrD/TmQfQqmbSBfNQ+pS9/B1OXaYJYZIy07HtQdRcWpU\nWonVWmgfbZFFnbODfhqoF6rJ0M0s1bHCqL/iVvymxztuEnjqd/4Sn/+x7wBAThut1NY+D/iwtVm6\nOySPQQPV56dMltDrddLi38YSGp+VgX1VWk7BcqnQY7ZqHVbFY7sbvbYddwaXqsWWKB1O3rLUdc+u\nNYTGU0dxjNGJ0O4HunftYFP0BOzK4B/dUlWObhFT7bGeSz8tkOfFk4bpK4EXv3eWV+2Hnlmx/+xW\n7dJi6t7tWdgGqrXHrmO3IkB194LRYqyF0gN9fPE+y/GnhOmrPlu1IZpZ2F2gWmph8Ln/+Bqrd/VI\n54sgCbGoGsjdBiT+vgBfm7wab5ioKrOQt2FyUUHQDknaMtGZzAnJasPR69BX5NamuNilGXuFZifr\nOBf7/VUZ3EkfQBylmhYVmdy08AlCFbMpV/gjwapHIRRsR/KB9Fa3GvIz/5L7Ea+rMCgif1hE/pWI\nfFpE/qaIjEXkKRH5WRH5goj8rag6dBVXcRUPaLzmTEBEHgX+EPAtIYSNiPwE8APAbwf+XAjhx0Xk\n/wJ+L/AX3pCzfYPi4BNauTr71l7JKVtLGBK4Yt94dLd8Pbtjx+4xddjJYVBE335SAQK/sbnO4PrY\nx3ZgWyXWJO17PNSHW92atIUhJxurvoeRkbZ3vKB/eIUxgVXQNMTuNNUNO5tTx2AC8q41VgKTcUe3\nKnOvvbWhby3dkR7dAeungZ3FRLPNzY0p7/7bC/pZxe5Qz3tyr8c1CmQxbQRY1ZYwGzN7bs3ky3vw\n7UpKEgnYn9/DuMBYeUGsbxqaC2gPDLd/k1YW2+NedQ+7AuIJVaEAp1Q5reDVWpmLKQNze4JZWPxB\nrxRigCB0NztkawkR5Vmfq/hotSq9eom8DkyItkd6zUwH1Uq3IkkNKojWBbp9n7ODIJrp2Z3krV63\nr4qxWiAu94/pIgclXm4TeQjBBmx6PWJGGeSrtqNvZrze7UAFTESkQ92HXgb+PeC/jH//MeB/5AGb\nBI4+q5veiydr2AvqFhz3knZhoxxY7F9DNr6gM5m+CmTW3yVWYqO+OmZncJHvzoXNaEP7iKIDu3WT\nB2o2NdnvkLVVHb9YzHr1ZJ+j/TWTusuTwP4XA7f/nWiXFbcSZtbhvWE0bgnAaC9KqIUR3bJhfn2F\ni732tq2U9DIw+ewe6vjif7HPzU94Dj6nGneLp/cYn+gEIE7fx81qCDUvfu8M28H87+rgvv1hqI8N\ne887mrV+7r0vr3GTiju/aZQBO5w31GdG99upntFrii5c7mqIKx2V9nrcjvRG/Qlakweim/hINhKq\nOElLp10KX4UsoRbivt9sZZC6l4nCbgugKgnQMsBXiJO85UtYCJ1EJGsVQOomBejV+AXAnBq1Y6ul\n1HFc0j0kS47dj3g9asMvisj/BjwHbIB/ghqQnIUQ0lf0AvDo6z7LNziaU90IB1PrAE4e8+ge2mwE\nd9hndZ+EKPNjj8QCVZiqsGUI6B4VtLUQvepCNVCatYq8Eyf0dyIqbOqopx39rsqTSOgMVAFfF3ae\n78ecOOHwcMXsIVX26Mf7jF6qMR9YsDnTrKYZ94QAu22DsY4qCnbaaY+RwG5X5aLZaNQxHXWcLaaE\nhIq0ge7A8ep3WS4eV72F6W1Pu2+xm4rT9yfdbjj5YCCMeh7/x3DnQ/p9NGdw62MLdtfGbK7HIt5z\nLS9/dA5PrPCv6ucWE2hvddCZXB/BRBakVZSgPqTiHf00Fu1SzQbVDqzObYHpjjzV3VqLi5s0MagY\nSFJVBvBEpaBZ6QKIj56TIRb9kphLbHkGYVDg1QHrq4FcenRZYhIIiSbuIYjoOcd1oL3m6OeG8asG\nE9WPg0XrJh24+v6lAq9nO3AEfD/qRHQG/G3gt34Dz/99wO8DGDN9rafxmsIsdFU6+sw+J6OG+sLk\nNNCPvTrPtCbbaUknqvozyu55qt7rlMSTJgu/57CnWo0OVltOoOmurzUVTS09tx8ngGVFGJdMI2Uh\nqYvQnBq6fsxJb5ju6+R19hsC1UoxDzce1rZS7wzOGx4+WjCpOhY7HbS3Zgtur/e42I7wccBfn69Y\nbMfszTfsujipjYSNH9MfBzYhdRQMj/yjlzn7zoeY3NNz3PvVU9a3riPfccHp+w7Y+/AdAOofu4Z8\n5kts/rN/i4vH05bpkOWHtthQso4wVey92Zjsg4hAXxcSEujg62dBSVoH/YBLEZCV0dU/PX1rs5b/\ncBCHKAyawo0oAqGJvr3Tbkg/DbhQCnntvmL8TSuXiFSp9x/KDk4LwaLnD5oJuEbbhFl5OXY61k/0\neXGoTw3ju4LdBvb/5jPcr3g9hcF/H/hSCOFOCKED/i7wbwOHIpIml8eAX1M6NYTwl0II3xlC+M6a\n0a91yFVcxVW8CfF6agLPAd8tIlN0O/B9wM8D/xz4z4Ef5wEzH0mRxCwP/nXL6uERuxsFs06llOEw\ndYXim3WjJct++5FXTL8bKMn0gnlsTXcxQgYrnTh15pG+GG6yqmDk1bwjG4Bqgc/sTN4bu2kUHw2S\nU/dw3NHuC5yNmR7q/r0eOzZdjfOG49GaTXQRan3F4XiDNZ7FVifbs82Y5XrMdNyyP9Xs4mQxoxr3\njCctS6OZ2WJaMfroLVwN+ycRoPTlF7n2K0e8+L4R5iHP8stKB37vS1tkrOYuac97/rQhbCr63mdf\nR7Oo8DOnIJuYZvdzH8Vdygob0mdvQimcgroUe3S7lrz/WiXvCGSxT9OJEpkkDPgNATeJbsFxV5YL\nkj5tScrzTaeEqVSsNJ2U7CMlHFGIZCi+0k8CzZmh9+U4EaFeS3S20sfciLjduY9VQV5fTeBnReTv\nAL8A9MAvorZi/wD4cRH5kfjYX3kjTvSNDF/rTXXyLSO2T7ZaZIpV8hDlq8SGkoIGCLMeWhXxBHTA\nH7a4nc17etlZuvORVu7HPkNLVeM/MgOT3p0XQq/FpARA6vb15vEN+o0CbhYBJ72wuauDU6Y944MW\nkcDJWu/mb3voRdZ9g5HAfr3FT9M+WJjZll1fsT/WXHjbVzx5/YSXL/ZY7XRzO5vs2OwatpuGOn4X\nnRMu3lVTX8Dp+/S4m4v3gMDoS2O6Pc/0hchCbBz3fvv7WT9SUvBdovp2pti8p729ISv2hCoQ+qjI\nlMRZ65LWKy4gHtsIYa+jqj0+dgdsEnV1hcmXINxBihmqbaMBjCEjKn0TIp5AMhsQFO4MMLprsgaA\n+FjMlAEGRMhio5ks5NXWLDC0YQuEWj93GHRA+kmgup+tAV6/+cgPAz/8FQ9/Efjw63ndb3aYLjHF\nQqQOg6/j8tUrKzBsbC74hYGoBSY+d+rwp412FdJcMdaqtXjROkJ6vFELM3taDfaigrNCGDtCupnT\nCiUDXv1GJcfUXTe+4KLGNT3jcU8X9/TrvmFa6eh7dnmMSQxG8bTOcjRe8+p6T99HAiKBvfGOttfn\nX6wjuMgJPr4mXtQMxRZthbsfmukgWkK1NPSxnHP+7oZuT/BVcfy1Cxul2Yo+oq9VSVkCeaKTSkE6\nkr5/0L2/04Ks3FKbMT1Yf/plnQFe3kYH4Y3Nq6wfaWsvrcR6XIJ2l85EFhoF8GRhULWCJ0uFwxAM\nxqU6gW21k9HNYxbR6jn6Ucici2BDBi/la9uTJ5D7Ge84xCCA+elfBGDv4MOsHrV0e4Hqni4hic5q\nL2xZVSoVvBzeUXLS0JwbXBNy6j56oVJvu6jNl9R4pBedUFqTL7jbd9R7OwhCn9yMmoBdmkLKIa4+\nlS++iSiuvls2WBuYT3R1f3F5wEPTJdOq5fp4mZ9/1k6V9upgZHXUbfuKxjquTda8cK5bI2s9zhmM\nDfhIibUr7XIEUwbK9lhX22qj6Mk00fUTTb/tRsrWyuvvwfqsMWDGvRK3vGRtBd+q3ZmvA/1hzBga\n1e5DAmyrohN40OKXtZJ9BrZjZqWt1ZRp2K3JFmgJHdiPFPKnxqLxeVFN2LQxrU+TUOxY9POSHSjs\nWL+PrAIksQ0pUhCQQbMCuyvtwOCT9mTIX5qrVY8i4RjuV1xRia/iKt7h8Y7MBFKIDzz6Ux2n72sY\nn+gKNL7neeUjDdsnduotiLL1zNooTiDrAWobyY99JgB1++pwiw1ZSVgPBtlpmzGtXtWZpQtoL3m/\n7J3dQy0mKdkAVeWgV2Rgf56UawXGnu1ixGSkW4BJ7dm6iso4Rrbn3k6BRYbAvN4xsV3eDhgJ9N5w\nup0wbaLYR9NxupzSRqyCnnfIGPqE/KgvtI7hvK5gaTXv9sgeCi5to1L2ZAKyivyKrqZaWqXgxq/I\nN/pdhlHpq+NEgVkpVU8Fw/MGuzb4qYch0WnQy4dYILRB999JEq5Tt6BgQ87yXCYOqTRbSvY2NwIk\n9fKB+AwDenA6d+lVau1SsdBpVuFSIdhE63Mp2Yp0gt2putD9jHf0JPDyRyrax1rsiafd07tn/VAD\nHpoXG7qYmpo23nRV0ZF3B1F4tJWiYbcf8QUC/mggINppWigBbEy1+71YOHRyKQUNnWH/eMkocuXv\nnu7h1hXSeMyeDtikiCTAJhb2rs3WrLuGk82Uo/EGH/cdnbNUxrHua+Z1NOYwnp2rOBhtuWhLe9an\nQqYtnQnT6jYkpbXJPKWbK1IysekIxXEp99A9mHXKh/WfamkYnQi748FAnLkInQ1IklEaFt5ao1qL\nxL21145A9nCIuAw39bl7I16LsYnMpcepE7NpJaNAVQBW33N7Y9hJiLZwTVBMCFE3slL8R9iWSSeM\nlKrthyyZELcJqcA7Aj+NJK+4fbSdYFoYnd7f7cA7ehKwv/ECzpQNt34iwlLHTpmEJhR2YI1evKqI\nTrAzuYgUsntxzBacYE/qAc03ctDrAos1G2WeSS8ZlBSiiu2uq/IksDff0E8NbVthI/81BGG7HDGa\ntbionLzuaqZ1R+ss1nhGsYB5sp7gwx6tszQ2avdLwAdh1TZMap1Y7i5nTMctfVfhIvgJEzkJQrYE\nJ2kWBrLXQf4+d3pTJ2fg7PHuJe+hjRPWj8RVP32XNhAax+i5UZZvc/s+e0Wy1+X3kEX0GDQhn1O1\nEnU2Hoi+SGJzmsJMdOOkmRguQb2R4uXQxU5AqAPV2hA2pY0YjP5Ui8sitEnEJdsxDFuGfUEmSntZ\n1qw/dOx92TK982YrCFyOd/Qk4L1o229SZnvZGLUnW9uiN9fF1WLks4GIXWovP1tQEyvJW8W0281A\nbThKaUsvxcHI6koF5FTb9kax8qf7vHJNW3/Tow3trub60UXGCVyfrlgdNDhvOBxr/+uwWfP88ohZ\n03K+G+O8iceuubOasd42hdBkPbPJDmsCL949BFTB6HwxxXcGmUZMwLLSTkdfVjm7QycFdUbPLk2p\nyu4mBSXX7Xl8lYqIqeoe8BPNarKrUGthZ9k91F+2B9spNyN0Jrdb1RREMJ0ZVPJjVT8NPiLEtxfl\nEKTMJjpAJfEX0MEu2+gqJKWF6RuPdFZVp/IWIxLBRNGAEMVWAozvmow96OceN9UuSV40fBRT7SEc\nxYxuWTN71TP++z/3a92eb1pcTQIG9QCIxKAw8sUKa+Di40WzgQwWgcgHKK9nurISBVOESmyrbSyJ\ne0/QFpbd6uvJ4DUD8UaPLcn12YT9aysORlsenermsQuG37j/ChvXsB/tfna+op9aPvnC4zRNz8FE\nl97aOlabEcYE+siwoxeqh5w+FmXMum2lJJytzQOhWiowB683fwq7i31vKf38IHqMabnE2jMh0E+K\nPZrdb2HRYCsHNm1ZIjZjQGoya4vdCd01h6wszVmEWzcxVZ+XL955o/gCV1J722qWMsxWklqQkohM\nubaNGs4m5iBAqOLevZdL25ukTpw6Dt2hpz4z0apNz70+V/i3mw48D30CFQlhlfgWhunf/Tj3O666\nA1dxFe/weEdnArqUFSAHALGQZXYFnJPQZNKVApl4CHFVSgi5ai2xoBTRYXGV7Ee6wngTCsEFcGMf\n5cX0/32SHmsl73fDRCv3+82Ww1rpZ/Nqx0h65nbHvU67AD4Ylv2I8ahjs2l4JYJ/wjV4+GjBnYtZ\ncfYFNhdjJntbbCy4uXsjVT+aubw1cpGBV6+lyGl5yVr70pUeOqJpc7dfimt+FPDz6A6U0uzOYPdb\nDuZb7iZ36GjWyarSQiS6z+8ilXv2nC04hZuBIBGgZUsWkr6vXNiLdQso1yfVYJKTcPqufRUyEjB7\nOybiUGBQ3AsZLZjARmYT4cm+XFc/UsdpKPBvu4uAqJ4Coe5KdnU/4x09CfSdogJlaGYZFPThxuWG\nSoYaA/o9iN5cwZYUPyTZK9Ab0JfUVA07ivlIP4kptS3tLdvp3nlYzIKKe+M5k7qjyXY/C+75ORPb\nsokonHu7KYfNmperfZbO4GN786XlNZrDHfuzLetUEZ/0iAl0AwVfOWpxyxqJ9Yz8eNBJLZ2jOHBW\nC28YspBmsMQJlfwdKFgmIij3tZ/n4nZjsRrnTsvs+prV3Slh5LOjsd9Zwl7P9PMjxvcCF0/Gx2N1\nXluwcaKsQ0YCJjv5aiUR8CNF7NNpnSYpDEO8zr2iFV0dBtuBONibskCYXjLkNz1fBWjJSMb0HaWJ\nIG2t+rljfLvS80tUk/Hwhrp/8Y6eBPCSB2qxAhdC0IJUaXmZfEOE4QZKdO9frQqvNIi21uzGlKqy\naJEsWOgi2Sg5Eokn8+J9ry7H/V4onoc20O8sr5zt50mg9ZZKPN9+cJdVFN87aLa4IBxONty7u0d1\nFi3LV8JuZ7i4FZhfVz2C5dkEdlZb8jETkKitWK1NsUucBKpN9OmLA8luJK+Y1WqA1ffa8vMjfwnJ\nF+qAWQsu7oOlNfjW0Noqv3ffG2TsIED9nH4e2woHP9MwWni6qVyabCS2+LIl3DYVL3VvDzqZ1kvJ\ntQEgIwirTclsEK3qhyDUy4LeM20s+MpAbShOzvVikL1F9KFx6mgNpZbUHYQsLCOdoT3w2J1w/ZN6\nvxx8YcODEO/oSUCsJxhD+Ipvwc+cztYJ3jlzCqE1hTGY24E7oz1/NCWt1oLvdJsxTP2JkNQsXjLS\n1SyMSqtLCTS6yqZth2mFcFaz9cKX+msAPH7jlBuTJf/4lQ8wi71/HwQjgS++fB17u8kpcL0E6S1t\nN8M/Eu24bCCMIktyUPw0W/NVMlf9nsdsSsEtpdlJ9Sd9RrtVnEBS2dFjNcsKA3x8ep9k1w6waw0y\n6xl9cczNTyZCATQLraKfPznO7EBIq/vgOvaiEO0hstsqGatawfZ6GcRurBDwIiha4L79ZJCiR2yE\n6S/rBIB+7tQGTfLjxpUOSHer0yLl1hS4cy/4mWP/X9dc/wefB2D9XU8+ECT6q8LgVVzFOzze2ZnA\ncApMUM7GEdYVdmUuAWSylNVgcZfIHgtxmbNbdRquE2HFpufr3j9URZ8wTBwQjTET8s1Ad9Qju4F+\n3txrMcIJNj7/5bN9OmepreP5M+3z994wrnuq2mEH6Wq1UqtwccJ8phvZbRvJUmNLdxrXorGnPt6w\nOx/nbIVeMBu5RCDyFTQLTZv9gBsfbKDaCrs9T30WMwEnSpVdCl2UMZedWq/j9T0B6ldrjp6xmM5n\nFx677jC7HjdtNCVP378NhK25tAdP/g3D62N2QjfXPf8lk9XaE7zJDEa7UzRfqBTUlLM3H+XklqaQ\nmmzAXljaA1/wCFVsk65NuYeirX21NvTTct/I2HH+YcfR554AYPLcxcBm5v7FO3oSeM/v+kU+95e/\nS/8nae3dbTBOEX4uO8oqHVZayQIjfhJhxNtyh7lJHCRxEEhyJUYQdCBnARIv6mxryMUwUICM2ZkM\naxUnel9LYHtX0SjVQcvJakrfl1lMBFoJzCY7FkdTZs/r3zY31Ryzv9FmiLExHms9fWcx+zqKp7Md\nXWeRkctaedVFRRXT/KyV72F7wxFmjs6EYulug8J7x44u3VYuintMlHsBcTslQU846e43gX4iHL7Q\nMfr8K/rUW0f0h2PsWo1Sc1U2xGtlfDmnCMpJdm+gAzPVYXKBt1e8hh/rNhCg8optcJaMboxfd4Yd\np4nFrgyjU2F7Y/A+o2hQ2oTcKfGnTZ7EExoUp+Cr0fUNp+9VDscjn1leTQIPRASi2UgZiL65bNGd\noL0qDBFn+1aQTaWPpX3xyuR9vR90CoyDvtFVKG8sbUAaT9hUmLkORL+qAOXG21hs9HVQQo8hP7c/\na6hv9jRNnwlAoHWBR+YLfulwj+5UB/z2Vo873jIygUeOFGx0thljBGTSUkUo8WaniMKwrLCR7DPk\n4vf7ZTWsDlr25htWm9ElKLNI0Ilp3OfzcdtKef4JNtwKPqhGQiIq+VFg8ZTg7YhHvqRZitl0yM5h\n7p7SffDdzG5oe3T1ykxX4d5ke3Ak4KbaOkwtRrvWbEF2BUXY7YU8kafJOBhbOP0D1emcBXrBLkuN\nw9cK8smiJ0stjtpexUT13BXNGCIfAqBeG9oJ9F3F+pF0DzwYu/FfdxIQkb8K/EfA7RDCt8bHjoG/\nBTwJPAv8jhDCqSj74/9AvQfWwO8OIfzCN+fU35iwC4s7cBnCmy6un3nsIikLx2LSzuTj3MTrCiMC\nu1RAVIIIPhbNUgXaK7y2vYbqAgDBeEKvqkQ+raaJwCODLoTV5wQTIHYw6r0WY3QTkoRCx01HbTyb\nvqaetex+g96QH3hMV9ax7TiodSR2M8NZO+VkM83iIyd391TotDPUF+Wm76eBfs8xvq5Fxa6zPHr9\njJ2zvOvgjJOtqookIdPj+ZqLKGNmJLAyDb2pccmmvDM6SAjUU61edlLTV5b+pOLsux4GYP9XzzHn\n2s24eDccRwTkuk8qHWSp9kR0EgqCM8Qipd0MKv556wJV9AU0XSzGdsmtKK7mtf5NGGAPYp9fJ3ku\nv2YFdhndoI46zLJS34T4WLenWyB/1kBsY/r5myuw+7Xi65mK/hpfrSL8R4F/FkJ4Gvhn8f8Bfhvw\ndPz5fTxgfgNXcRVX8dXx62YCIYSfEpEnv+Lh7wd+S/z9x4B/AfyR+PhfDyEE4BkRORSRh0MIL79R\nJ/xGx41Pwt1vqy6RhRJ91EWih1lWmK2uKskTz26NCmFOVNZKn6yrZ7BSik2glNtGU80kT06vPoaM\n/CUHIiwZsZfPxwQlzMw0za5qx+F0Q4AsD7ZYjxk3HRfbEU/cOGXZ6nZgXu84qDfc2c7pYnqxdTU+\nCPcuZlmZiK1FvPbAu2hm6mM7jcZnj7/RuOV8M+Z4tqb1lk2n6XtlPc4Lk7rLzMTz7ZjZpGUtZGtx\nH1DrchNUch0Qo6n88ukOE4uW9cWc2dmSs3/3Kd7z0S9zutV6SGh0+2VXJvMHzMbi93rwgokrrx/7\nSI02l/FbY7WMz1oGEedQRZ2BfH135e9pa+hrxSH0kzBoF6rbUKgoJjVOqM8N7bHL9vTVysR2q8nZ\nQ3djymDXed/itdYEHhoM7FeAh+LvjwLPD45L5iMP7CQwPnXsf7Fi8e6YWg5QXHlwBxWc9A0kGmG/\np4U+urI3lc6ok07a+qcbxcU01UmhH9cRJxBMTvPpUZXjjb0kkiFBU9XcAree2jqujVd8+fwY0EHY\nORUfmVUtv+2hfwXAZ1YPc283i/Rh/Yznuwm1dTx0cMErZ3vx3BVh58alV+5mHjNXtl8z0jt3u2no\nKkddOba2yjWFtrc0lcMHYRsnJue1TtA0fZ4E7MSp45MXFXUFLRAGAQcXT+vr9dMa8Q9x+z/d8mi9\n4zNfUA8be2Fx+72KtiYS0FGrGpBD1F5bBluq0JtWi7uJBAQ62E0XGX6BLPpKILsmJ3ozKNVYCVTl\nHvKNbvf6/fjeO8VBiCsaCwlYVq8kYzja/YoJ9z9ed2EwhBBEhiWkry/up/nIMNxIaBaBye24Sl4v\nCLPRvSQmAdUm4EZCNy+gGV8HXF32+Yml1s9UnLJe6OP1Qtje9NilLeCaC6O/Ny6rFeHALK2uwKno\nvtOb1telct11llXbcLKa0lQ6aEZ1z3rX0LaWV9dzfnmkg8YFofUVF+2IvUaXt1m9Y+tqbi/mNI1m\nF61V5F14eEvXJgURgbuqnuwnOqKakR5/PFmzcxWrmHE0laN3lto4bm903x6C0HU2vwdoJrFeVTHD\nSUAak6XW/V48n33Ds99vmI07PvGrT2FSsdKrnqCfF5n4sKm0U9OZogI09rgphJUtCEYhW4lnBLZw\nqe2bYMcSIlDLFsi06SUDuYoqUsjOxqkDksRnlYJeXrtyFumGWcZbmzvwakrzReRh4HZ8/EXg8cFx\n/0bzEVSinH05vm8g6mAE0weaRSzWVEJ7CJNXhP3n4yo3Nyye0rZhc6bPm70I22uGYIt4aKKLdjMY\nn0AfBUM3t7x2DapELEEH1lQ7BDLS9/GrGhfFRpNtNcSbrgnZDHUXGk57y2M3TrOXQG0CIcCtowtq\n67K8WCWOSjRrGEeh0ZfX+xlpePFKzAQ8uOOOR6+fc/tfamLXHTqqh9eZlATQn4yZ3FryuRceoh71\nmYo839vig/D86SF91C1omj7TmpMPYtdWyMhh5h1uoa8Zxk4zA1c+o5tpW3Z1Z5rh2AD9YQ+RNpzD\npPakh5hxyMYSRh4/GUyyoQxuiVmC0rsjldiEbIMmbURFuoE1ORHVKQNE505f19dl+5f4IYlDkJ97\n1GG6hvE98nf+IMRr7VH8JGosApcNRn4S+K9E47uB8we5HnAVV3EVX1+L8G+iRcDrIvIC6jPwp4Gf\nEJHfC3wZ+B3rHbw9AAAgAElEQVTx8H+Itge/gLYIf8834Zzf0Jj+vZ/Vf7/n2wBYPTrGuIDpA/d+\no349KiCqhJWEQxcPsxeF2QseN9KZv91X0okZqe15jsgbwED7UCSUpP3susq/iwkqld2EjGjztaab\nwZOBJ/Zeja9qnvPHJEk+zXOFO95wOF/nlb4ynnXf4IPw2Tu6wretxXUWv63K3nhl8H3NyRduIUkC\n2wSCF1brESbKlX3wW5/l0y9qG08kEOJqvgT8pqKad7l+YCTQ9ZYXXzpmHF2Sbx5dsNo1nJ/OCrpv\n5JT1KOQ+P+hnFgy4AWahNZoxDLgE+GgeEk1EgCzqai/sJd5CYhvm9zARuzBSsI915Vg/CuAHNZJJ\nyI5Dw9Q1WF31s7y4IUvRZ4ejXug7Q3vkGJ1EUZHzwT1yH+Pr6Q78zq/xp+/7NY4NwB94vSd1XyKO\npv3PXbB6as7pe6ssqpnsscK05G/eBi7eG7j4tk7lrwB6o/vCyEPPN2QV7bQGmvNmp2o41aJUqvsD\nr4ZuoeAVQKvO0ppclPTjSId9fox7TPvnfl2z99ASAa5N1qy6SDHeTFlsxogE6niH98Zgxz0t4CN7\nyt3qYVWxu+Ezg9FeWNx6gj/oMLFg+isvP8TB3preWRZ35sUF2Kor8HBwbDYN3ptLtOVNV7HrKkIY\nqPtMBWqPrG3+LsQDVci1kwTICo1HOkMwvuAqKk9AyTp+MtiEC7h5Af4ktp9ek/jUtU7cSfYtdQeS\nJJyNWpB6zVTjYKgDkHQHbUvZSkQ1pmojhfgU4eF2ZWkP9LF2v3og0HoPwjk8EFEtdDBdPL3PxWOW\n3XW16ga0yNMX9BcoYpAgyElDSNZkNigSLWLMi/CkIsjM0pbVL3YL3HhQeNqY7FmYVHORSDsuc0Dh\nqDeBEHUD5jdXjOue3qmUeB1X7vWuobYuFw4Bbh1esD/a8spyL08Mp8spXeNwnSEs6vzeZidUtxu6\nIz2f6bU154uZDuKlLSIcsw6/qXAXNV187+50hHQGOd5lQNTJywdaA+kM/jCV7w3mosodE4jfd1QQ\nxpT9tmz1u5Rt+S7prCI5bWnBholHNqplkCG8ein0O03io01p9/m66CNWGyG0WidIU78fBapVNCvp\ny2N2m0RnUrUwZg89hFTzlqK8nBaHfjxISe5jXE0CMTaPaEV79ZClm0F/q4Xc/w/gtO2TG7sWQEUq\ns3VWFVQ1plcoabpRzE7bVaEq9604FSpJPHiI7cDhBIC+RjcLmI3RijioeIfov0RtRCMBazx7ox3v\nmp+yc3ppb04vWHYj3j2/x6dOHgHUrvzedsZiNcbEanpVOXbbmsl8x27gO+A2FexMxi6s702RxjM/\nXLP78jiTn9p5hZ13+Dtj+lGcRMZeSUgvj/NnNA5cQAt7icFlgxblKj+YOHWFTtX7rPdYh4jH8Jno\nFEb6PngyrJvY8pSu0J2TWpBpS6aVVnVvNY1J3QVf6/GmG6gq9do5Mv1ACCZyK9w45IklXXvVL4gf\nJxZ364vSMbifduTDeDDAy1dxFVdx3+IqE4jR7RWPATcO2XsAIoKv0pUq4dUlKgsreyyuSF736qEe\nSFsTlYZODV5KgSvtTwNlf2r62DOvQvbuYyMZ157zUhuwk54QSt/eB+GJ/VMa0zOxHTOrS9BhvWbn\nK3UrHumWZ9GO6b1h1Oj2AWDadFT7HpHANrYDbxwtaeeW01f2i+Jua7Dzjr3xDrktTG/rSd17ekd3\nMqa5EDoi6m8TqdamuPP2s4iXqIA+fhmHHaEx2vpLEYKu7o1XslBiEVbqZhTGIT8mrYlFv8trmtkW\nncD8WB+vQbo2o8iQjHTpoVGJj8XFoUJUWtlT668+F60nbUvLz7a6ZeunJTsQpwSyamV59M98jAcp\nriaBGPOf0NRs+Yc/Cgaq8wLs8ROvdNXWXurt+lFM0yeJkRbApMJfMaOso9243ZbU3zWRXXjoaSIo\nKWnguapsJfpDFf70jdYZAPzNFu+Eqna54Ha8t2Lb1zy+d8pBteEiuprW4tjEitW753cB+Mz5LbZ9\nxcFkyzLWCRrr2LQ1y4sx07lW8id1x3I7Uhmw2GsPI4+tHC/fPuSpT+9o9/UW6u9NqC4M/TzkIpuJ\nWn4SinPR6MSyvdmrVXsybD2v42CXUvU3ARl7ws5eKqjiI+rSBEjbqN5EsJAttYNOdHL1MMQN263Q\nzbXbA5TiYxVNUdOIsHp9fF2EUyX+R12Z46Q2DRmpmBCGdi1FlzG+t5sEzMpeMpt9UOJqEviK6Kbg\nrWYDyVjD7yz9gcPsdbjUCdjozZmKR0AsCOrNJ5B96PwoRE3ByytDPw3UJ6a0lmyhMKebUVtcQZ1r\nYgfDvjxS2+u9nnqmS5OgPIGdrziwG1xcuq/XF/pYteGLm+sA1MZhY7cggT2NBCrrGE06rs2Utjup\nOg6mG1bn40ExI9BuappJx70P7HH4+VjccwY/LkUyAEnIuIqszpuQgVBYd34cwT9D/M/E4bdVFlTJ\nET0KZW0JqUbSKP8iDDMJQ3Epig+7qUd8LCymybzV8zWd0EdtSCi+BfhyLQSd3IWSvWX48CDjCFVB\nG1YDdmqoA+/6kw9WFgBXk8BXxeM/+jGe/ZGP4F25+NVKqDYV/sTmx4INuKMeuxP8AADu5p5qYRi6\n4diksxcK9bSflBUkpf4xg2do20VA9fRcKSi5cYDDFrwwGesLHk/WPD27zaIf8/nNTd4/jRRi6fju\n+Rf4YnuTL17oJLBs1b3odDVhHPUIOm/oXCL56KC7s9JiqR057FSPc87gzhv6Ssk2xiXchOD3eqSv\nstVWsEK1Ggh+EFtysTqfPrd0QFW6HoBOAHYwOaSJwMbC4NiXx4J2a8JAGVg6VXnyo4FacCeXOB2g\n5yGuKCq7RAIKhtGZ0O2FomC8Tv3LkNWkEgx5uOXRN9NzzoakqZD7AMbVJPA1ws9dNuj0jdGbdlJW\ncjdRiGt36DIByCwqzE5bUll0M0a9kAw5BVQVt4sw1rSYJp9CV1bOFGmPCtouk4saqpDhvBzBq+0+\nT03u8Pz2mHHExc7Mjlf6Q077GUcjXeEvdiNCEA5nm8xCBDicbHnx9iEvvHoTgNHNNe86PuV8OS4s\nwJ1i8YOHbl7OL6TBOWiVubnXSfHcqqQYELb2knUbxOM9hHG4XPF3gtSesLbI1OXnZ7eiZqjSFMp5\nAFhlK4or7D67LBwPHzMgNw6M7pm8TaiSuewk0AYY3ylbBP03TQjxMZQk5UPpNKgdm3Yb0rau2hge\n/1MPXhYAV92Bq7iKd3xcZQK/RrhJUFRapAj7kadaKr03LWBmE3P5IEh0LzYtmTKq5JPBa45Uwz8j\n4uLK3g81p4NuCdy4PDdUkVFoB9LkddACWOU52Cva9XvVFh8MH5o9Tx1hf1Oz456bc95PWHb6ZpXx\nrHbqSLyLZB9rPF4C146XHEVp8mXX8MLZAVUVxTkB7+MK7IX20JOcd+bPWpbvBj8b6ivoyu7GgeZu\nLCyaKL1mS6tEXOzpx39BOzIqCho/c3rNSkFBodcsAVCFphgyAAZJH7EXA8HY4PVxkzQlHfTzQH0u\njO9KKe4h0S8CDr6gTz97f8jXJtiUJSqq0Az0zkuNp2z1hnTkBy2uJoFfI97zg8/wuT//4fz/4tUQ\nBMj7OvFKLU3MQbjcXhI/KBiikNJ+YFIaqlIILEYjAFpQSoKmwVL2wTHVNVuDH3nMqMwylTh6b7jd\n7jE1LdugLMLn2usYAg8359xulDF4vhtzNN1wup4wH2v1zkpg01WEIGx67SacrbTYsT/dsqn0scW2\n0sFtVHBk+Zje5T5V4p0UIxch4vrLdxsM2bj1knMTXDIkDXVERHUgA60+PGqaWgXCOpEp4qQ9tIgK\nCtiSQWMhvb86FqeLC4SYvoswvqMHt/taGHSToJwQ4NbHPafvt6wf73NhUDqBqZrFpK6IbyCgvIF0\nT7znBx8MYNCvFVeTwNcIuzGlKhw0G7Brk4testa2kunlUr0n9aGDCaUdZIIOhtheAh3Q6bgQs4FQ\nBUIjmO3AIQcUyRYngnQcNuA7SxtXwYtuTBcs1+oVJ/2MvVhZfGp0h89sHuGsm9LHNx9XPYutTgR3\nL3Sy2CzGTPa3dG2VLdBn45baOi62owwvnh+tWS3GJL78+iE9dv0tW4IX7Eld6LMuIiXNAJPfqNaC\nn4RLYiyJe59hyBEKbNY64EXSAPOlRZgGd5pwB61EaQfdFl+OA6iSFTkUK7kK3H7I9uLVWhidQjcr\nalKba4ZHfmrN4qkJJx+ILzlWkpVQdCj0+oLdwBM/dP9dh3+9uJoEvkYEczklzzFgmdm4PcgrXSyM\n+ZpLhS/fRPhoEEansWg21lRxdFFWMNekYyUXC1XyWnB1KISktLyFQBuFRlNl/6H6nLUf0cUl6HPb\nW1yvL1j0YxatzkrrruY4kowmI21JbGTEuOl49Oick7WOhDTwQxCOp7pFePbVa5hKtQvCAHePgEQe\ng9mUUpPdxVU2rfBTh0sGpem5cZLzo1BUlnN71Ufln3isieAtCdohIGYQNk60SZGpDnnw2yj2kdh+\n3oavyL7i+XvydqTbC4RKqC/KxNTNhfP3Trj2i2f0E/V7OH9/nKC7oiJkeu3uZIu2BzyuCoNXcRXv\n8LjKBL5GvPcPP8Pn/qIak8hO01U/LqtL5pTLYDVBpcgT6zBlEmanhpmmg91xLDbW+iISTF4RTa+r\niBuXtNZHx13pisMtkTHHzmQB0N4bfDC80B5zUK2Zx+3A3G6ztmBSFlpKwCOMqp6TpdLc9o/W3Jit\nGFU9vdPeXytQRUDR8/d05RPjqWyg3VZRGzB+Hyao9foYpfmixKlurH36vC8PIBNHcIKNpql+FHJh\nMPf0dwNiVaqLEFf9URRczKQiJROFiUNWZdU3ESiUspVqpdTeoZM0QBVrq+Ivty6Dhc3Nku3YjXB6\nE8QdcvPn1MNhd3zI9rqPhCPyNbMb4fH/4cFsCX5l/LqZgIj8VRG5LSKfHjz2v4rIZ0XkUyLy90Tk\ncPC3HxKRL4jIr4rIf/jNOvE3IySy50ITIvgD/dfoHjLUIReagikpLH4wYFGl2Xop0YpMfyToDa36\ngXpT9rMQ01B9Ld0/l0GRBom0RuW0BLwTvBNq61i5ho2rud3uc7vTny5YXu322a+2tN7Sesu6rdl0\nNbu+4ni+5ni+Zj7ecbqd0DoVDG0qhRGDdhNcb3GDKvxk1qrtWqc4B7+uclovfXQJHvn4/8BBpz8C\nrPRYd9jjDnstJpqQn59+qLTL4seq2a/sySISKtEngThJ0in6Uouteg52Fwd20G2AjXwGvQCKHMxy\nYRHglcBDSdAlvbcbB+xOOPkA7G5O2d2ccvPnd2rBXqk0WagV4/H4j7w1JgD4+rYDf42v9h34p8C3\nhhA+CHwO+CEAEfkW4AeAD8Tn/HkReRBUlV9TPP2Hfpan/9DPxsJe3GfGGypXnUXtp92ei3BUrYbb\ntaE51x+7g/ZQabLVhVBFOqm4qHcXzUoI5BvftIUHP9x3FwFLgdpjK/1ZbEdsXM2inzAyPbU4anEs\n3ZjjasXOV3Te0nnLpOnovVERUmdpnaVzFmt8LgoCTKKhyXzUYqzXn6hluFk1uFu7PIHZRbnMIUJk\nicQct+8IrSG0KvwRooCILCv9cWTFH0kqQQn8U2udIA1q6Yzy9bcmT0B2rRO12RjsRqXhbaYN60Rg\nd9ExuokArV60qFuHATxYKcFuHNRKLpCfV631O7c7vQYvfU/NS99TM7q94tYzLsrRq4X7oBnxlohf\ndxIIIfwUcPIVj/2TEEJqsjyDCoqC+g78eAhhF0L4Eioz9mHe6tELYewv8fwJUZYqbRHiIA4SV20P\n1Up/xEG91LS/nwVVI443JwzaVp2olZmUFcnElczN/eX3sQE6Q7+q6Vc1m11D6yx9MJx10zwJuGAy\nmeiDhy/ywcMXeWh6wXI74nw1YbEas1iN6Z3hLG4NRlXPqOpZbkbcW05pncWYgDEB70V/ekPVuDwx\nBQtMnE5OcZWl9jByyNjlydNsDfXditE9y+jUMDo1OcMxW8mf0a5MNHyNmVActBJ0wgiDS5EKsXYr\n5XxioW+YqfUzXflNp7LfptUtgt1KPuX0Pv1Uj/X18Pro61YboT0ItAeBl3/LMbNnvsTxr2jWZjrh\nqT/64HcEhvFGFAb/a+Afxd+/lu/AVVzFVTyg8boKgyLyx1FJzP/nNTz3gfAd+Hrifb//5/jcX/qu\nS20n3atqCjpkr5mdYBzs/2tolnrw2XuN2ln7Il+V+AXiuZw+erCurHSpgKVsuNL+MluDn7pMotlt\nal5aHtAcOAyBuxHYPzI9O1+xcqOsNvTs2TGrO1PsXkcVfQt6b6jrXqXJYmvwxv6SzhsuNuNcgPS9\nYKrA/tEaI4HWKs5g+pJhdRx7/2nPPvKEnaE6qYq1eWJJNgPgVNxm2U0RCnXjApAKIllBSTpRave2\nyLInZqL0XMJm1LH9WoxGolX6RjJi0PTRMyBSv7NGgVdZctOr27Re29IuTH6Ni/d45t/7bvZ//BPs\n/78DiOhbKF7zJCAivxs1Kv2+KDAKb0Hfga87IrAnyYuFaEThR37AYTc0Z8LhFxyTOx0vf0TvyM1D\nXvevrQwoqAPwT3wLN1EufkpjQVNa38RqeSIYbbVvbtZWJwLAL2vORhPaueXWeMsqIlymtmVulWL8\n+dUNAE7v7CG9wd8Zs4vovn6/ZTrd0VhHGzEHtipquMmuXGJNYNJ0bNo6n+e1T3cgY3bHCsEFsLuK\n3TXdY2cDEMpEkJV4OwETC6TJLbgK4ER7/IEM05WgQK3kGgS6Dej3dbuW2Je+iZbj44LzsCvdXvTT\ngu3om1jvqcrghwQNBlcVvEgyKaUnm5tVK7jz7cLs77w1JwB4jdsBEfmtwH8P/CchhPXgTz8J/ICI\njETkKdSY9Ode/2ne/3jff/MJ3bduoqtuFKwEtGVXB8a3DY/98yWzF7csnhixveHZ3vC5qKS01nhT\npSKfK1tou5FMV602oitW3LeaXrBLg12anEH46IMoG1VB2l2MeGl5wEubA2Z2x8zuMMR2oOnZdNoV\nsJMe5p1OTPHz+JMRq4sxt8/mWOOVSxAE5w2bdUPwoojASkVFOmfwQXK3w7Y60UkHm4cdm4cd60d9\n0U2MRbxqqTUD0w06ID2K5jMxk9pptd9udI/vph4/0h839ti1TgBpD64FV6MV/UYnTfHKBDSttieD\nqBnM+CSCkOJ7243QXGgG4ivysRnZach1inql18z05BpHtbrcVnwrxmv1HfghYAT80wjnfCaE8N+G\nEP6ViPwE8CvoNuEPhBDeulPkV8TTf/Bn+fz/8d36P6LGowjYc13aHvmZLcEadscNm4ck6wOoLx2X\n+uo+Co/4iiyDbbuBIs0gEr8geQyYCyXlmE2R6KYKyLLizr09KlOAzHvVjuNmxZfXx9ky3HcGzmuC\nhb0v6t3eHsI2NHRTxypqFMxGLWcXE12Jd/oZxwcb9sc75s2Olxb7uTd++ztGLN/dU10U269kyzbk\n8PezQL00dHOfP6evy2PD5xoH/Sjak8UMobrQNqD4Aq02rWZlYso2KukEhEonVNAtxu5ImD8fWLw7\nXocRhE4JXkPqb5Ci75Bgw92eTnKhIiMOJcCTf+KtVQj8ynitvgN/5d9w/I8CP/p6TuoqruIq3ry4\nQgx+o5F4BH1MM6vAjY/rSjN67oTtk9c4fV/F9lrIWHJxQr2KfeRkeBkzA7sr8tXJyDStrqDCHXar\nrau0Bw51aUXm97ioCKKiHyfLac4GzCzQ7QwH9ZaDiW6Y1+tRokCweJ/+9vBPC8sLy8V74MJrUfEi\nwP7NJaO9DXdeUjzYdlszbTq2fU3XVYyWg+9GIvfhUuszEIJgh95/VYiFUfL3k7AC2bXZpj24tg2T\nxbdSsAEPzXnK2SNKb0cpNiYpNykrud1oPaBaCtc+rd/P7e8MxYBkXc6p2uj5D1/TRzDQUCHqsf/5\nrQMK+lpxNQl8g/H0H1Dbss/9+Q8jneH6JyzHP/MCAO76Prd/00ityhIhBR3EwRRVItAbrFprGptp\nysDel2B3BLujwWRBIhKV88hIuCTR5cBPPbKq2HRTXuoKeGfe7Oic5dZsAcCrZ3s4q8AlX+k53f4O\nNVG1K0NUDCPUgYvn9+kfWeYuRLcYcae3zOdbtUhf6cHtnpD8EDJcugdQGbFCvU2Q6cFna0I2/nC5\nSlWcmYemJKEm1g4G7r4WwhSkLeo+vg70c51sMtU7+hDsjmDvRb04t54xvPLRUABcySB6RNSBLOdZ\nbQom4bH/5a0/+FNcTQKvMd73+7XeWT3xON0jxwC8+ptnbK8XHvklxF/Q/X4WGkntL1vssK//glCv\nPefvN3m8Nwuhn8UJIM4hdi2ZrptUb3UVVuCLE6E71+XvJQ44Pljx2N4ZW6fL3Gyy49SOL/Hqg+jE\nU22FJtY4dte9Wm9/4oBmru/nRuB6YdFa5kfr/PzmIsDYUy2KK1FWW74oA7GfxUKgFMGNnBUMTf5i\nMSFIGdigg5ga6kFBLlRR3y8U6LbpinagTS7BUXk4CJy/W2/9h396ga/m3Pl2zepG92L9YJJetxQJ\nEZ0Ibv25t88EAFeTwOuO/svPc/69CphsD2KaKLo61cmRptIbf6g0ZDc6KXRHPdd+Xi/D9G7P7e+o\nCVJku/tpiDj8kIUsM8wWcnGsXgn2tlXYqje4uJz3/ZjbuwofhG2kHa/XIzUgbQavGciTVOqBz14w\n1BcBcYFO4QD4qac+3hK8of2VA259SbcY1fmGux+dK6Q3rfBxNQ019El8NE5+Q+elrOpcDQZc7O8b\np9r+aULppyFmMKVwd+l7TVsRIaMIL2UC8fySbfzivXOOPnkXb29w/rSu/Po6ZB2ElPqLe/tNAHBF\nJb6Kq3jHx1Um8AbE4V/XFtHZj35EV8JkphlXPztwpx3ug7tDx61/YTn4nO7Vn/utB+pFsJA8PSeS\nS7WSwXPJmUVOvVPxqiqy3qAIP2ctd27vFxvzZYWN8ttZEs1Hc5SKrK5Tr6DbE+w2sP8lfaz6jCBu\nigSYvbDGrnQ5Xrz/AHsul5iPqT3oq5ABQolN6SsYnerJ95OomRiZlRBJSTtNyd2kCKrYrboED+sr\n6fscApKSxHdSNgKotmULkh5b3TJMH9nn+JfP2V47zNbzIJFnMHiPt+loeZt+rPsTT/7xj/PCH/uo\nYgAGvgVDQ8zUHQjAu/4BzH/hOZ77XU8CsLvmmb1g6PbIVOQg8cYfhQwkkj6mwh5qX7YNSVPPTQNR\ncRyDTgTVq02R1NrpJCNdmQSSklK1iTUIIBihXsH2WvFBUNWcQLWF9qBhsozVOSmaCanCblxBPKYi\nXj9Vfr7ZXdYYGGoPAtTnEfLrIxMwpv79mEvdByCzLodQZAxUu+htkDoGUibPKn4/3RwWT4w4WnXM\nX3TsjtKsWL6XVNR8EI1D3oi4mgTe4Mi6hK6Ae1RvLrar4oRw+KvC9J99mts/8CHWD2ulujk3qmbb\nk5d2k4BGTdGwk05X62pVVqrpS7C5pRV6N9XKeDqP+szgR2XwpEHn65KZ2F1sxa0v76tTtT+p8BKE\n8T3B94H1zYrpF7UyWG08biaYM3PpNd04YHaXv6OEkkx1gmTY4sZFwMONI5Kyj8Ygyfk5IS13BX6c\nwFjiSiuSXOMYdGQsEN97KArb7gm7G2NsFxirUxvdXCcxX8Hjb9PBn+KqJvAGx7v+p49FIkq6MQu0\nVBwZ6nrjkxfwvic5ex/UC0O9MEpQsUnfLmS7rPZQ9QwTXz0ZW/iarEWwOxImr2hhz64Lh970QoiY\nd1Uu0vcIdVD8QdQt6OZexVIaTZldA+1B+GqdPNEiYbsvdDMBa8Aa7M5jl4rmS/z79lDZUSZJice+\nu7cq8JEeU8qwDmJfRRRlr5Od3SiM2I20SGe3ZfJrLvSnWuuA1VYsGdItLiIJffnJxcH4XZgutgIn\nBtcYqnWgWoecubwdcAC/XlxNAt+EeOKHdSLINmOREbe75osQxot3eeV7DqN/X7y5N3qsQMbAJyhr\nunnFR9iqjyKeccBWW2gPJa+KdqvtwnohefLJdllbzQr6aaCfefqZz7JmvirvUy/1mDCQ/hpabYUK\ndg/vsXt4j2rVU0XVniTMkeoYvhooMIkOWDeOQCJTtjl2q05N9UKyU3Cok8QaxUfAR6/AOGEQ8f1J\nSDQBioINxZR0MBH4CPtN0F8MdBOD6QLVNv5sAo/82bf/BABXk8BVXMU7Pq4mgW9SPPVDH8+ZQOqN\n+8Zz9JnA0WcC7rEbXDwRqJbaCzcuwlu9psHpp58Wi+ssORZBL7qa6k8/Kd2CYMnZhUJcS2VddQEl\np7tp4x8kovlGZdUGBlX5km4jmgV0M9jcqNncqBHnM7w5MewyA0/I2xMfNfhMX84nA6HiuQdbEJHd\nrGwbMGmFj2CsvhT6ktxbkjtLhcbhVmDI/kvXptqC3QZGC0d9UajTN/7CW5sU9I3EVWHwmxhP/nG9\nkZ7/Ex9l+7CjuWc5/GyE7n7kAMRjOnOpyp0GTKrQKyc+XKq6q6OvFsvMoBCWagRQ/u3nOjqCCZlN\nt73hsxafm6ZuhdYO7LaAeKq1UpllgFY0PWrcuRaqDUhyJe595gpkdd5VpE93hfEnxPS+K85EiTMQ\nbGH89dOotdijxc4k4mqIdvBkgZd+Ws4vV/VtwERNwdyt6MDG7ULqIlTbwPzlnnrRY376Fzn4Oq/t\n2ymuJoE3IR7/kY/x3A9/lJu/0LO9qZC07TF5IGWLblPot3ZAf1VyjO5ZIQ7CKJOdEXaBXBk320Ka\nMa1OKElVByKMNxp2ZH9Dqwvk0PnIjRRKazqhUYVtupmeYz/VmWF0qqtnqExUSS52XBLK+w9bbnjB\nWzJOP7cCd8XKO+n5ma58P6DuQd6W4iHE2sgYLQYmF+BWyUL1qhCyUhZCBfVS32f+cs/o3g6e+dTX\ndzHfhgccdCgAAAoPSURBVHE1CbxJ8a4/+THMB38DJx860gdMAcakFVHVcePv8cpUK8FNYlocI7Wu\nqENu53mrmUHqp2fjU5+2CeVYNwpqiRbBPKAYedDJIA1igD6uuBkoExl0dqdW3piEXfBRQahgAiAS\noUL5jAQgdhCGE47ppHgFoOeVPrNxZVIcmn361E7cGxRK6/J306aOTHyPXieCehk4/LyepNm5d/QE\nAFc1gau4ind8vCbzkcHfflBEgohcj/8vIvJ/RvORT4nId3wzTvqtGv5Tn+Xwb3ycw7/xcap14awP\nQTmIEm/6aaCfRh37Xpfs7E+QWoWiGYCP6ELfxLaZ1YJXtY3twijg2c0D3TxEKa1YcEvFS5vah5Lf\n21e64ueCY1LtacmMvO1RxfaoAonbmLXktqWLW4PkBJR0/JWiG0qLL7L/Uj0hKRHlXn4sjOYtRaTz\nhgG/H/Rzp+eHSrdH2lIMiA+YLlAvArOXHfXJmvpkjXz8l96sy//Axms1H0FEHgf+A+C5wcO/DdUV\nfBpVEv4Lr/8U357xyJ/9GC5p2kedvmALKjDhCVKF27RSqumxSm768lwg98pDdXnQ5q3FVrIjr9YE\nShcise6yAnIU3wy24BxIPf4mThgbod2LPwcN9UWkOMdB7EYhYvoHPfqBMnOKYOLk1ZTzzsW8KOha\nJqaQ0YAJZ+BH4dJ3BxELEb0FghGC0depdoHx3/85/Kc+i//UZ78JV/atF6/JfCTGn0PFRodX9fuB\nvx40ngEOReThN+RM34bx+I9+TAdepTe3b0LRuouCm9U6DrjdwKkohhtxqeU11PJLq6wbk620fK1F\nRtNp9dxuJJttANn9J7Uih92Bbi9apMX3yao7qUU51816Nw+5hVdtdNIKVcjZjt1GNONWwUj1Mtp6\nj9R6LLv4uJI1DCeH5CyUQD++GtQRXBn4JoKJtDUYML1OZAf/9zNv0tV968RrKgyKyPcDL4YQfklE\nhn/6WuYjL7/mM3ybx1Ch5ot/5iO4uadeWKqo4dzPKJJcSYSzJXPdS+su4fQVP5+7A10ZDMPiWlql\n8wDysXi4kUw0CpVgdlrE6yIXIfENTPRl9HUsNtbaQWgPS3HSV4PzG3QhpANsaREmMpFpKcuSKLvQ\nbiR3D1LUK+jHRWNAfQckOgiR36deqWdBUk+6+RffGQjAbzS+4UlARKbAH0O3Aq853krmI1dxFW/n\neC2ZwHuAp4CUBTwG/IKIfJi3s/nImxDv/iMKLnr5v/soPq7kWuzT9l8GzABJ/z47IcfCopsGvCtI\nv2wd7kt2EGwofgdx5TRBV+Z+WrKDFL4uakMZMTjAJwBsjwwYPS63J11qQZZzT2Ag9SNInyXVIYQg\nBSeQ3IQS9Rj0OXYTtwKZiixZzSh/PQ7cSKgvAtf+yjsH/fda4hueBEIIvwzcTP8vIs8C3xlCuCsi\nPwn8QRH5ceA3A+chhKutwDcYD//vl9PWL//JjxbTElDUXATS1Bc6Grs93YvbdbE3A3K9wFdkTYBg\nL/P+03HiBv8Owu6KHFdC8SXKc7Lomj3rqVee299eXjQV/LJZaHwfFRUJ+TX1cySPgjJJBNFagfSS\n0YG+KbWQDAzakLcdSRBFAjz6p6/S/68nXpP5SAjha/kO/EPgt6NuxGvg97xB5/mOjid++Ktv5mf/\n1EcuVdGlJyvxpg4CUIRE+sHqHn9tFkVTr5+qU5Fxklf33LXoC0gnS34nhGI8tpsZDn7uReqn35Un\nhuCB2F7MlmORI+EmgeNfLhPD4j3asXCxe+DG6iWYJqVU+bfb2O2Q6AhErJHEjsjbSQX4zQopNoL3\nL/blOPxm+b77fRpvyXj2Rz4C6CBPZppaTNO/h1pXXbsbuPPsdNKolyEX9tp9ShswIuxyYS+RgdAO\nQ9Lnt21BOH5l9gLw8g9+NP/e7cX3jrLd05e//jT9+T/x0TxxubGSrkZnIU8s1/7yVbr/9cT/F/7O\nJ///9u4ftK4yjOP490e1HUTQUg26SJVmqIOhpKWDilk07RJdpC4WcRBp3evmWAQRRC0ohLSDlAxW\nMxT/dXDTtkJRI4pFK1hqo4uDQkrr43De4iXJwfb23ryneX6f5d68CZfnyU1+vOec5DwRMb503X8x\naJacdwJmSXgnYGYrcgiYJecQMEvOIWCWnEPALDmHgFlyDgGz5BwCZsk5BMyScwiYJecQMEvOIWCW\nnEPALDmHgFlyfQ8fkfSSpO8lzUt6tWf95TJ85AdJTwyjaDMbnGu5x+AM8CZw5OqCpAmaGQMPRcSi\npLvL+lZgD/AgcC/wmaTRiLiy7FXNrBP6HT7yInAwIhbL1yyU9SngaEQsRsTPNPca3DHAes1swPo9\nJzAKPCLpS0mfS9pe1tuGj5hZR/U7mvwWYCOwE9gOzEq6/3pewMNHzLqh353Ar8D7ZebgSZq7wm/i\nOoePRMR4RIzfyoY+yzCzG9VvCHwATABIGgXWA38Ac8AeSRskbaaZTnxyEIWa2XD0NXwEmAamy2XD\nS8DeaG5bPC9pFvgOuAzs85UBs27zLcfNkvAtx81sRQ4Bs+QcAmbJOQTMknMImCXnEDBLziFglpxD\nwCw5h4BZcg4Bs+QcAmbJOQTMknMImCXnEDBLrhP/Sizpd+AvmhuTZLOJfH1n7Bnq931fRNy1dLET\nIQAg6fRK/+u81mXsO2PP0N2+fThglpxDwCy5LoXAO7ULqCRj3xl7ho723ZlzAmZWR5d2AmZWQfUQ\nkDRZJhiflXSgdj3DJOmcpG8knZF0uqxtlPSppB/L452167xRK02ybutTjTfK+/+1pG31Kr8xLX2/\nIul8ec/PSNrd87lOTPCuGgKS1gFvAbuArcAzZbLxWjYREWM9l4oOACciYgtwonx8s5sBJpestfW5\ni2ZIzRaasXSHVqnGYZhhed8Ar5f3fCwijsOyCd6TwNvl92HV1d4J7ADORsRPEXEJOEoz2TiTKeBw\neX4YeLJiLQPRMsm6rc8p4EgZafcFcIeke1an0sFq6btNZyZ41w6BbFOMA/hE0ldlICvASERcKM9/\nA0bqlDZ0bX1m+BnYXw51pnsO9zrTd+0QyObhiNhGswXeJ+nR3k+WUW5r/nJNlj6LQ8ADwBhwAXit\nbjnL1Q6Ba55ivBZExPnyuAAco9n+Xby6/S2PC/UqHKq2Ptf0z0BEXIyIKxHxD/Au/235O9N37RA4\nBWyRtFnSepoTJXOVaxoKSbdJuv3qc+Bx4FuafveWL9sLfFinwqFr63MOeLZcJdgJ/Nlz2HDTW3J+\n4yma9xw6NMH7f6cSD1NEXJa0H/gYWAdMR8R8zZqGaAQ4Jgma7/t7EfGRpFPArKTngV+ApyvWOBAt\nk6wPsnKfx4HdNCfG/gaeW/WCB6Sl78ckjdEc/pwDXgCIiM5M8PZfDJolV/twwMwqcwiYJecQMEvO\nIWCWnEPALDmHgFlyDgGz5BwCZsn9C5ko4zvFnAZPAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   1910\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m                 \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEXTENSION\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: ''",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-6468d5474c37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimgplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'slice_126_4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimsave\u001b[0;34m(fname, arr, **kwargs)\u001b[0m\n\u001b[1;32m   2131\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2133\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi)\u001b[0m\n\u001b[1;32m   1514\u001b[0m                 \u001b[0mbackground\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackground\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1516\u001b[0;31m             \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   1911\u001b[0m                 \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEXTENSION\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1912\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1913\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unknown file extension: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSAVE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: unknown file extension: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W3vzSA7OzD2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "af2e48dc-ea40-4160-ae41-41c2a68db3a2"
      },
      "source": [
        "\n",
        "%pylab inline\n",
        "import matplotlib.pyplot as plt\n",
        "img = Y_labels[:,126,:]\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()\n",
        "#plt.imsave('slice_126_GT',img,cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAQkklEQVR4nO3df4wc5X3H8fenJuCahoJL4tpAa9c2\nVCZqHOSYq1IiiJPY0CSXSggbRYVQS4bGJKkbKTHpH/SPRoL+comamEJwAIliWw40VuvGgEtKKuUM\nhjgBmyQc5tcZGxMFKAqVwfDtHzNnlvPu3d7OzO3sPZ+XFN3uzOzuMzHz2eeZmX2+igjMLF2/1u0G\nmFl3OQTMEucQMEucQ8AscQ4Bs8Q5BMwSV1kISFom6WeSBiWtrepzzKwYVXGfgKQpwM+BjwFDwEPA\npRGxt/QPM7NCquoJLAYGI2JfRLwObAT6K/osMyvguIre9zTguYbnQ8C5rTY+XifEVE6sqClmBvAq\nL/0iIt4zcnlVITAmSauAVQBTmca5WtKtppgl4b7Y8kyz5VUNB/YDZzQ8Pz1fdlRE3BQRiyJi0bs4\noaJmmNlYqgqBh4D5kuZIOh5YAWyt6LPMrIBKhgMRcUTS1cB2YAqwISL2VPFZZlZMZecEImIbsK2q\n9zezcviOQbPEOQTMEucQMEucQ8AscQ4Bs8Q5BMwS5xAwS5xDwCxxDgGzxDkEzBLnEDBLnEPALHEO\nAbPEOQTMEucQMEucQ8AscR2HgKQzJN0vaa+kPZK+mC+fLuleSU/kf08pr7lmVrYiPYEjwJciYgHQ\nB6yWtABYC+yIiPnAjvy5mdVUxyEQEQci4pH88avA42T1BvqB2/LNbgM+XbSRZladUs4JSJoNfADY\nCcyIiAP5qoPAjDI+w8yqUTgEJP0G8B3gLyLifxvXRVbosGmxQ0mrJO2StOsNDhdthpl1qFAISHoX\nWQDcERF35YtfkDQzXz8TONTstS4+YlYPRa4OCLgFeDwi/rFh1Vbg8vzx5cB3O2+emVWtSN2BDwF/\nCjwqaXe+7KvAdcBmSSuBZ4BLijXRzKrUcQhExP8AarHa1UXNeoTvGDRLnEPALHEOAbPEOQTMEucQ\nMEucQ8AscQ4Bs8Q5BMwS5xAwS5xDwCxxDgGzxDkEzBLnEDBLnEPALHEOAbPEOQTMElfGRKNTJP1I\n0r/nz+dI2ilpUNImSccXb6aZVaWMnsAXyWoODLseWBcR84CXgJUlfIaZVaTobMOnA38MfCt/LuAj\nwJZ8ExcfMau5oj2BfwK+DLyVP/8t4OWIOJI/HyKrSnQM1x0wq4ciU45/AjgUEQ938nrXHTCrh6JT\njn9K0kXAVOAk4AbgZEnH5b2B04H9xZtpZlUpUpD0mog4PSJmAyuA/4qIzwD3Axfnm7n4iFnNVXGf\nwFeAv5Q0SHaO4JYKPsPMSlJkOHBURHwf+H7+eB+wuIz3NbPq+Y5Bs8Q5BMwS5xAwS5xDwCxxDgGz\nxDkEzBLnEDBLnEPALHEOAbPEOQTMEucQMEucQ8AscQ4Bs8Q5BMwS5xAwS1zR2YZPlrRF0k8lPS7p\nDyVNl3SvpCfyv6eU1VgzK1/RnsANwPci4veB95PVH1gL7IiI+cCO/LmZ1VSR2YZ/E/gw+fRhEfF6\nRLwM9JPVGwDXHTCrvSI9gTnAi8C38zJk35J0IjAjIg7k2xwEZhRtpJlVp0gIHAecA6yPiA8Av2JE\n1z8iAohmL3bxEbN6KBICQ8BQROzMn28hC4UXJM0EyP8eavZiFx8xq4cidQcOAs9JOitftATYC2wl\nqzcArjtgVntFpxz/PHBHXn58H3AFWbBslrQSeAa4pOBnmFmFCoVAROwGFjVZtaTI+5rZxPEdg2aJ\ncwiYJc4hYJY4h4BZ4hwCZolzCJglziFgljiHgFniHAJmiXMImCXOIWCWOIeAWeIcAmaJcwiYJc4h\nYJY4h4BZ4ooWH1kjaY+kxyTdKWmqpDmSdkoalLQpn3XIzGqqSN2B04AvAIsi4n3AFGAFcD2wLiLm\nAS8BK8toqJlVo+hw4Djg1yUdB0wDDgAfIZt5GFx8xKz2Op5jMCL2S/p74Fng/4B7gIeBlyPiSL7Z\nEHBa4VZa2wbX9Y25zbw1AxPQEusVRYYDp5CVHJsDzAJOBJaN4/UuPtIl7QSFpaPIcOCjwFMR8WJE\nvAHcBXwIODkfHgCcDuxv9mIXHzGrhyJTjj8L9EmaRjYcWALsAu4HLgY24uIjE2a83+7D23toYEXO\nCeyUtAV4BDgC/Ai4CfgPYKOkv8mX3VJGQ625ol37ka93KKSnaPGRa4FrRyzeBywu8r7WHo/trQxF\ny5DZBKn6gHcPIF2+bdgscQ6BHjAR3X4PLdLlEKg5H5xWNYeAHeXASZNPDNbURB2QPiFoDoEEjDzQ\n6/KN7xuW6sHDAbPEOQRqat6agVK+IZu9h795rZGHA5PUWAf6vDUDXR8WOIzqwT2BmqvyQCn7vQfX\n9XU9WGz83BPoAXX41h42uK6PeWsG2P787iZr82XLsz9LZy2csHZZ59wTMEucQ6BH1GX83LoXcKzt\nz++uTQ/GWvNwwNrS7oE/0pPLb4TlMHfTVUB9wsze5hBISLNv5bEOysF1fdmB3MJ5q688ZtkPvvEv\nxyw7+h7Lfa6gbsYMAUkbgE8Ah/L6AkiaDmwCZgNPA5dExEuSBNwAXAS8Bnw2Ih6ppuk2mna74aPd\ntddJADQubxYGVj/tnBO4lWNnEV4L7IiI+cCO/DnAhcD8/H+rgPXlNNPMqjJmCETEA8AvRyzuJyss\nAu8sMNIP3B6ZAbKZh2eW1VibGMPX+zvpBbSj0/MLVo1OzwnMiIgD+eODwIz88WnAcw3bDRcfOYD1\njNEOfmje3W8WCuetvtJDgh5Q+MRgRISkGO/rJK0iGzIwlWlFm5GE4XF7lZfdxvMt3U5voFUQbH9+\nt08Q1kSn9wm8MNzNz/8eypfvB85o2M7FRypQ5mW2J5ffyJPLb2T787vbDoAyvt0dAPXRaQhsJSss\nAu8sMLIVuEyZPuCVhmGDmdXQmCEg6U7gh8BZkoYkrQSuAz4m6QmycmTX5ZtvI6s7MAjcDHyuklZb\n4d7AcA+gU+32BnxOoP7GPCcQEZe2WLWkybYBrC7aKGvPeH9YVOSgb9dYB72HAfXj3w70uLImH+nE\neL7ll85a6ACoKd823OPa7Qm02wtoPOPf6iC/4tnzjj6e95W9b7fl+gXv2M4HfW9wT8Asce4J9Lgy\n7x0Yz12Az/e9esyyaexk6d3+9u817glYS61C4YEfnj3BLbEqOQR6XDvz+hW5KlDkNwLWGzwc6FHj\n6f7P3XRVW0Hga/ppck+gR43n0mAV9wd42rDJwyFgljgPBxIw2nBg5JjfQ4L0OAR6WBVd8nZuFrLJ\nxcOBHlb17cK+MpAG9wR6WNGeQLszBdvk5p6AWeIcAj1s+DJhp8MCf+sbgLIpAEbZoHndgb8DPgm8\nDjwJXBERL+frrgFWAm8CX4iI7WM14iRNj3N1zPQE1oYq5xMYrX7A3E1XuZpQj7kvtjwcEYtGLu+0\n7sC9wPsi4g+AnwPXAEhaAKwAzs5f801JUwq027rgvNVXuoBIQtqZWegBSbNHLLun4ekAcHH+uB/Y\nGBGHgackDQKLyaYnswqM51eEw/UAYfRewfCB76sDaSjjnMCfAf+ZP25Vd8DMaqpQCEj6K+AIcEcH\nr10laZekXW9wuEgzjPHfMzB301Xv6Bk0M9ZQwL8fmBw6DgFJnyU7YfiZePvsousOdNF4g2DemoGO\n5v4bKzyst3QUApKWAV8GPhURrzWs2gqskHSCpDlkhUkfLN5MK9vIwGg3DBwAk087pcnvBM4HTpU0\nBFxLdjXgBODerBo5AxFxVUTskbQZ2Es2TFgdEW9W1Xgr39JZC5k18G4Avv07Pzi63Af/5NVp3YFb\nRtn+a8DXijTKzCaOfzswyZQx8ejwJKJLWeiTfwlwCEwig+v62q5KNLxtq3Wj8Z2Ck8uYtw1PBN82\nXJ1WB7QP5PQUuW3Yelizg90BYI0cAmaJcwiYJc4nBhPg7r+Nxj0Bs8Q5BMwS5xAwS5xDwCxxDgGz\nxDkEzBLnEDBLnEPALHEOAbPEjRkCkjZIOiTpsSbrviQpJJ2aP5ekr0salPQTSedU0WgzK0+nxUeQ\ndAbwceDZhsUXks0rOB9YBawv3kQzq9KYIRARDwC/bLJqHdlko40TEvQDt0dmADhZ0sxSWmpmleh0\ntuF+YH9E/HjEKhcfMesx4/4VoaRpwFfJhgIdk7SKbMjAVKYVeSszK6CTnsBcYA7wY0lPkxUYeUTS\nb+PiI2Y9Z9whEBGPRsR7I2J2RMwm6/KfExEHyYqPXJZfJegDXomIA+U22czK1M4lwjvJqgqfJWlI\n0spRNt8G7AMGgZuBz5XSSjOrTKfFRxrXz254HMDq4s0ys4niOwbNEucQMEucQ8AscQ4Bs8Q5BMwS\n5xAwS5xDwCxxDgGzxDkEzBLnEDBLnEPALHEOAbPEOQTMEucQMEucQ8AscQ4Bs8R1XHxE0ucl/VTS\nHkl/27D8mrz4yM8kLa2i0WZWnnZmG74V+Gfg9uEFki4gqzHw/og4LOm9+fIFwArgbGAWcJ+kMyPi\nzbIbbmbl6LT4yJ8D10XE4XybQ/nyfmBjRByOiKfI5hpcXGJ7zaxknZ4TOBM4T9JOSf8t6YP5chcf\nMesx4y4+0vC66UAf8EFgs6TfG88buPiIWT102hMYAu7Kaw4+CLwFnIqLj5j1nE5D4N+ACwAknQkc\nD/yCrPjICkknSJpDVp34wTIaambVGHM4kBcfOR84VdIQcC2wAdiQXzZ8Hbg8rzmwR9JmYC9wBFjt\nKwNm9abs2O2ukzQ9ztWSbjfDbFK7L7Y8HBGLRi73HYNmiXMImCXOIWCWOIeAWeIcAmaJcwiYJc4h\nYJY4h4BZ4hwCZolzCJglziFgljiHgFniHAJmiXMImCWuFj8llvQi8CuyiUlScyrp7XeK+wzd3+/f\njYj3jFxYixAAkLSr2W+dJ7sU9zvFfYb67reHA2aJcwiYJa5OIXBTtxvQJSnud4r7DDXd79qcEzCz\n7qhTT8DMuqDrISBpWV7BeFDS2m63p0qSnpb0qKTdknbly6ZLulfSE/nfU7rdzqKaVbJutZ/KfD3/\n9/+JpHO61/JiWuz3X0van/+b75Z0UcO6WlTw7moISJoCfAO4EFgAXJpXNp7MLoiIhQ2XitYCOyJi\nPrAjf97rbgWWjVjWaj8vJCtSM5+sLN36CWpjFW7l2P0GWJf/my+MiG1wTAXvZcA38+NhwnW7J7AY\nGIyIfRHxOrCRrLJxSvqB2/LHtwGf7mJbStGiknWr/ewHbs9L2g0AJ0uaOTEtLVeL/W6lNhW8ux0C\nqVUxDuAeSQ/nBVkBZkTEgfzxQWBGd5pWuVb7mcJ/A1fnQ50NDcO92ux3t0MgNX8UEeeQdYFXS/pw\n48q8lNukv1yTyn7m1gNzgYXAAeAfutucY3U7BNquYjwZRMT+/O8h4G6y7t8Lw93f/O+h7rWwUq32\nc1L/NxARL0TEmxHxFnAzb3f5a7Pf3Q6Bh4D5kuZIOp7sRMnWLrepEpJOlPTu4cfAx4HHyPb38nyz\ny4HvdqeFlWu1n1uBy/KrBH3AKw3Dhp434vzGn5D9m0ONKniPWZW4ShFxRNLVwHZgCrAhIvZ0s00V\nmgHcLQmy/9//NSK+J+khYLOklcAzwCVdbGMpWlSyvo7m+7kNuIjsxNhrwBUT3uCStNjv8yUtJBv+\nPA1cCRARtang7TsGzRLX7eGAmXWZQ8AscQ4Bs8Q5BMwS5xAwS5xDwCxxDgGzxDkEzBL3/3QLXceb\nikAbAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT_xNOTsPC14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_gen(input_dim,x,y,slice_no):\n",
        "  X1 = []\n",
        "  X2 = []\n",
        "  Y = []\n",
        "  \n",
        "  for i in range(int((input_dim)/2),y.shape[0]-int((input_dim)/2)):\n",
        "    for j in range(int((input_dim)/2),y.shape[2]-int((input_dim)/2)):\n",
        "      #Filtering all 0 patches\n",
        "      if(x[i-16:i+17,j-16:j+17,:].any != 0):\n",
        "        X2.append(x[i-16:i+17,j-16:j+17,:])\n",
        "        X1.append(x[i-int((input_dim)/2):i+int((input_dim)/2)+1,j-int((input_dim)/2):j+int((input_dim)/2)+1,:])\n",
        "        Y.append(y[i,slice_no,j])\n",
        "      \n",
        "      \n",
        "  X1 = np.asarray(X1)\n",
        "  X2 = np.asarray(X2)\n",
        "  Y = np.asarray(Y)\n",
        "  d = [X1,X2,Y]\n",
        "  return d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2MsaLYPPG7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_gen(data,y,slice_no,model_no):\n",
        "  d = []\n",
        "  x = data[slice_no]\n",
        "  #filtering all 0 slices and non-tumor slices\n",
        "  if(x.any() != 0 and y.any() != 0):\n",
        "    if(model_no == 0):\n",
        "      X1 = []\n",
        "      for i in range(16,159):\n",
        "        for j in range(16,199):\n",
        "          if(x[i-16:i+17,j-16:j+17,:].all != 0):\n",
        "            X1.append(x[i-16:i+17,j-16:j+17,:])\n",
        "      Y1 = []\n",
        "      for i in range(16,159):\n",
        "        for j in range(16,199):\n",
        "          if(x[i-16:i+17,j-16:j+17,:].all != 0):\n",
        "            Y1.append(y[i,slice_no,j]) \n",
        "      X1 = np.asarray(X1)\n",
        "      Y1 = np.asarray(Y1)\n",
        "      d = [X1,Y1]\n",
        "    elif(model_no == 1):\n",
        "      d = model_gen(65,x,y,slice_no)\n",
        "    elif(model_no == 2):\n",
        "      d = model_gen(56,x,y,slice_no)\n",
        "    elif(model_no == 3):\n",
        "      d = model_gen(53,x,y,slice_no)  \n",
        "    \n",
        "  return d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvPx2quh8Ree",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4fb709a-ac64-4db1-a33c-bfe9da15c56c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: bazel: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs-K3wtfPwOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, Lambda,Concatenate\n",
        "from tensorflow.keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D, Add\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "from tensorflow.keras.initializers import glorot_normal\n",
        "#import pydot\n",
        "from IPython.display import SVG\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuky77UKPK7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def two_path(X_input):\n",
        "  # Local path Conv1\n",
        "  X = Conv2D(64,(7,7),strides=(1,1),padding='valid', kernel_regularizer=regularizers.l2(0.01),\n",
        "               activity_regularizer=regularizers.l1(0.01) )(X_input)\n",
        "  # Batch-norm\n",
        "  X = BatchNormalization()(X)\n",
        "  X1 = Conv2D(64,(7,7),strides=(1,1),padding='valid', kernel_regularizer=regularizers.l2(0.01),\n",
        "               activity_regularizer=regularizers.l1(0.01))(X_input)\n",
        "  X1 = BatchNormalization()(X1)\n",
        "  # Max-out\n",
        "  X = layers.Maximum()([X,X1])\n",
        "  X = layers.Dropout(.5)(X)\n",
        "  X = Conv2D(64,(4,4),strides=(1,1),padding='valid',activation='relu', kernel_regularizer=regularizers.l2(0.01),\n",
        "               activity_regularizer=regularizers.l1(0.01))(X)\n",
        "  \n",
        "  # Global path\n",
        "  X2 = Conv2D(160,(13,13),strides=(1,1),padding='valid', kernel_regularizer=regularizers.l2(0.01),\n",
        "               activity_regularizer=regularizers.l1(0.01))(X_input)\n",
        "  X2 = BatchNormalization()(X2)\n",
        "  X21 = Conv2D(160,(13,13),strides=(1,1),padding='valid', kernel_regularizer=regularizers.l2(0.01),\n",
        "               activity_regularizer=regularizers.l1(0.01))(X_input)\n",
        "  X21 = BatchNormalization()(X21)\n",
        "  # Max-out\n",
        "  X2 = layers.Maximum()([X2,X21])\n",
        "  X2 = layers.Dropout(.5)(X2)\n",
        "\n",
        "  \n",
        "  # Local path Conv2\n",
        "  X3 = Conv2D(64,(3,3),strides=(1,1),padding='valid', kernel_regularizer=regularizers.l2(0.01),\n",
        "               activity_regularizer=regularizers.l1(0.01))(X)\n",
        "  X3 = BatchNormalization()(X3)\n",
        "  X31 =  Conv2D(64,(3,3),strides=(1,1),padding='valid',  kernel_regularizer=regularizers.l2(0.01),\n",
        "               activity_regularizer=regularizers.l1(0.01))(X)\n",
        "  X31 = BatchNormalization()(X31)\n",
        "  X = layers.Maximum()([X3,X31])\n",
        "  X = layers.Dropout(.5)(X)\n",
        "\n",
        "  X = Conv2D(64,(2,2),strides=(1,1),padding='valid',activation='relu', kernel_regularizer=regularizers.l2(0.01),\n",
        "               activity_regularizer=regularizers.l1(0.01))(X)\n",
        "  \n",
        "  # Merging the two paths\n",
        "  X = Concatenate()([X2,X])\n",
        "\n",
        "  return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFKFL29MYhdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFYyw0QiPNuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_cascade(input_shape1,input_shape2):\n",
        "  \n",
        "  X1_input = Input(input_shape1)\n",
        "  # 1st two-path of cascade\n",
        "  X1 = two_path(X1_input)\n",
        "  X1 = Conv2D(5,(21,21),strides=(1,1),padding='valid',activation='relu', kernel_regularizer=regularizers.l2(0.01),\n",
        "               activity_regularizer=regularizers.l1(0.01))(X1)\n",
        "  X1 = BatchNormalization()(X1)\n",
        "  \n",
        "  X2_input = Input(input_shape2)\n",
        "  # Concatenating the output of 1st to input of 2nd\n",
        "  X2_input1 = Concatenate()([X1,X2_input])\n",
        "  X2 = two_path(X2_input1)\n",
        "  \n",
        "  # Fully convolutional softmax classification including L1/L2 regularization\n",
        "  X2 = Conv2D(5,(21,21),strides=(1,1),padding='valid',  kernel_regularizer=regularizers.l2(0.01),\n",
        "               activity_regularizer=regularizers.l1(0.01))(X2)\n",
        "  X2 = BatchNormalization()(X2)\n",
        "  #X2 = Flatten()(X2)\n",
        "  X2 = Activation('softmax')(X2)\n",
        "  \n",
        "  model = Model(inputs=[X1_input,X2_input],outputs=X2)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6BcUMstPl6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_REgVjdPnzN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "c59a1cc5-5c72-4319-ede9-69c8650bf88f"
      },
      "source": [
        "\n",
        "m0 = two_path((33,33,4))\n",
        "m0.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-6bc726adab4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mm0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwo_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mm0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-ed6af690bab5>\u001b[0m in \u001b[0;36mtwo_path\u001b[0;34m(X_input)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m# Local path Conv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   X = Conv2D(64,(7,7),strides=(1,1),padding='valid', kernel_regularizer=regularizers.l2(0.01),\n\u001b[0;32m----> 4\u001b[0;31m                activity_regularizer=regularizers.l1(0.01) )(X_input)\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;31m# Batch-norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;31m# Eager execution on data tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m           with base_layer_utils.autocast_context_manager(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2125\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2126\u001b[0m       input_spec.assert_input_compatibility(\n\u001b[0;32m-> 2127\u001b[0;31m           self.input_spec, inputs, self.name)\n\u001b[0m\u001b[1;32m   2128\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2129\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    153\u001b[0m                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' inputs, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                      \u001b[0;34m'but it received '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                      ' input tensors. Inputs received: ' + str(inputs))\n\u001b[0m\u001b[1;32m    156\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0minput_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Layer conv2d expects 1 inputs, but it received 3 input tensors. Inputs received: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'Const_1:0' shape=() dtype=int32>, <tf.Tensor 'Const_2:0' shape=() dtype=int32>]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHYmqoHRP9d9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7dcbe18a-d8e8-426d-b360-b1d7729e7427"
      },
      "source": [
        "m1 = input_cascade((65,65,4),(33,33,4))\n",
        "m1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 65, 65, 4)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 59, 59, 64)   12608       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 59, 59, 64)   12608       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 59, 59, 64)   256         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 59, 59, 64)   256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "maximum (Maximum)               (None, 59, 59, 64)   0           batch_normalization[0][0]        \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 59, 59, 64)   0           maximum[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 56, 56, 64)   65600       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 54, 54, 64)   36928       conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 54, 54, 64)   36928       conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 53, 53, 160)  108320      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 53, 53, 160)  108320      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 54, 54, 64)   256         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 54, 54, 64)   256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 53, 53, 160)  640         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 53, 53, 160)  640         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "maximum_2 (Maximum)             (None, 54, 54, 64)   0           batch_normalization_4[0][0]      \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "maximum_1 (Maximum)             (None, 53, 53, 160)  0           batch_normalization_2[0][0]      \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 54, 54, 64)   0           maximum_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 53, 53, 160)  0           maximum_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 53, 53, 64)   16448       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 53, 53, 224)  0           dropout_1[0][0]                  \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 33, 33, 5)    493925      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 33, 33, 5)    20          conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 33, 33, 4)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 33, 33, 9)    0           batch_normalization_6[0][0]      \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 27, 27, 64)   28288       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 27, 27, 64)   28288       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 27, 27, 64)   256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 27, 27, 64)   256         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "maximum_3 (Maximum)             (None, 27, 27, 64)   0           batch_normalization_7[0][0]      \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 27, 27, 64)   0           maximum_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 24, 24, 64)   65600       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 22, 22, 64)   36928       conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 22, 22, 64)   36928       conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 21, 21, 160)  243520      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 21, 21, 160)  243520      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 22, 22, 64)   256         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 22, 22, 64)   256         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 21, 21, 160)  640         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 21, 21, 160)  640         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "maximum_5 (Maximum)             (None, 22, 22, 64)   0           batch_normalization_11[0][0]     \n",
            "                                                                 batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "maximum_4 (Maximum)             (None, 21, 21, 160)  0           batch_normalization_9[0][0]      \n",
            "                                                                 batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 22, 22, 64)   0           maximum_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 21, 21, 160)  0           maximum_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 21, 21, 64)   16448       dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 21, 21, 224)  0           dropout_4[0][0]                  \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 1, 1, 5)      493925      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 1, 1, 5)      20          conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 1, 1, 5)      0           batch_normalization_13[0][0]     \n",
            "==================================================================================================\n",
            "Total params: 2,089,778\n",
            "Trainable params: 2,087,454\n",
            "Non-trainable params: 2,324\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ssep_-drQnV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import class_weight\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GjyGadWJ8QO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "import keras.backend as K\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNt6V30zq1ZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElJqU1X5o05Y",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr4DkGNQJhMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.utils import class_weight\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7YI97-ST_Z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_gen_hg(path,slice_no,model_no):\n",
        "  p = os.listdir(path)\n",
        "  p.sort(key=str.lower)\n",
        "  arr = []\n",
        "  for i in range(len(p)):\n",
        "    if 'more' in p[i] or 'OT' in p[i]:\n",
        "      if p[i] != '.DS_Store':\n",
        "        p1 = os.listdir(path+'/'+p[i])\n",
        "        img = sitk.ReadImage(path+'/'+p[i]+'/'+p1[0])\n",
        "        y = sitk.GetArrayFromImage(img)    \n",
        "\n",
        "    else:\n",
        "      if p[i] != '.DS_Store':\n",
        "        p1 = os.listdir(path+'/'+p[i])\n",
        "        p1.sort()\n",
        "        img = sitk.ReadImage(path + '/' + p[i]+'/'+p1[-1])\n",
        "        arr.append(sitk.GetArrayFromImage(img))\n",
        "  data = np.zeros((196,176,160,4))\n",
        "  for i in range(196):\n",
        "    data[i,:,:,0] = arr[0][:,i,:]\n",
        "    data[i,:,:,1] = arr[1][:,i,:]\n",
        "    data[i,:,:,2] = arr[2][:,i,:]\n",
        "    data[i,:,:,3] = arr[3][:,i,:]\n",
        "  x = data[slice_no]\n",
        "  \n",
        "  if(model_no == 0):\n",
        "    X1 = []\n",
        "    for i in range(16,159):\n",
        "      for j in range(16,199):\n",
        "        X1.append(x[i-16:i+17,j-16:j+17,:])\n",
        "    Y1 = []\n",
        "    for i in range(16,159):\n",
        "      for j in range(16,199):\n",
        "        Y1.append(y[i,slice_no,j]) \n",
        "    X1 = np.asarray(X1)\n",
        "    Y1 = np.asarray(Y1)\n",
        "    d = [X1,Y1]\n",
        "  elif(model_no == 1):\n",
        "    d = model_gen(65,x,y,slice_no)\n",
        "  elif(model_no == 2):\n",
        "    d = model_gen(56,x,y,slice_no)\n",
        "  elif(model_no == 3):\n",
        "    d = model_gen(53,x,y,slice_no)  \n",
        "    \n",
        "  return d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhiHDLerGDlo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_gen_lg(path,slice_no,model_no):\n",
        "  p = os.listdir(path)\n",
        "  p.sort(key=str.lower)\n",
        "  arr = []\n",
        "  for i in range(len(p)):\n",
        "    if 'more' in p[i] or 'OT' in p[i]:\n",
        "      if p[i] != '.DS_Store':\n",
        "        p1 = os.listdir(path+'/'+p[i])\n",
        "        img = sitk.ReadImage(path+'/'+p[i]+'/'+p1[0])\n",
        "        y = sitk.GetArrayFromImage(img)    \n",
        "\n",
        "    else:\n",
        "      if p[i] != '.DS_Store':\n",
        "        p1 = os.listdir(path+'/'+p[i])\n",
        "        p1.sort()\n",
        "        img = sitk.ReadImage(path + '/' + p[i]+'/'+p1[-1])\n",
        "        arr.append(sitk.GetArrayFromImage(img))\n",
        "  data = np.zeros((196,176,216,4))\n",
        "  for i in range(196):\n",
        "    data[i,:,:,0] = arr[0][:,i,:]\n",
        "    data[i,:,:,1] = arr[1][:,i,:]\n",
        "    data[i,:,:,2] = arr[2][:,i,:]\n",
        "    data[i,:,:,3] = arr[3][:,i,:]\n",
        "  x = data[slice_no]\n",
        "  \n",
        "  if(model_no == 0):\n",
        "    X1 = []\n",
        "    for i in range(16,215):\n",
        "      for j in range(16,199):\n",
        "        X1.append(x[i-16:i+17,j-16:j+17,:])\n",
        "    Y1 = []\n",
        "    for i in range(16,215):\n",
        "      for j in range(16,199):\n",
        "        Y1.append(y[i,slice_no,j]) \n",
        "    X1 = np.asarray(X1)\n",
        "    Y1 = np.asarray(Y1)\n",
        "    d = [X1,Y1]\n",
        "  elif(model_no == 1):\n",
        "    d = model_gen(65,x,y,slice_no)\n",
        "  elif(model_no == 2):\n",
        "    d = model_gen(56,x,y,slice_no)\n",
        "  elif(model_no == 3):\n",
        "    d = model_gen(53,x,y,slice_no)  \n",
        "    \n",
        "  return d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4w6cmkXqQGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = data_gen_hg('/content/drive/My Drive/BRATS-2/Image_Data/HG/0004',100,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk4n-_wPvpue",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Oj1sGfnVcdR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35614267-af6a-41a5-b152-f4a839374f0b"
      },
      "source": [
        "print(len(d[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10752\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNC1oIzH4vwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# d = []\n",
        "\n",
        "# for i in range(1,3):\n",
        "#   path = '/content/drive/My Drive/BRATS-2/Image_Data/LG/000' + str(i)\n",
        "#   d.append(data_gen_lg(path, 100,1))\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCbPAuBrcbZE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8d19fae4-540d-4c21-c2a8-97321f5cad8c"
      },
      "source": [
        "\n",
        "y = np.zeros((10752,1,1,5))\n",
        "\n",
        "for i in range(y.shape[0]):\n",
        "  y[i,:,:,d[2][i]] = 1\n",
        "\n",
        "\n",
        "sample = np.zeros((5,1))\n",
        "for i in range(5):\n",
        "  sample[i] = np.sum(y[:,:,:,i])\n",
        "print(sample/np.sum(sample))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.78552827]\n",
            " [0.0250186 ]\n",
            " [0.04938616]\n",
            " [0.11988467]\n",
            " [0.02018229]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiIur16G9JdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# for i in range(4,6):\n",
        "#   path = '/content/drive/My Drive/BRATS-2/Image_Data/HG/000' + str(i)\n",
        "#   d.append(data_gen_hg(path, 100,1))\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Kleu1c09s28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lengths_d = []\n",
        "# for i in range(len(d)):\n",
        "#   lengths_d.append(len(d[i][0]))\n",
        "# print(lengths_d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ImcKgeTVkZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y = []\n",
        "# for i in range(len(lengths_d)):\n",
        "#   y.append(np.zeros((lengths_d[i],1,1,5)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM1S06snVqt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# for j in range(len(d)):\n",
        "#   for i in range(y[j].shape[0]):\n",
        "#     y[j][i,:,:,d[j][2][i]] = 1\n",
        "#   sample = np.zeros((5,1))\n",
        "#   for i in range(5):\n",
        "#     sample[i] = np.sum(y[j][:,:,:,i])\n",
        "#   print(sample/np.sum(sample))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxCdJIZDVyCW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1687f5b3-797f-47e9-dfe3-280814cbadb0"
      },
      "source": [
        "X1 = np.asarray(d[0])\n",
        "X1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10752, 65, 65, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBYXUckLTuwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrJ6E48eVMDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3lxc6ChUb4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# for i in range(len(d)):\n",
        "\n",
        "#     # Create the model based on the model type\n",
        "#     # Create the optimizer\n",
        "#     sgd = optimizers.SGD(lr=.005)\n",
        "\n",
        "\n",
        "#     X1 = np.asarray(d[i][0])\n",
        "#     X2 = np.asarray(d[i][1])\n",
        "\n",
        "#     class_weights = class_weight.compute_class_weight('balanced',\n",
        "#                                                  np.unique(d[i][2]),\n",
        "#                                                  d[i][2])\n",
        "#     m1.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy',f1])\n",
        "\n",
        "#         # Compute quantities required for feature-wise normalization\n",
        "#         # (std, mean, and principal components if ZCA whitening is applied).\n",
        "\n",
        "#         # Fit the model on the batches generated by datagen.flow().\n",
        "#     m1_info = m1.fit([X1,X2],y[i],epochs=20,batch_size=256,class_weight = class_weights)\n",
        "\n",
        "#     m1.save('trial_InputCascade_acc.h5'+ i)\n",
        "\n",
        "#     # Save model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io-L_25ZVyLE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88f94046-8d8c-4873-ec16-ba60a2bd96c9"
      },
      "source": [
        "X2 = np.asarray(d[1])\n",
        "X2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10752, 33, 33, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaYhWGmASZTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HvhUQSKeYD2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bea54644-dee9-4134-81c0-153f0d5b5fa5"
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(d[2]),\n",
        "                                                 d[2])\n",
        "\n",
        "class_weights\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.25460573, 7.99405204, 4.04971751, 1.66826998, 9.90967742])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyMaS5lKV-IE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7345f27b-14c0-42b4-9d85-480773f6c8fa"
      },
      "source": [
        "m1.input_shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(None, 65, 65, 4), (None, 33, 33, 4)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWzLjRGC8BKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM2jJdEDF2Z1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAhIjiTgF4Kd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "deb105f8-32bd-45a7-f194-5501cf910392"
      },
      "source": [
        "#K.clear_session()\n",
        "print(X2.sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11776462582.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5j5CIxK8C_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# m0.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy', f1])\n",
        "# m0_info = m0.fit(X2,y,epochs=100,batch_size=1024,class_weight = class_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgmX8Cj68Rp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "sgd = tf.keras.optimizers.SGD(lr=.001, decay=.01, momentum=.9, clipnorm=1)\n",
        "m1.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy',f1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56sTPTKkxpcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpqersxmFLH8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "2fa07ddb-07ff-4733-afa4-5f3a3e798d22"
      },
      "source": [
        "m1_info = m1.fit([X1,X2],y,epochs=20,batch_size=256,class_weight = class_weights)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 10752 samples\n",
            "Epoch 1/20\n",
            "10752/10752 [==============================] - 35s 3ms/sample - loss: 618376.0060 - acc: 0.4680 - f1: 0.2319\n",
            "Epoch 2/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 289345.4219 - acc: 0.7472 - f1: 0.3743\n",
            "Epoch 3/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 212796.1161 - acc: 0.6785 - f1: 0.4789\n",
            "Epoch 4/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 171972.6648 - acc: 0.6659 - f1: 0.4971\n",
            "Epoch 5/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 147746.9866 - acc: 0.6741 - f1: 0.5156\n",
            "Epoch 6/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 132072.4243 - acc: 0.7099 - f1: 0.5463\n",
            "Epoch 7/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 121005.1382 - acc: 0.7314 - f1: 0.5773\n",
            "Epoch 8/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 112397.2959 - acc: 0.7420 - f1: 0.5907\n",
            "Epoch 9/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 105683.8770 - acc: 0.7580 - f1: 0.6043\n",
            "Epoch 10/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 100177.8752 - acc: 0.7691 - f1: 0.6127\n",
            "Epoch 11/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 95564.7011 - acc: 0.7711 - f1: 0.6270\n",
            "Epoch 12/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 91559.3544 - acc: 0.7837 - f1: 0.6373\n",
            "Epoch 13/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 87974.0253 - acc: 0.7880 - f1: 0.6458\n",
            "Epoch 14/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 84829.6549 - acc: 0.7878 - f1: 0.6518\n",
            "Epoch 15/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 82130.5872 - acc: 0.7973 - f1: 0.6567\n",
            "Epoch 16/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 79690.8378 - acc: 0.7992 - f1: 0.6625\n",
            "Epoch 17/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 77424.9392 - acc: 0.8013 - f1: 0.6676\n",
            "Epoch 18/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 75332.2468 - acc: 0.8000 - f1: 0.6731\n",
            "Epoch 19/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 73438.8666 - acc: 0.8039 - f1: 0.6738\n",
            "Epoch 20/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 71721.8132 - acc: 0.8093 - f1: 0.6806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s-D6eiBXYVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "m1.save('trial_InputCascade_acc.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkqCARxZ9Ibp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.losses\n",
        "keras.losses.custom_loss = f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l2ft5Hk4OJt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "f76b18d8-58f2-4e99-ed48-da5838dbb265"
      },
      "source": [
        "m1 = tf.keras.models.load_model('trial_InputCascade_acc.h5', custom_objects={'f1': f1})\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22jJSWNTVjjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# info = []\n",
        "# for i in range(0,data.shape[0]):\n",
        "#   d = data_gen(data,Y_labels,i,3)\n",
        "#   if(len(d) != 0):\n",
        "#     y = np.zeros((d[2].shape[0],1,1,5))\n",
        "#     for j in range(y.shape[0]):\n",
        "#       y[j,:,:,d[2][j]] = 1\n",
        "#     X1 = d[0]\n",
        "#     X2 = d[1]\n",
        "#     class_weights = class_weight.compute_class_weight('balanced',\n",
        "#                                                       np.unique(d[2]),\n",
        "#                                                       d[2])\n",
        "#     print('slice no:'+str(i))\n",
        "#     info.append(m1.evaluate([X1,X2],y,batch_size=256))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gEcLsnjP0Qg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwUbJ6pCqXfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "hf = h5py.File('info1_input.h5', 'w')\n",
        "hf.create_dataset('dataset_1', data=info)\n",
        "hf.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC_BQb06JEEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hf = h5py.File('info1_input.h5', 'r')\n",
        "X = hf.get('dataset_1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIoo1Y-KJBCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "K.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIL_qdsRShaX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bd152ce9-e079-4a24-f79a-9be05ec9b0fc"
      },
      "source": [
        "fold = os.listdir('/content/drive/My Drive/BRATS-2/Image_Data/HG/')\n",
        "fold.sort(key=str.lower) \n",
        "fold = fold[:3]\n",
        "for path in fold:\n",
        "    print(path)\n",
        "    path = '/content/drive/My Drive/BRATS-2/Image_Data/HG/'+path\n",
        "    p = os.listdir(path)\n",
        "    p.sort(key=str.lower)\n",
        "    arr = []\n",
        "    \n",
        "    # Reading from 4 images and creating 4 channel slice-wise \n",
        "    for i in range(len(p)):\n",
        "      if 'more' in p[i] or 'OT' in p[i]:\n",
        "        if p[i] != '.DS_Store':\n",
        "          p1 = os.listdir(path+'/'+p[i])\n",
        "          img = sitk.ReadImage(path+'/'+p[i]+'/'+p1[0])\n",
        "          Y_labels = sitk.GetArrayFromImage(img) \n",
        "      else:\n",
        "        if p[i] != '.DS_Store':\n",
        "          p1 = os.listdir(path+'/'+p[i])\n",
        "          p1.sort()\n",
        "          img = sitk.ReadImage(path+'/'+p[i]+'/'+p1[-1])\n",
        "          arr.append(sitk.GetArrayFromImage(img))\n",
        "    data = np.zeros((Y_labels.shape[1],Y_labels.shape[0],Y_labels.shape[2],4))\n",
        "    for i in range(Y_labels.shape[1]):\n",
        "      data[i,:,:,0] = arr[0][:,i,:]\n",
        "      data[i,:,:,1] = arr[1][:,i,:]\n",
        "      data[i,:,:,2] = arr[2][:,i,:]\n",
        "      data[i,:,:,3] = arr[3][:,i,:]\n",
        "    print(data.shape)\n",
        "    info = []\n",
        "    print(data.shape[0])\n",
        "    # Creating patches for each slice and training(slice-wise)\n",
        "    for i in range(data.shape[0]):\n",
        "      d = data_gen(data,Y_labels,i,1)\n",
        "      if(len(d) != 0):\n",
        "        y = np.zeros((d[2].shape[0],1,1,5))\n",
        "        for j in range(y.shape[0]):\n",
        "          y[j,:,:,d[2][j]] = 1\n",
        "        X1 = d[0]\n",
        "        X2 = d[1]\n",
        "        class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                          np.unique(d[2]),\n",
        "                                                          d[2])\n",
        "        print('slice no:'+str(i))\n",
        "        info.append(m1.fit([X1,X2],y,epochs=5,batch_size=128,class_weight= class_weights))\n",
        "        m1.save('trial_InputCascade_acc_001].h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0001\n",
            "(216, 176, 160, 4)\n",
            "216\n",
            "slice no:20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 34s 3ms/sample - loss: 59653.5571 - acc: 0.6481 - f1: 0.0434\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 32064.7671 - acc: 0.8883 - f1: 0.0535\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 23501.1536 - acc: 0.9203 - f1: 0.0912\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 18793.9645 - acc: 0.9375 - f1: 0.1415\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15885.0380 - acc: 0.9473 - f1: 0.1953\n",
            "slice no:21\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 17035.5735 - acc: 0.9542 - f1: 0.6776\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14811.9193 - acc: 0.9606 - f1: 0.9084\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13277.1555 - acc: 0.9620 - f1: 0.9226\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12179.0718 - acc: 0.9666 - f1: 0.9349\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11351.8196 - acc: 0.9703 - f1: 0.9402\n",
            "slice no:22\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15527.3711 - acc: 0.9705 - f1: 0.9404\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14307.1722 - acc: 0.9674 - f1: 0.9405\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13424.4090 - acc: 0.9711 - f1: 0.9464\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12754.4758 - acc: 0.9731 - f1: 0.9486\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12220.4791 - acc: 0.9742 - f1: 0.9515\n",
            "slice no:23\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12859.5284 - acc: 0.9753 - f1: 0.9524\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12170.2683 - acc: 0.9765 - f1: 0.9545\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11635.4542 - acc: 0.9756 - f1: 0.9555\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11217.9937 - acc: 0.9773 - f1: 0.9582\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10873.3888 - acc: 0.9807 - f1: 0.9615\n",
            "slice no:24\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 16015.1178 - acc: 0.9795 - f1: 0.9587\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15279.2523 - acc: 0.9787 - f1: 0.9577\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14708.7730 - acc: 0.9801 - f1: 0.9596\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14253.7214 - acc: 0.9785 - f1: 0.9596\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13875.9893 - acc: 0.9815 - f1: 0.9619\n",
            "slice no:25\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13704.4676 - acc: 0.9826 - f1: 0.9648\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13206.5912 - acc: 0.9808 - f1: 0.9641\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12826.2092 - acc: 0.9827 - f1: 0.9662\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12515.7145 - acc: 0.9808 - f1: 0.9669\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12246.9952 - acc: 0.9840 - f1: 0.9683\n",
            "slice no:26\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15957.3164 - acc: 0.9853 - f1: 0.9664\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15493.5946 - acc: 0.9851 - f1: 0.9670\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15137.8771 - acc: 0.9854 - f1: 0.9682\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14828.8252 - acc: 0.9836 - f1: 0.9680\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14564.3201 - acc: 0.9871 - f1: 0.9701\n",
            "slice no:27\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13916.5447 - acc: 0.9845 - f1: 0.9677\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13569.2079 - acc: 0.9856 - f1: 0.9707\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13299.0946 - acc: 0.9873 - f1: 0.9708\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13072.5517 - acc: 0.9863 - f1: 0.9735\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12874.6443 - acc: 0.9872 - f1: 0.9721\n",
            "slice no:28\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 17246.3362 - acc: 0.9875 - f1: 0.9726\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 16884.4385 - acc: 0.9888 - f1: 0.9739\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 16581.3532 - acc: 0.9888 - f1: 0.9735\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 16318.3904 - acc: 0.9890 - f1: 0.9747\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 16078.1091 - acc: 0.9900 - f1: 0.9757\n",
            "slice no:29\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15561.3406 - acc: 0.9893 - f1: 0.9750\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15287.1845 - acc: 0.9914 - f1: 0.9762\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15060.4885 - acc: 0.9894 - f1: 0.9752\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14865.2166 - acc: 0.9907 - f1: 0.9770\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14691.8137 - acc: 0.9919 - f1: 0.9792\n",
            "slice no:30\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 16599.4893 - acc: 0.9928 - f1: 0.9795\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 16336.9485 - acc: 0.9927 - f1: 0.9811\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 16111.7404 - acc: 0.9940 - f1: 0.9825\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15918.7647 - acc: 0.9940 - f1: 0.9818\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15739.9096 - acc: 0.9952 - f1: 0.9844\n",
            "slice no:31\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15246.0287 - acc: 0.9941 - f1: 0.9841\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15028.0638 - acc: 0.9940 - f1: 0.9834\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14847.9559 - acc: 0.9934 - f1: 0.9828\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14690.8889 - acc: 0.9947 - f1: 0.9863\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14549.7059 - acc: 0.9948 - f1: 0.9870\n",
            "slice no:32\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 16502.7628 - acc: 0.9950 - f1: 0.9875\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 16268.4409 - acc: 0.9947 - f1: 0.9875\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 16065.1481 - acc: 0.9955 - f1: 0.9885\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15888.4786 - acc: 0.9964 - f1: 0.9887\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15724.6659 - acc: 0.9955 - f1: 0.9892\n",
            "slice no:33\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15152.4884 - acc: 0.9961 - f1: 0.9891\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14960.1446 - acc: 0.9944 - f1: 0.9885\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14796.1976 - acc: 0.9953 - f1: 0.9892\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14648.7698 - acc: 0.9955 - f1: 0.9900\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14516.0547 - acc: 0.9959 - f1: 0.9897\n",
            "slice no:34\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15270.2179 - acc: 0.9967 - f1: 0.9901\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15091.8108 - acc: 0.9963 - f1: 0.9900\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14936.6754 - acc: 0.9962 - f1: 0.9910\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14798.2523 - acc: 0.9969 - f1: 0.9902\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14671.9885 - acc: 0.9963 - f1: 0.9906\n",
            "slice no:35\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14088.5551 - acc: 0.9967 - f1: 0.9896\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13944.5353 - acc: 0.9969 - f1: 0.9908\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13818.3723 - acc: 0.9967 - f1: 0.9908\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13703.4145 - acc: 0.9968 - f1: 0.9912\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13598.8599 - acc: 0.9968 - f1: 0.9914\n",
            "slice no:36\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14905.7299 - acc: 0.9972 - f1: 0.9912\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14761.9414 - acc: 0.9979 - f1: 0.9924\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14639.6960 - acc: 0.9981 - f1: 0.9929\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14525.4538 - acc: 0.9972 - f1: 0.9911\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14424.0714 - acc: 0.9977 - f1: 0.9917\n",
            "slice no:37\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13907.7736 - acc: 0.9969 - f1: 0.9924\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13794.7482 - acc: 0.9977 - f1: 0.9925\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13698.3974 - acc: 0.9970 - f1: 0.9924\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13609.8477 - acc: 0.9985 - f1: 0.9940\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13530.1442 - acc: 0.9979 - f1: 0.9931\n",
            "slice no:38\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13887.8992 - acc: 0.9984 - f1: 0.9930\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13770.1280 - acc: 0.9976 - f1: 0.9920\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13668.1091 - acc: 0.9975 - f1: 0.9934\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13579.0998 - acc: 0.9975 - f1: 0.9932\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13497.0734 - acc: 0.9980 - f1: 0.9933\n",
            "slice no:39\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12616.8125 - acc: 0.9976 - f1: 0.9917\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12521.4491 - acc: 0.9977 - f1: 0.9928\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12440.2267 - acc: 0.9979 - f1: 0.9925\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12368.6655 - acc: 0.9975 - f1: 0.9919\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12303.1760 - acc: 0.9980 - f1: 0.9922\n",
            "slice no:40\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13105.7911 - acc: 0.9980 - f1: 0.9944\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13012.9534 - acc: 0.9979 - f1: 0.9930\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12931.0479 - acc: 0.9988 - f1: 0.9943\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12858.4852 - acc: 0.9974 - f1: 0.9935\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12792.3877 - acc: 0.9987 - f1: 0.9935\n",
            "slice no:41\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12244.6428 - acc: 0.9973 - f1: 0.9930\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12162.4798 - acc: 0.9976 - f1: 0.9941\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12092.1595 - acc: 0.9981 - f1: 0.9931\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12028.3584 - acc: 0.9978 - f1: 0.9930\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11970.5581 - acc: 0.9980 - f1: 0.9933\n",
            "slice no:42\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12980.6902 - acc: 0.9984 - f1: 0.9941\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12896.1134 - acc: 0.9988 - f1: 0.9943\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12821.6228 - acc: 0.9980 - f1: 0.9938\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12753.3694 - acc: 0.9980 - f1: 0.9939\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12691.4947 - acc: 0.9980 - f1: 0.9941\n",
            "slice no:43\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12589.7450 - acc: 0.9983 - f1: 0.9938\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12514.1121 - acc: 0.9986 - f1: 0.9954\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12447.6995 - acc: 0.9978 - f1: 0.9945\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12387.1647 - acc: 0.9983 - f1: 0.9938\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12328.4312 - acc: 0.9986 - f1: 0.9951\n",
            "slice no:44\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12922.4087 - acc: 0.9982 - f1: 0.9945\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12836.9585 - acc: 0.9983 - f1: 0.9945\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12764.2589 - acc: 0.9988 - f1: 0.9944\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12696.7997 - acc: 0.9987 - f1: 0.9938\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12632.3118 - acc: 0.9986 - f1: 0.9948\n",
            "slice no:45\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12430.4304 - acc: 0.9984 - f1: 0.9951\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12357.3320 - acc: 0.9985 - f1: 0.9949\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12295.1765 - acc: 0.9984 - f1: 0.9949\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12235.4546 - acc: 0.9983 - f1: 0.9956\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12179.1893 - acc: 0.9988 - f1: 0.9951\n",
            "slice no:46\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12609.5634 - acc: 0.9980 - f1: 0.9947\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12531.6489 - acc: 0.9976 - f1: 0.9935\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12464.6109 - acc: 0.9979 - f1: 0.9940\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12403.8862 - acc: 0.9970 - f1: 0.9936\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12347.4273 - acc: 0.9980 - f1: 0.9948\n",
            "slice no:47\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12058.3373 - acc: 0.9981 - f1: 0.9948\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11995.2365 - acc: 0.9987 - f1: 0.9950\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11941.3745 - acc: 0.9975 - f1: 0.9948\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11890.7256 - acc: 0.9988 - f1: 0.9958\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11843.3307 - acc: 0.9980 - f1: 0.9951\n",
            "slice no:48\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12706.7633 - acc: 0.9982 - f1: 0.9958\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12639.5072 - acc: 0.9985 - f1: 0.9962\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12580.9283 - acc: 0.9985 - f1: 0.9962\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12526.8436 - acc: 0.9983 - f1: 0.9959\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12476.6365 - acc: 0.9988 - f1: 0.9964\n",
            "slice no:49\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12455.8044 - acc: 0.9989 - f1: 0.9963\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12392.2785 - acc: 0.9983 - f1: 0.9959\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12337.3756 - acc: 0.9989 - f1: 0.9959\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12287.1363 - acc: 0.9985 - f1: 0.9957\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12239.5131 - acc: 0.9988 - f1: 0.9967\n",
            "slice no:50\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12426.4821 - acc: 0.9986 - f1: 0.9963\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12368.5408 - acc: 0.9984 - f1: 0.9957\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12317.5251 - acc: 0.9980 - f1: 0.9953\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12270.0824 - acc: 0.9985 - f1: 0.9959\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12226.2271 - acc: 0.9984 - f1: 0.9957\n",
            "slice no:51\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11861.6813 - acc: 0.9981 - f1: 0.9954\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11809.0774 - acc: 0.9988 - f1: 0.9960\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11763.2734 - acc: 0.9982 - f1: 0.9954\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11720.9378 - acc: 0.9992 - f1: 0.9963\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11681.6359 - acc: 0.9977 - f1: 0.9956\n",
            "slice no:52\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11283.1903 - acc: 0.9974 - f1: 0.9945\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11235.4527 - acc: 0.9978 - f1: 0.9953\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11193.5541 - acc: 0.9979 - f1: 0.9947\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11153.4515 - acc: 0.9981 - f1: 0.9951\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11116.6035 - acc: 0.9980 - f1: 0.9956\n",
            "slice no:53\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10979.8795 - acc: 0.9977 - f1: 0.9948\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10934.6607 - acc: 0.9978 - f1: 0.9946\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10894.8278 - acc: 0.9983 - f1: 0.9960\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10858.3450 - acc: 0.9972 - f1: 0.9949\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10823.7335 - acc: 0.9974 - f1: 0.9946\n",
            "slice no:54\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11158.1445 - acc: 0.9972 - f1: 0.9948\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11111.9733 - acc: 0.9966 - f1: 0.9941\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11070.2653 - acc: 0.9970 - f1: 0.9939\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11031.1489 - acc: 0.9981 - f1: 0.9954\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10995.4040 - acc: 0.9974 - f1: 0.9947\n",
            "slice no:55\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11090.9581 - acc: 0.9962 - f1: 0.9928\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11042.9807 - acc: 0.9968 - f1: 0.9947\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11001.1888 - acc: 0.9966 - f1: 0.9939\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10963.2974 - acc: 0.9960 - f1: 0.9936\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10928.4061 - acc: 0.9966 - f1: 0.9933\n",
            "slice no:56\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11338.0879 - acc: 0.9960 - f1: 0.9925\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11287.8903 - acc: 0.9954 - f1: 0.9928\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11246.0505 - acc: 0.9957 - f1: 0.9930\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11206.6396 - acc: 0.9944 - f1: 0.9918\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11169.7882 - acc: 0.9956 - f1: 0.9934\n",
            "slice no:57\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11491.7257 - acc: 0.9960 - f1: 0.9926\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11445.1585 - acc: 0.9957 - f1: 0.9927\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11403.9289 - acc: 0.9959 - f1: 0.9935\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11366.1070 - acc: 0.9955 - f1: 0.9928\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11331.6157 - acc: 0.9956 - f1: 0.9930\n",
            "slice no:58\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11761.3136 - acc: 0.9946 - f1: 0.9926\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11713.4315 - acc: 0.9950 - f1: 0.9928\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11671.3838 - acc: 0.9944 - f1: 0.9923\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11633.1311 - acc: 0.9939 - f1: 0.9914\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11597.0914 - acc: 0.9953 - f1: 0.9931\n",
            "slice no:59\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12584.9176 - acc: 0.9914 - f1: 0.9903\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12536.6613 - acc: 0.9921 - f1: 0.9908\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12493.5873 - acc: 0.9919 - f1: 0.9905\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12452.8460 - acc: 0.9919 - f1: 0.9915\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12413.4051 - acc: 0.9919 - f1: 0.9908\n",
            "slice no:60\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13194.9992 - acc: 0.9887 - f1: 0.9869\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13136.5117 - acc: 0.9902 - f1: 0.9880\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13085.1286 - acc: 0.9892 - f1: 0.9883\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13038.3149 - acc: 0.9886 - f1: 0.9875\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12993.3331 - acc: 0.9890 - f1: 0.9875\n",
            "slice no:61\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12648.5921 - acc: 0.9837 - f1: 0.9821\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12596.2679 - acc: 0.9837 - f1: 0.9819\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12551.4961 - acc: 0.9841 - f1: 0.9823\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12510.1965 - acc: 0.9835 - f1: 0.9823\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12470.9450 - acc: 0.9833 - f1: 0.9811\n",
            "slice no:62\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13522.9828 - acc: 0.9767 - f1: 0.9750\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13468.1128 - acc: 0.9767 - f1: 0.9747\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13420.3562 - acc: 0.9750 - f1: 0.9736\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13374.9614 - acc: 0.9764 - f1: 0.9754\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13331.9935 - acc: 0.9767 - f1: 0.9749\n",
            "slice no:63\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13551.9239 - acc: 0.9661 - f1: 0.9639\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13497.5204 - acc: 0.9657 - f1: 0.9638\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13447.7221 - acc: 0.9652 - f1: 0.9635\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13403.7667 - acc: 0.9671 - f1: 0.9657\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13360.7912 - acc: 0.9663 - f1: 0.9643\n",
            "slice no:64\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14748.2150 - acc: 0.9559 - f1: 0.9545\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14686.5653 - acc: 0.9562 - f1: 0.9562\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14632.4144 - acc: 0.9552 - f1: 0.9548\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14582.8596 - acc: 0.9573 - f1: 0.9551\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14537.9788 - acc: 0.9568 - f1: 0.9558\n",
            "slice no:65\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14996.4693 - acc: 0.9485 - f1: 0.9467\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14926.6949 - acc: 0.9474 - f1: 0.9474\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14866.3409 - acc: 0.9470 - f1: 0.9460\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14810.5497 - acc: 0.9481 - f1: 0.9470\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14757.9006 - acc: 0.9480 - f1: 0.9479\n",
            "slice no:66\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14785.7949 - acc: 0.9420 - f1: 0.9430\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14724.3572 - acc: 0.9423 - f1: 0.9421\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14669.7903 - acc: 0.9421 - f1: 0.9424\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14619.4749 - acc: 0.9426 - f1: 0.9434\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14571.0259 - acc: 0.9432 - f1: 0.9428\n",
            "slice no:67\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14531.5534 - acc: 0.9362 - f1: 0.9362\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14472.1211 - acc: 0.9359 - f1: 0.9362\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14419.3577 - acc: 0.9359 - f1: 0.9392\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14369.1424 - acc: 0.9352 - f1: 0.9382\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14321.8720 - acc: 0.9383 - f1: 0.9383\n",
            "slice no:68\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14650.4717 - acc: 0.9327 - f1: 0.9330\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14595.5038 - acc: 0.9307 - f1: 0.9320\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14546.0063 - acc: 0.9317 - f1: 0.9332\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14499.6005 - acc: 0.9317 - f1: 0.9317\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14455.2691 - acc: 0.9326 - f1: 0.9322\n",
            "slice no:69\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14402.8054 - acc: 0.9270 - f1: 0.9287\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14350.2161 - acc: 0.9273 - f1: 0.9271\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14304.4312 - acc: 0.9276 - f1: 0.9294\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14261.0805 - acc: 0.9261 - f1: 0.9282\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14220.1309 - acc: 0.9271 - f1: 0.9288\n",
            "slice no:70\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14681.9667 - acc: 0.9197 - f1: 0.9216\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14629.5251 - acc: 0.9210 - f1: 0.9216\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14583.1860 - acc: 0.9192 - f1: 0.9232\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14539.8225 - acc: 0.9196 - f1: 0.9212\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14499.2105 - acc: 0.9206 - f1: 0.9223\n",
            "slice no:71\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14239.1931 - acc: 0.9174 - f1: 0.9183\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14186.9246 - acc: 0.9172 - f1: 0.9180\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14141.5876 - acc: 0.9170 - f1: 0.9184\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14100.1308 - acc: 0.9167 - f1: 0.9182\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14060.7914 - acc: 0.9180 - f1: 0.9192\n",
            "slice no:72\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14561.9158 - acc: 0.9111 - f1: 0.9121\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14510.3933 - acc: 0.9118 - f1: 0.9117\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14464.3484 - acc: 0.9107 - f1: 0.9121\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14421.5921 - acc: 0.9116 - f1: 0.9126\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14381.3092 - acc: 0.9107 - f1: 0.9099\n",
            "slice no:73\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14387.0824 - acc: 0.9100 - f1: 0.9105\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14337.1684 - acc: 0.9089 - f1: 0.9097\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14292.3951 - acc: 0.9097 - f1: 0.9099\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14250.2450 - acc: 0.9089 - f1: 0.9097\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14210.9917 - acc: 0.9094 - f1: 0.9103\n",
            "slice no:74\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14979.9823 - acc: 0.9033 - f1: 0.9014\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14924.0975 - acc: 0.9016 - f1: 0.9018\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14874.6077 - acc: 0.9013 - f1: 0.9000\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14828.1138 - acc: 0.9018 - f1: 0.8990\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14785.1360 - acc: 0.9047 - f1: 0.9026\n",
            "slice no:75\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14849.2222 - acc: 0.8982 - f1: 0.8977\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14796.3560 - acc: 0.8987 - f1: 0.8978\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14747.4944 - acc: 0.8967 - f1: 0.8959\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14703.1816 - acc: 0.8969 - f1: 0.8954\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14660.1061 - acc: 0.8981 - f1: 0.8970\n",
            "slice no:76\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15247.4487 - acc: 0.8928 - f1: 0.8911\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15189.2559 - acc: 0.8937 - f1: 0.8900\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15136.3949 - acc: 0.8925 - f1: 0.8906\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15087.9110 - acc: 0.8924 - f1: 0.8914\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15041.3430 - acc: 0.8930 - f1: 0.8904\n",
            "slice no:77\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14824.4191 - acc: 0.8888 - f1: 0.8876\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14770.3461 - acc: 0.8876 - f1: 0.8856\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14721.7722 - acc: 0.8898 - f1: 0.8888\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14676.1709 - acc: 0.8891 - f1: 0.8864\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14633.7217 - acc: 0.8903 - f1: 0.8882\n",
            "slice no:78\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15025.3910 - acc: 0.8853 - f1: 0.8846\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14974.6177 - acc: 0.8855 - f1: 0.8854\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14929.7940 - acc: 0.8871 - f1: 0.8863\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14888.2382 - acc: 0.8870 - f1: 0.8854\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14848.6065 - acc: 0.8845 - f1: 0.8843\n",
            "slice no:79\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15056.4177 - acc: 0.8836 - f1: 0.8826\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15008.7352 - acc: 0.8830 - f1: 0.8824\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14967.0190 - acc: 0.8830 - f1: 0.8817\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14927.9764 - acc: 0.8823 - f1: 0.8814\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14890.9240 - acc: 0.8832 - f1: 0.8822\n",
            "slice no:80\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15332.9726 - acc: 0.8790 - f1: 0.8780\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15285.2054 - acc: 0.8810 - f1: 0.8791\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15241.2949 - acc: 0.8803 - f1: 0.8804\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15200.2842 - acc: 0.8810 - f1: 0.8810\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15161.7780 - acc: 0.8820 - f1: 0.8795\n",
            "slice no:81\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15500.4681 - acc: 0.8789 - f1: 0.8785\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15455.6604 - acc: 0.8786 - f1: 0.8753\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15415.8858 - acc: 0.8775 - f1: 0.8757\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15379.4764 - acc: 0.8775 - f1: 0.8771\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15343.6223 - acc: 0.8789 - f1: 0.8766\n",
            "slice no:82\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15462.3779 - acc: 0.8739 - f1: 0.8715\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15417.7373 - acc: 0.8746 - f1: 0.8726\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15378.7152 - acc: 0.8756 - f1: 0.8728\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15341.9160 - acc: 0.8745 - f1: 0.8713\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15306.1097 - acc: 0.8757 - f1: 0.8723\n",
            "slice no:83\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15217.0413 - acc: 0.8730 - f1: 0.8695\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15175.4917 - acc: 0.8721 - f1: 0.8691\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15138.3209 - acc: 0.8728 - f1: 0.8698\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15103.5134 - acc: 0.8732 - f1: 0.8705\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 15070.0981 - acc: 0.8741 - f1: 0.8709\n",
            "slice no:84\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14815.7150 - acc: 0.8690 - f1: 0.8661\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14773.0542 - acc: 0.8692 - f1: 0.8670\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14735.4951 - acc: 0.8694 - f1: 0.8656\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14699.6291 - acc: 0.8677 - f1: 0.8656\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14665.6157 - acc: 0.8705 - f1: 0.8680\n",
            "slice no:85\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14578.1890 - acc: 0.8658 - f1: 0.8619\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14535.9401 - acc: 0.8657 - f1: 0.8619\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14497.9104 - acc: 0.8672 - f1: 0.8639\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14462.2060 - acc: 0.8663 - f1: 0.8618\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14427.5260 - acc: 0.8658 - f1: 0.8625\n",
            "slice no:86\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14644.1215 - acc: 0.8638 - f1: 0.8615\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14601.0751 - acc: 0.8655 - f1: 0.8607\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14562.5116 - acc: 0.8635 - f1: 0.8613\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14526.3886 - acc: 0.8641 - f1: 0.8618\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14493.0643 - acc: 0.8647 - f1: 0.8615\n",
            "slice no:87\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14592.1875 - acc: 0.8610 - f1: 0.8579\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14548.0011 - acc: 0.8619 - f1: 0.8586\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14509.1421 - acc: 0.8607 - f1: 0.8575\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14473.2508 - acc: 0.8611 - f1: 0.8570\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14438.7102 - acc: 0.8616 - f1: 0.8579\n",
            "slice no:88\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14912.5763 - acc: 0.8582 - f1: 0.8558\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14870.8092 - acc: 0.8587 - f1: 0.8556\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14832.8599 - acc: 0.8585 - f1: 0.8553\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14798.2994 - acc: 0.8582 - f1: 0.8543\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14765.1095 - acc: 0.8584 - f1: 0.8559\n",
            "slice no:89\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14105.7881 - acc: 0.8577 - f1: 0.8554\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14066.1011 - acc: 0.8573 - f1: 0.8564\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 14031.0809 - acc: 0.8583 - f1: 0.8561\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13999.4931 - acc: 0.8592 - f1: 0.8567\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13969.1575 - acc: 0.8578 - f1: 0.8563\n",
            "slice no:90\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13946.6345 - acc: 0.8573 - f1: 0.8568\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13910.6425 - acc: 0.8574 - f1: 0.8557\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13877.5307 - acc: 0.8570 - f1: 0.8565\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13847.3828 - acc: 0.8568 - f1: 0.8557\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13818.6363 - acc: 0.8582 - f1: 0.8568\n",
            "slice no:91\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13861.5433 - acc: 0.8567 - f1: 0.8566\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13827.3624 - acc: 0.8570 - f1: 0.8552\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13796.9894 - acc: 0.8570 - f1: 0.8550\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13768.9180 - acc: 0.8574 - f1: 0.8562\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13741.7864 - acc: 0.8575 - f1: 0.8552\n",
            "slice no:92\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13912.5309 - acc: 0.8575 - f1: 0.8539\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13879.5949 - acc: 0.8557 - f1: 0.8528\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13849.5733 - acc: 0.8558 - f1: 0.8534\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13821.7940 - acc: 0.8558 - f1: 0.8534\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13795.3371 - acc: 0.8562 - f1: 0.8533\n",
            "slice no:93\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13496.9010 - acc: 0.8578 - f1: 0.8540\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13466.5288 - acc: 0.8575 - f1: 0.8538\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13439.7510 - acc: 0.8564 - f1: 0.8529\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13414.0096 - acc: 0.8581 - f1: 0.8545\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13389.8647 - acc: 0.8576 - f1: 0.8533\n",
            "slice no:94\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13595.8416 - acc: 0.8578 - f1: 0.8530\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13565.0580 - acc: 0.8575 - f1: 0.8535\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13537.5289 - acc: 0.8582 - f1: 0.8536\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13511.5808 - acc: 0.8567 - f1: 0.8530\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13487.2344 - acc: 0.8582 - f1: 0.8539\n",
            "slice no:95\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13172.4942 - acc: 0.8594 - f1: 0.8546\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13142.8012 - acc: 0.8597 - f1: 0.8542\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13116.2426 - acc: 0.8607 - f1: 0.8539\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13091.6513 - acc: 0.8591 - f1: 0.8525\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13068.8147 - acc: 0.8611 - f1: 0.8549\n",
            "slice no:96\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13216.0083 - acc: 0.8585 - f1: 0.8501\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13185.5616 - acc: 0.8577 - f1: 0.8515\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 13159.2569 - acc: 0.8597 - f1: 0.8520\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13134.5698 - acc: 0.8607 - f1: 0.8542\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13111.0326 - acc: 0.8588 - f1: 0.8522\n",
            "slice no:97\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12994.0708 - acc: 0.8607 - f1: 0.8543\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12964.8774 - acc: 0.8603 - f1: 0.8528\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12939.2697 - acc: 0.8610 - f1: 0.8526\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12915.9308 - acc: 0.8604 - f1: 0.8531\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12893.0080 - acc: 0.8603 - f1: 0.8537\n",
            "slice no:98\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12660.1244 - acc: 0.8626 - f1: 0.8562\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12630.7168 - acc: 0.8619 - f1: 0.8552\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12605.2367 - acc: 0.8616 - f1: 0.8546\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12581.2109 - acc: 0.8613 - f1: 0.8564\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12558.6998 - acc: 0.8606 - f1: 0.8548\n",
            "slice no:99\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12418.5748 - acc: 0.8613 - f1: 0.8555\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12390.9399 - acc: 0.8605 - f1: 0.8544\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12367.2956 - acc: 0.8610 - f1: 0.8561\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12345.4749 - acc: 0.8613 - f1: 0.8543\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12324.2072 - acc: 0.8622 - f1: 0.8562\n",
            "slice no:100\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12809.5994 - acc: 0.8597 - f1: 0.8539\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12780.2758 - acc: 0.8580 - f1: 0.8531\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12754.1912 - acc: 0.8600 - f1: 0.8544\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12729.8058 - acc: 0.8610 - f1: 0.8554\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12707.1917 - acc: 0.8601 - f1: 0.8546\n",
            "slice no:101\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12457.4875 - acc: 0.8620 - f1: 0.8572\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12429.7503 - acc: 0.8607 - f1: 0.8550\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12405.4140 - acc: 0.8621 - f1: 0.8566\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12382.9460 - acc: 0.8623 - f1: 0.8570\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 12362.1558 - acc: 0.8622 - f1: 0.8577\n",
            "slice no:102\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11981.4197 - acc: 0.8687 - f1: 0.8628\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11955.7209 - acc: 0.8677 - f1: 0.8619\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11933.6111 - acc: 0.8681 - f1: 0.8619\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11912.8905 - acc: 0.8680 - f1: 0.8627\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11894.0770 - acc: 0.8682 - f1: 0.8620\n",
            "slice no:103\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11164.9223 - acc: 0.8710 - f1: 0.8653\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11141.0107 - acc: 0.8705 - f1: 0.8657\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11120.3911 - acc: 0.8719 - f1: 0.8657\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11101.4144 - acc: 0.8704 - f1: 0.8652\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11083.2683 - acc: 0.8695 - f1: 0.8634\n",
            "slice no:104\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10958.9063 - acc: 0.8719 - f1: 0.8666\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10935.0946 - acc: 0.8724 - f1: 0.8661\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10914.5306 - acc: 0.8723 - f1: 0.8669\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10895.8625 - acc: 0.8719 - f1: 0.8674\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10877.5946 - acc: 0.8730 - f1: 0.8674\n",
            "slice no:105\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10912.0199 - acc: 0.8736 - f1: 0.8681\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10889.6016 - acc: 0.8740 - f1: 0.8690\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10870.4267 - acc: 0.8743 - f1: 0.8687\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10852.3567 - acc: 0.8741 - f1: 0.8683\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10835.0203 - acc: 0.8748 - f1: 0.8693\n",
            "slice no:106\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10983.5803 - acc: 0.8770 - f1: 0.8730\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10961.6443 - acc: 0.8777 - f1: 0.8726\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10941.8911 - acc: 0.8773 - f1: 0.8722\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10923.9388 - acc: 0.8780 - f1: 0.8731\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10906.9758 - acc: 0.8779 - f1: 0.8719\n",
            "slice no:107\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10732.7242 - acc: 0.8786 - f1: 0.8727\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10711.0789 - acc: 0.8789 - f1: 0.8734\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10691.5123 - acc: 0.8785 - f1: 0.8728\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10673.1583 - acc: 0.8774 - f1: 0.8728\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10655.9741 - acc: 0.8785 - f1: 0.8728\n",
            "slice no:108\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10485.6253 - acc: 0.8803 - f1: 0.8740\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10465.0638 - acc: 0.8811 - f1: 0.8749\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10447.0080 - acc: 0.8808 - f1: 0.8747\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10430.5595 - acc: 0.8810 - f1: 0.8742\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10414.7174 - acc: 0.8812 - f1: 0.8758\n",
            "slice no:109\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10353.5636 - acc: 0.8822 - f1: 0.8772\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10333.4272 - acc: 0.8819 - f1: 0.8762\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10315.6765 - acc: 0.8831 - f1: 0.8775\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10299.3241 - acc: 0.8828 - f1: 0.8769\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10283.6838 - acc: 0.8830 - f1: 0.8778\n",
            "slice no:110\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10467.9261 - acc: 0.8861 - f1: 0.8805\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10448.4030 - acc: 0.8864 - f1: 0.8811\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10430.9827 - acc: 0.8859 - f1: 0.8805\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10414.5794 - acc: 0.8859 - f1: 0.8804\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10398.8746 - acc: 0.8851 - f1: 0.8812\n",
            "slice no:111\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10531.3777 - acc: 0.8891 - f1: 0.8846\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10511.8080 - acc: 0.8896 - f1: 0.8842\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10494.5119 - acc: 0.8895 - f1: 0.8850\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10478.0127 - acc: 0.8890 - f1: 0.8848\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10462.1193 - acc: 0.8890 - f1: 0.8853\n",
            "slice no:112\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10623.3308 - acc: 0.8922 - f1: 0.8877\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10603.7999 - acc: 0.8926 - f1: 0.8883\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10585.5359 - acc: 0.8930 - f1: 0.8886\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10568.7315 - acc: 0.8930 - f1: 0.8894\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10553.4166 - acc: 0.8923 - f1: 0.8883\n",
            "slice no:113\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10701.3123 - acc: 0.8951 - f1: 0.8917\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10680.9179 - acc: 0.8950 - f1: 0.8925\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10663.4724 - acc: 0.8954 - f1: 0.8915\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10646.4857 - acc: 0.8953 - f1: 0.8917\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10630.3808 - acc: 0.8956 - f1: 0.8928\n",
            "slice no:114\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10668.1943 - acc: 0.8976 - f1: 0.8949\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10648.5612 - acc: 0.8974 - f1: 0.8952\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10630.6398 - acc: 0.8970 - f1: 0.8948\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10613.2312 - acc: 0.8977 - f1: 0.8953\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10597.0197 - acc: 0.8977 - f1: 0.8950\n",
            "slice no:115\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10993.9619 - acc: 0.8999 - f1: 0.8976\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10972.7307 - acc: 0.9003 - f1: 0.8980\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10953.9205 - acc: 0.9004 - f1: 0.8973\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10936.2887 - acc: 0.9006 - f1: 0.8982\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10919.4201 - acc: 0.9006 - f1: 0.8979\n",
            "slice no:116\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11175.6921 - acc: 0.9007 - f1: 0.8981\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11154.5207 - acc: 0.9006 - f1: 0.8986\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11136.0122 - acc: 0.9004 - f1: 0.8977\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11118.5115 - acc: 0.9012 - f1: 0.8978\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11101.5323 - acc: 0.9005 - f1: 0.8978\n",
            "slice no:117\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10959.4845 - acc: 0.9001 - f1: 0.8979\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10939.1153 - acc: 0.9001 - f1: 0.8986\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10921.2569 - acc: 0.9006 - f1: 0.8982\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10904.6746 - acc: 0.9003 - f1: 0.8973\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10888.5300 - acc: 0.9001 - f1: 0.8978\n",
            "slice no:118\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11189.5219 - acc: 0.8994 - f1: 0.8971\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11168.6850 - acc: 0.9002 - f1: 0.8972\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11150.0590 - acc: 0.8996 - f1: 0.8965\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11132.9444 - acc: 0.9002 - f1: 0.8980\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11117.1805 - acc: 0.9003 - f1: 0.8982\n",
            "slice no:119\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10802.9015 - acc: 0.9009 - f1: 0.8987\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10782.1241 - acc: 0.9015 - f1: 0.8985\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10763.6971 - acc: 0.9009 - f1: 0.8981\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10746.5630 - acc: 0.9010 - f1: 0.8982\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10730.3549 - acc: 0.9011 - f1: 0.8988\n",
            "slice no:120\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10962.6061 - acc: 0.9041 - f1: 0.9010\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10942.2148 - acc: 0.9032 - f1: 0.9010\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10924.5842 - acc: 0.9040 - f1: 0.9005\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10908.1958 - acc: 0.9036 - f1: 0.9000\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10892.7717 - acc: 0.9039 - f1: 0.9009\n",
            "slice no:121\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10997.4153 - acc: 0.9058 - f1: 0.9030\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10977.2558 - acc: 0.9053 - f1: 0.9017\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10959.2133 - acc: 0.9051 - f1: 0.9019\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10942.5127 - acc: 0.9058 - f1: 0.9029\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10926.9260 - acc: 0.9062 - f1: 0.9031\n",
            "slice no:122\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11315.1010 - acc: 0.9096 - f1: 0.9077\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11293.9525 - acc: 0.9095 - f1: 0.9072\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11275.2455 - acc: 0.9097 - f1: 0.9068\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11257.9487 - acc: 0.9100 - f1: 0.9072\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11241.7248 - acc: 0.9091 - f1: 0.9074\n",
            "slice no:123\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11435.1062 - acc: 0.9121 - f1: 0.9095\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11414.0538 - acc: 0.9127 - f1: 0.9107\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11395.1049 - acc: 0.9128 - f1: 0.9106\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11377.3553 - acc: 0.9129 - f1: 0.9101\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11360.7456 - acc: 0.9124 - f1: 0.9108\n",
            "slice no:124\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11118.5713 - acc: 0.9150 - f1: 0.9122\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11097.4855 - acc: 0.9152 - f1: 0.9121\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11078.8705 - acc: 0.9152 - f1: 0.9110\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11061.2468 - acc: 0.9152 - f1: 0.9116\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11044.7078 - acc: 0.9153 - f1: 0.9124\n",
            "slice no:125\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11081.7528 - acc: 0.9175 - f1: 0.9143\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11060.6313 - acc: 0.9167 - f1: 0.9139\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11042.0624 - acc: 0.9169 - f1: 0.9132\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11024.9814 - acc: 0.9169 - f1: 0.9133\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11008.7089 - acc: 0.9172 - f1: 0.9143\n",
            "slice no:126\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11639.9624 - acc: 0.9182 - f1: 0.9149\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11618.3521 - acc: 0.9184 - f1: 0.9146\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11599.2090 - acc: 0.9174 - f1: 0.9144\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11581.3685 - acc: 0.9183 - f1: 0.9148\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11564.4810 - acc: 0.9181 - f1: 0.9154\n",
            "slice no:127\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11763.7026 - acc: 0.9194 - f1: 0.9163\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11741.1081 - acc: 0.9195 - f1: 0.9161\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11721.2324 - acc: 0.9203 - f1: 0.9165\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11702.8551 - acc: 0.9197 - f1: 0.9168\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11685.6010 - acc: 0.9192 - f1: 0.9152\n",
            "slice no:128\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11698.1372 - acc: 0.9200 - f1: 0.9165\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11676.0837 - acc: 0.9202 - f1: 0.9175\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11656.5830 - acc: 0.9209 - f1: 0.9171\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11638.0408 - acc: 0.9208 - f1: 0.9170\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11620.1567 - acc: 0.9201 - f1: 0.9172\n",
            "slice no:129\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11634.8545 - acc: 0.9215 - f1: 0.9179\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11613.6109 - acc: 0.9214 - f1: 0.9178\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11594.5817 - acc: 0.9218 - f1: 0.9181\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11576.8311 - acc: 0.9215 - f1: 0.9184\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11559.8111 - acc: 0.9218 - f1: 0.9188\n",
            "slice no:130\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11566.9669 - acc: 0.9216 - f1: 0.9177\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11546.5685 - acc: 0.9221 - f1: 0.9182\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11527.7502 - acc: 0.9213 - f1: 0.9185\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11509.9475 - acc: 0.9222 - f1: 0.9185\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11493.4189 - acc: 0.9220 - f1: 0.9183\n",
            "slice no:131\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11669.2356 - acc: 0.9204 - f1: 0.9175\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11648.1504 - acc: 0.9203 - f1: 0.9184\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11628.8336 - acc: 0.9202 - f1: 0.9176\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11611.1870 - acc: 0.9201 - f1: 0.9174\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11594.7551 - acc: 0.9207 - f1: 0.9183\n",
            "slice no:132\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11810.4119 - acc: 0.9191 - f1: 0.9157\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11788.8805 - acc: 0.9180 - f1: 0.9157\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11769.5276 - acc: 0.9178 - f1: 0.9153\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11750.9824 - acc: 0.9185 - f1: 0.9162\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11733.6998 - acc: 0.9184 - f1: 0.9162\n",
            "slice no:133\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11761.2617 - acc: 0.9194 - f1: 0.9173\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11740.1177 - acc: 0.9198 - f1: 0.9179\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11720.9360 - acc: 0.9201 - f1: 0.9175\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11702.8231 - acc: 0.9195 - f1: 0.9171\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11685.9437 - acc: 0.9199 - f1: 0.9181\n",
            "slice no:134\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11624.8293 - acc: 0.9218 - f1: 0.9201\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11603.4536 - acc: 0.9215 - f1: 0.9197\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11584.3020 - acc: 0.9218 - f1: 0.9196\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11565.4020 - acc: 0.9224 - f1: 0.9203\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11547.3361 - acc: 0.9214 - f1: 0.9196\n",
            "slice no:135\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11546.0338 - acc: 0.9242 - f1: 0.9219\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11524.3767 - acc: 0.9245 - f1: 0.9225\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11505.5154 - acc: 0.9244 - f1: 0.9222\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11487.4571 - acc: 0.9242 - f1: 0.9225\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11469.7285 - acc: 0.9244 - f1: 0.9231\n",
            "slice no:136\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11304.4956 - acc: 0.9280 - f1: 0.9262\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11283.7940 - acc: 0.9275 - f1: 0.9253\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11265.7041 - acc: 0.9280 - f1: 0.9256\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11248.6321 - acc: 0.9278 - f1: 0.9255\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11231.8619 - acc: 0.9272 - f1: 0.9259\n",
            "slice no:137\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11336.7872 - acc: 0.9336 - f1: 0.9319\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11316.0161 - acc: 0.9339 - f1: 0.9316\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11297.3845 - acc: 0.9329 - f1: 0.9307\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11279.6369 - acc: 0.9337 - f1: 0.9316\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11262.8393 - acc: 0.9338 - f1: 0.9319\n",
            "slice no:138\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11207.0946 - acc: 0.9436 - f1: 0.9421\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11187.4606 - acc: 0.9444 - f1: 0.9418\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11169.7774 - acc: 0.9441 - f1: 0.9419\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11153.0427 - acc: 0.9442 - f1: 0.9424\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11136.9593 - acc: 0.9435 - f1: 0.9411\n",
            "slice no:139\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11064.6931 - acc: 0.9527 - f1: 0.9503\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11044.8572 - acc: 0.9528 - f1: 0.9506\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11027.2348 - acc: 0.9525 - f1: 0.9508\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 11010.5007 - acc: 0.9522 - f1: 0.9504\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10994.7133 - acc: 0.9530 - f1: 0.9509\n",
            "slice no:140\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10920.7645 - acc: 0.9595 - f1: 0.9570\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10901.2395 - acc: 0.9592 - f1: 0.9571\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10884.2509 - acc: 0.9590 - f1: 0.9568\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10868.1259 - acc: 0.9594 - f1: 0.9571\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10852.5898 - acc: 0.9591 - f1: 0.9570\n",
            "slice no:141\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10680.8611 - acc: 0.9673 - f1: 0.9653\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10662.1457 - acc: 0.9672 - f1: 0.9654\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10645.6633 - acc: 0.9672 - f1: 0.9649\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10630.0522 - acc: 0.9675 - f1: 0.9649\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10614.9118 - acc: 0.9666 - f1: 0.9646\n",
            "slice no:142\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10551.0156 - acc: 0.9769 - f1: 0.9745\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10533.3384 - acc: 0.9764 - f1: 0.9750\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10517.2568 - acc: 0.9771 - f1: 0.9748\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10502.2815 - acc: 0.9777 - f1: 0.9750\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10488.2443 - acc: 0.9777 - f1: 0.9751\n",
            "slice no:143\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10266.2754 - acc: 0.9868 - f1: 0.9840\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10248.9361 - acc: 0.9867 - f1: 0.9833\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10233.3491 - acc: 0.9865 - f1: 0.9831\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10218.7074 - acc: 0.9865 - f1: 0.9839\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10204.9170 - acc: 0.9865 - f1: 0.9832\n",
            "slice no:144\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10156.3387 - acc: 0.9907 - f1: 0.9876\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10139.2646 - acc: 0.9907 - f1: 0.9866\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10123.9118 - acc: 0.9906 - f1: 0.9876\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10109.5363 - acc: 0.9909 - f1: 0.9874\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10095.5926 - acc: 0.9899 - f1: 0.9862\n",
            "slice no:145\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10064.1509 - acc: 0.9935 - f1: 0.9906\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10047.0195 - acc: 0.9932 - f1: 0.9904\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10031.3469 - acc: 0.9940 - f1: 0.9906\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10016.8323 - acc: 0.9940 - f1: 0.9919\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10003.1458 - acc: 0.9937 - f1: 0.9912\n",
            "slice no:146\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10007.9065 - acc: 0.9966 - f1: 0.9940\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 9990.8233 - acc: 0.9962 - f1: 0.9934\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 9975.7523 - acc: 0.9966 - f1: 0.9932\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 9961.7823 - acc: 0.9954 - f1: 0.9929\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 9947.8934 - acc: 0.9962 - f1: 0.9941\n",
            "slice no:147\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10027.6906 - acc: 0.9971 - f1: 0.9949\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10010.7696 - acc: 0.9972 - f1: 0.9946\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 9994.8447 - acc: 0.9973 - f1: 0.9950\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 9980.0853 - acc: 0.9972 - f1: 0.9945\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 9965.9093 - acc: 0.9976 - f1: 0.9950\n",
            "slice no:148\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 9960.0274 - acc: 0.9979 - f1: 0.9953\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 9942.9594 - acc: 0.9978 - f1: 0.9959\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 9927.8351 - acc: 0.9972 - f1: 0.9953\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 9913.5892 - acc: 0.9989 - f1: 0.9961\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 9900.0184 - acc: 0.9984 - f1: 0.9961\n",
            "slice no:149\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10005.1693 - acc: 0.9981 - f1: 0.9962\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 9988.2729 - acc: 0.9987 - f1: 0.9966\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 9973.0757 - acc: 0.9988 - f1: 0.9970\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 9958.7420 - acc: 0.9982 - f1: 0.9957\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 9945.1458 - acc: 0.9983 - f1: 0.9962\n",
            "slice no:150\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10222.7317 - acc: 0.9987 - f1: 0.9966\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10205.0303 - acc: 0.9986 - f1: 0.9968\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10189.0513 - acc: 0.9980 - f1: 0.9964\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10173.9838 - acc: 0.9987 - f1: 0.9968\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10159.9016 - acc: 0.9985 - f1: 0.9969\n",
            "slice no:151\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10313.6318 - acc: 0.9984 - f1: 0.9969\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 2ms/sample - loss: 10295.1396 - acc: 0.9986 - f1: 0.9976\n",
            "Epoch 3/5\n",
            "  128/10752 [..............................] - ETA: 26s - loss: 10096.5527 - acc: 1.0000 - f1: 0.9961Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTvOBHDzMZ8X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "0e7cb0ff-3a32-4f4e-a137-56b961a3a4f9"
      },
      "source": [
        "model = tf.keras.models.load_model('trial_InputCascade_acc_001].h5', custom_objects={'f1': f1})\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jjy-lZVMM3kJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17f1e90c-de3b-4f9d-bbe4-b651d7985048"
      },
      "source": [
        "path = '/content/drive/My Drive/BRATS-2/Image_Data/LG/0013'\n",
        "p = os.listdir(path)\n",
        "p.sort(key=str.lower)\n",
        "arr = []\n",
        "for i in range(len(p)):\n",
        "    if 'more' in p[i] or 'OT' in p[i]:\n",
        "      if p[i] != '.DS_Store':\n",
        "        p1 = os.listdir(path+'/'+p[i])\n",
        "        img = sitk.ReadImage(path+'/'+p[i]+'/'+p1[0])\n",
        "        Y_labels = sitk.GetArrayFromImage(img) \n",
        "    else:\n",
        "      if p[i] != '.DS_Store':\n",
        "        p1 = os.listdir(path+'/'+p[i])\n",
        "        p1.sort()\n",
        "        img = sitk.ReadImage(path+'/'+p[i]+'/'+p1[-1])\n",
        "        arr.append(sitk.GetArrayFromImage(img))   \n",
        "data = np.zeros((Y_labels.shape[1],Y_labels.shape[0],Y_labels.shape[2],4))\n",
        "for i in range(Y_labels.shape[1]):\n",
        "  data[i,:,:,0] = arr[0][:,i,:]\n",
        "  data[i,:,:,1] = arr[1][:,i,:]\n",
        "  data[i,:,:,2] = arr[2][:,i,:]\n",
        "  data[i,:,:,3] = arr[3][:,i,:]\n",
        "info = []\n",
        " \n",
        "    \n",
        "d = data_gen(data,Y_labels,110,1)\n",
        "if(len(d) != 0):\n",
        "  y = np.zeros((d[2].shape[0],1,1,5))\n",
        "  for j in range(y.shape[0]):\n",
        "    y[j,:,:,d[2][j]] = 1\n",
        "  X1 = d[0]\n",
        "  X2 = d[1]\n",
        "  pred = model.predict([X1,X2],batch_size = 256) \n",
        "  pred = np.around(pred)\n",
        "  #print(pred.shape)\n",
        "  pred1 = np.argmax(pred.reshape(y.shape[0],5)[:,1:4],axis = 1)\n",
        "  y2 = np.argmax(y.reshape(y.shape[0],5)[:,1:4],axis = 1)\n",
        "  f1 = metrics.f1_score(y2,pred1,average='micro')\n",
        "  print(f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9518614398422091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUJPW_s-Rbli",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "a4d4b20d-de86-4b76-e454-ec3d4a3dc2a8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-0479a66aab70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HG/0001'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: data_gen() missing 1 required positional argument: 'model_no'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHuy6Eo-iCO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# m0.compile(optimizer='sgd',loss='categorical_hinge',metrics=[f1_score])\n",
        "# m0.save('trial_0001_twopathcnn_f1.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6li6W7egTQEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKt8BL36TQtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8U0nPsKSm7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMRT_nNUF6nb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfY_gPYavnE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec4vdoZOS4_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaGVclYpTRx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkbp6sv-Wzqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAbxx1isoA2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}